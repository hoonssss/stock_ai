import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import pickle
import warnings
import os
from curl_cffi import requests
import yfinance as yf

from matplotlib.dates import DateFormatter

# ë°ì´í„° ì²˜ë¦¬ ë° ëª¨ë¸ë§
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, RandomizedSearchCV, TimeSeriesSplit
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, r2_score
from sklearn.metrics import roc_curve
import xgboost as xgb
from xgboost import plot_importance

# ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import talib
from talib import abstract

import yfinance as yf
import time
from tqdm import tqdm

# ë³‘ë ¬ ì²˜ë¦¬
from concurrent.futures import ProcessPoolExecutor, as_completed

warnings.filterwarnings('ignore')

class StockPredictionModel:
    def __init__(self, prediction_type='classification', prediction_period=5, confidence_threshold=0.6):
        """
        ì£¼ì‹ ì˜ˆì¸¡ ëª¨ë¸ ì´ˆê¸°í™”

        Parameters:
        -----------
        prediction_type : str
            'classification' (ìƒìŠ¹/í•˜ë½ ë¶„ë¥˜) ë˜ëŠ” 'regression' (ê°€ê²© ì˜ˆì¸¡)
        prediction_period : int
            ì˜ˆì¸¡ ê¸°ê°„ (ì¼)
        confidence_threshold : float
            íŠ¸ë ˆì´ë”© ê²°ì •ì„ ìœ„í•œ í™•ì‹ ë„ ì„ê³„ê°’ (0.0 ~ 1.0)
        """
        self.prediction_type = prediction_type
        self.prediction_period = prediction_period
        self.confidence_threshold = confidence_threshold
        self.model = None
        self.scaler = StandardScaler()
        self.feature_names = []
        self.test_accuracy = None
        
        # ğŸ”¥ GPU ë©”ëª¨ë¦¬ í”„ë¦¬ë¡œë”©
        self.setup_gpu_memory()

    def setup_gpu_memory(self):
        """GPU ë©”ëª¨ë¦¬ ì‚¬ì „ ìµœì í™”"""
        try:
            import torch
            if torch.cuda.is_available():
                # ë©”ëª¨ë¦¬ í’€ ì„¤ì •
                torch.cuda.set_per_process_memory_fraction(0.98)
                torch.cuda.empty_cache()
                
                # ë©”ëª¨ë¦¬ í• ë‹¹ ì „ëµ ìµœì í™”
                import os
                os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'
                
                # GPU ì›Œë°ì—…
                dummy = torch.randn(2000, 2000).cuda()
                dummy = dummy @ dummy.T  # í–‰ë ¬ ì—°ì‚°ìœ¼ë¡œ GPU í™œì„±í™”
                del dummy
                torch.cuda.empty_cache()
                
                print("âœ… GPU ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ GPU ë©”ëª¨ë¦¬ ì„¤ì • ì˜¤ë¥˜: {e}")

    def check_xgboost_version(self):
        """XGBoost ë²„ì „ í™•ì¸ ë° í˜¸í™˜ ë°©ì‹ ê²°ì •"""
        import xgboost as xgb
        version = xgb.__version__
        major_version = int(version.split('.')[0])
        
        print(f"ğŸ” XGBoost ë²„ì „: {version}")
        
        if major_version >= 2:
            return 'v2'  # callbacks ë°©ì‹
        else:
            return 'v1'  # early_stopping_rounds ë°©ì‹

    def train_with_xgb_compatibility(self, model):
        """XGBoost ë²„ì „ì— ë§ëŠ” í•™ìŠµ ë°©ì‹"""
        eval_set = [(self.X_train, self.y_train), (self.X_test, self.y_test)]
        xgb_version = self.check_xgboost_version()
        
        try:
            if xgb_version == 'v2':
                # XGBoost 2.x ë°©ì‹
                model.fit(
                    self.X_train, self.y_train,
                    verbose=False
                )
                print("âœ… XGBoost 2.x ë°©ì‹ ì„±ê³µ")
            else:
                # XGBoost 1.x ë°©ì‹
                model.fit(
                    self.X_train, self.y_train,
                    eval_set=eval_set,
                    early_stopping_rounds=30,
                    verbose=False
                )
                print("âœ… XGBoost 1.x ë°©ì‹ ì„±ê³µ")
                
        except Exception as e:
            print(f"âš ï¸ ì¡°ê¸° ì¢…ë£Œ ì‹¤íŒ¨, ê¸°ë³¸ í•™ìŠµ: {e}")
            model.fit(self.X_train, self.y_train, verbose=False)
        
        return model

    def load_data(self, filepath=None, df=None):
        """
        ë°ì´í„° ë¡œë“œ (íŒŒì¼ ë˜ëŠ” ë°ì´í„°í”„ë ˆì„)

        Parameters:
        -----------
        filepath : str, optional
            ë°ì´í„° íŒŒì¼ ê²½ë¡œ (CSV)
        df : DataFrame, optional
            ì§ì ‘ ë°ì´í„°í”„ë ˆì„ ì „ë‹¬

        Returns:
        --------
        DataFrame
            ë¡œë“œëœ ì£¼ê°€ ë°ì´í„°
        """
        if filepath is not None:
            self.data = pd.read_csv(filepath)
            # ë‚ ì§œ í˜•ì‹ ë³€í™˜
            self.data['Date'] = pd.to_datetime(self.data['Date'])
            self.data = self.data.sort_values('Date')
        elif df is not None:
            self.data = df.copy()
            if 'Date' in self.data.columns:
                self.data['Date'] = pd.to_datetime(self.data['Date'])
                self.data = self.data.sort_values('Date')
        else:
            raise ValueError("íŒŒì¼ ê²½ë¡œ ë˜ëŠ” ë°ì´í„°í”„ë ˆì„ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")

        # OHLCV ë°ì´í„° ì¡´ì¬ í™•ì¸
        required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
        if not all(col in self.data.columns for col in required_cols):
            raise ValueError(f"ë°ì´í„°ì— í•„ìš”í•œ ì—´ì´ ì—†ìŠµë‹ˆë‹¤: {required_cols}")

        print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.data)} í–‰")
        return self.data

    def optimize_dataframe_memory(self, df):
        """ë°ì´í„°í”„ë ˆì„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” - Colab Proìš©"""
        start_mem = df.memory_usage().sum() / 1024**2

        # float64ë¥¼ float32ë¡œ ë³€í™˜ (ë©”ëª¨ë¦¬ ì ˆì•½)
        for col in df.select_dtypes(include=['float64']).columns:
            df[col] = df[col].astype('float32')

        # int64ë¥¼ int32ë¡œ ë³€í™˜
        for col in df.select_dtypes(include=['int64']).columns:
            if df[col].max() < 2147483647 and df[col].min() > -2147483648:
                df[col] = df[col].astype('int32')

        end_mem = df.memory_usage().sum() / 1024**2
        reduction = (start_mem - end_mem) / start_mem

        print(f"ë©”ëª¨ë¦¬ ìµœì í™”: {start_mem:.2f} MB â†’ {end_mem:.2f} MB ({reduction:.1%} ê°ì†Œ)")
        return df

    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
    @staticmethod
    def has_skopt():
        """scikit-optimize ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸"""
        try:
            import skopt
            return True
        except ImportError:
            return False

    @staticmethod
    def has_shap():
        """SHAP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸"""
        try:
            import shap
            return True
        except ImportError:
            return False
        
    def train_model(self, optimize=True, n_iter=20, advanced_optimize=True):
        """
        ëª¨ë¸ í•™ìŠµ ë©”ì„œë“œ - GPU ìµœì í™” ë²„ì „ í˜¸ì¶œ
        
        Parameters:
        -----------
        optimize : bool
            í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì—¬ë¶€
        n_iter : int
            ìµœì í™” ë°˜ë³µ íšŸìˆ˜
        advanced_optimize : bool
            ê³ ê¸‰ ìµœì í™” ì—¬ë¶€
        
        Returns:
        --------
        ëª¨ë¸ ê°ì²´
        """
        return self.train_model_gpu_fixed(optimize=optimize, n_iter=n_iter, advanced_optimize=advanced_optimize)

    def train_model_gpu_fixed(self, optimize=True, n_iter=20, advanced_optimize=True):
        """ğŸ”¥ GPU ì„±ëŠ¥ ê·¹ëŒ€í™” + ì •í™•ë„ ìœ ì§€"""
        
        if not hasattr(self, 'X_train'):
            raise ValueError("ë¨¼ì € prepare_data() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")

        print("ğŸ”¥ GPU ìµœëŒ€ ì„±ëŠ¥ ëª¨ë“œ ì‹œì‘...")

        # í´ë˜ìŠ¤ ë¹„ìœ¨ í™•ì¸
        if self.prediction_type == 'classification':
            class_counts = self.y_train.value_counts()
            scale_pos_weight = class_counts[0] / class_counts[1] if len(class_counts) > 1 else 1
        else:
            scale_pos_weight = 1

        # ğŸ”¥ GPU ìµœëŒ€ ì„±ëŠ¥ íŒŒë¼ë¯¸í„° (ì •í™•ë„ ìœ ì§€)
        if self.prediction_type == 'classification':
            gpu_params = {
                'device': 'cuda',
                'tree_method': 'hist',
                'objective': 'binary:logistic',
                'eval_metric': 'logloss',
                'learning_rate': 0.05,              # ì‹ ì¤‘í•œ í•™ìŠµ
                'n_estimators': 1500,               # GPU í™œìš© ì¦ê°€
                'max_depth': 6,                     # 5â†’6ìœ¼ë¡œ ì•½ê°„ ì¦ê°€
                'min_child_weight': 5,              # ê³¼ì í•© ë°©ì§€
                'subsample': 0.8,                   # 0.7â†’0.8ë¡œ ì•½ê°„ ì¦ê°€
                'colsample_bytree': 0.8,            # 0.7â†’0.8ë¡œ ì•½ê°„ ì¦ê°€
                'scale_pos_weight': scale_pos_weight * 1.5,  # 2â†’1.5ë¡œ ì™„í™”
                'gamma': 0.1,                       # ê³¼ì í•© ë°©ì§€ ì¶”ê°€
                'reg_alpha': 0.1,                   # L1 ì •ê·œí™” ì¶”ê°€
                'reg_lambda': 0.2,                  # L2 ì •ê·œí™” ê°•í™”
                'random_state': 42,
                'verbosity': 1,
                'n_jobs': 1
            }
            model = xgb.XGBClassifier(**gpu_params)
        else:
            gpu_params = {
                'device': 'cuda',
                'tree_method': 'hist',
                'objective': 'reg:squarederror',
                'eval_metric': 'rmse',
                'learning_rate': 0.05,
                'n_estimators': 1500,
                'max_depth': 6,
                'min_child_weight': 5,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'gamma': 0.1,
                'reg_alpha': 0.1,
                'reg_lambda': 0.2,
                'random_state': 42,
                'verbosity': 1,
                'n_jobs': 1
            }
            model = xgb.XGBRegressor(**gpu_params)
        # ğŸ”¥ GPU ë©”ëª¨ë¦¬ ìµœì í™”
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.set_per_process_memory_fraction(0.98)  # 98% ì‚¬ìš©
        except:
            pass

        # ëª¨ë¸ í•™ìŠµ
        try:
            model = self.train_with_xgb_compatibility(model)
            print("âœ… GPU ìµœì í™” í•™ìŠµ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
            model.fit(self.X_train, self.y_train)

        self.model = model

        # í…ŒìŠ¤íŠ¸ ì •í™•ë„ ê³„ì‚° (ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ)
        if self.prediction_type == 'classification':
            y_pred = self.model.predict(self.X_test)
            self.test_accuracy = accuracy_score(self.y_test, y_pred)
        else:
            y_pred = self.model.predict(self.X_test)
            self.test_accuracy = r2_score(self.y_test, y_pred)

        print(f"ğŸ‰ GPU ìµœì í™” ì™„ë£Œ! ì •í™•ë„: {self.test_accuracy:.4f}")
        return model

    def prepare_data(self, test_size=0.2):
        """
        ëª¨ë¸ë§ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„

        Parameters:
        -----------
        test_size : float
            í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨

        Returns:
        --------
        tuple
            (X_train, X_test, y_train, y_test) ë°ì´í„° ì„¸íŠ¸
        """
        if not hasattr(self, 'data_with_features'):
            raise ValueError("ë¨¼ì € create_features() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")

        df = self.data_with_features.copy()

        # íŠ¹ì„± ë° íƒ€ê²Ÿ ë¶„ë¦¬
        X = df[self.feature_names]
        y = df['Target']

        # ë¬´í•œëŒ€ ê°’ ì²˜ë¦¬ (inf, -infë¥¼ NaNìœ¼ë¡œ ë³€í™˜ í›„ ì²˜ë¦¬)
        X = X.replace([np.inf, -np.inf], np.nan)

        for col in X.columns:
            # ë¹„ìœ¨ ì§€í‘œëŠ” 1ë¡œ ì±„ì›€ (ì¤‘ë¦½ì  ê°’)
            if 'Ratio' in col:
                X[col] = X[col].fillna(1)
            # ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ ì±„ì›€
            else:
                X[col] = X[col].fillna(0)

        print(f"ë¬´í•œëŒ€ ë° NaN ê°’ ì²˜ë¦¬ ì™„ë£Œ")

        # ì‹œê³„ì—´ ë¶„í•  (ìµœê·¼ ë°ì´í„°ë¥¼ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ)
        split_idx = int(len(df) * (1 - test_size))
        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

        # ë‚ ì§œ ì €ì¥ (ë‚˜ì¤‘ì— ì‹œê°í™”ì— ì‚¬ìš©)
        self.test_dates = df['Date'].iloc[split_idx:].reset_index(drop=True)

        # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # DataFrameìœ¼ë¡œ ë³€í™˜ (íŠ¹ì„± ì´ë¦„ ìœ ì§€)
        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)
        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)

        print(f"í•™ìŠµ ë°ì´í„°: {X_train_scaled.shape}, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test_scaled.shape}")

        self.X_train, self.X_test, self.y_train, self.y_test = X_train_scaled, X_test_scaled, y_train, y_test
        return X_train_scaled, X_test_scaled, y_train, y_test

    def _check_technical_indicators(self):
        """ê¸°ìˆ ì  ì§€í‘œ í™•ì¸"""
        # ìµœê·¼ ë°ì´í„°
        recent_data = self.data_with_features.tail(20)
        latest = recent_data.iloc[-1]

        # ì˜ˆì¸¡ ë°©í–¥
        prediction = 1 if latest.get('PredictionProba', 0.5) > 0.5 else 0
        bullish_prediction = prediction == 1

        # ê¸°ìˆ ì  ì§€í‘œ í™•ì¸
        confirmations = {}

        # 1. ì´ë™í‰ê· ì„  í™•ì¸
        if 'MA_20' in latest and 'MA_50' in latest:
            ma_bullish = latest['Close'] > latest['MA_20'] > latest['MA_50']
            confirmations['ì´ë™í‰ê· '] = (ma_bullish == bullish_prediction)

        # 2. RSI í™•ì¸
        if 'RSI' in latest:
            rsi = latest['RSI']
            if bullish_prediction:
                rsi_confirm = rsi > 50 and rsi < 70  # ìƒìŠ¹ ì¶”ì„¸, ê³¼ë§¤ìˆ˜ ì•„ë‹˜
            else:
                rsi_confirm = rsi < 50 and rsi > 30  # í•˜ë½ ì¶”ì„¸, ê³¼ë§¤ë„ ì•„ë‹˜
            confirmations['RSI'] = rsi_confirm

        # 3. MACD í™•ì¸
        if 'MACD' in latest and 'MACD_Signal' in latest:
            macd_bullish = latest['MACD'] > latest['MACD_Signal']
            confirmations['MACD'] = (macd_bullish == bullish_prediction)

        # 4. ë³¼ë¦°ì € ë°´ë“œ í™•ì¸
        if 'BB_Position' in latest:
            bb_pos = latest['BB_Position']
            if bullish_prediction:
                bb_confirm = bb_pos > 0.5  # ìƒë‹¨ ë°´ë“œì— ê°€ê¹Œì›€
            else:
                bb_confirm = bb_pos < 0.5  # í•˜ë‹¨ ë°´ë“œì— ê°€ê¹Œì›€
            confirmations['ë³¼ë¦°ì €ë°´ë“œ'] = bb_confirm

        # 5. ADX ì¶”ì„¸ ê°•ë„ í™•ì¸
        if 'ADX' in latest and 'PLUS_DI_14' in latest and 'MINUS_DI_14' in latest:
            adx_strong = latest['ADX'] > 20  # ê°•í•œ ì¶”ì„¸
            trend_bullish = latest['PLUS_DI_14'] > latest['MINUS_DI_14']
            confirmations['ADX'] = adx_strong and (trend_bullish == bullish_prediction)

        return confirmations
    def _get_recent_prediction_errors(self, lookback=20):
        """ìµœê·¼ ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„ì„"""
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ìµœê·¼ ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„ì„
        if not hasattr(self, 'X_test') or not hasattr(self, 'y_test'):
            return pd.Series([0.02 * self.data['Close'].iloc[-1]])  # ê¸°ë³¸ê°’ ë°˜í™˜

        # ìµœê·¼ lookback ê°œì˜ ìƒ˜í”Œë§Œ ì‚¬ìš©
        X_recent = self.X_test.tail(lookback)
        y_recent = self.y_test.tail(lookback)

        # ì˜ˆì¸¡
        y_pred = self.model.predict(X_recent)

        # ì˜¤ì°¨ ê³„ì‚°
        errors = y_pred - y_recent

        return pd.Series(errors)

    def predict_future(self, days=1, confidence_analysis=True):
        """ë¯¸ë˜ ì˜ˆì¸¡ - ê°œì„ ëœ ë²„ì „"""
        if self.model is None:
            raise ValueError("ë¨¼ì € train_model() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")

        # ìµœì‹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        latest_data = self.data_with_features.iloc[-1]
        latest_date = latest_data['Date']
        latest_price = latest_data['Close']

        print(f"ìµœì‹  ë‚ ì§œ: {latest_date.strftime('%Y-%m-%d')}")
        print(f"ìµœì‹  ê°€ê²©: {latest_price:.2f}")

        # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ë°ì´í„°í”„ë ˆì„
        predictions_df = pd.DataFrame({
            'Date': [latest_date + timedelta(days=i+1) for i in range(days)],
            'Prediction': [None] * days,
            'Confidence': [None] * days,
            'Upper_Bound': [None] * days,
            'Lower_Bound': [None] * days
        })

        # 1. ê°œì„ : ì•ˆì •ì ì¸ íŠ¹ì„± ì¶”ì¶œ
        if not all(f in latest_data for f in self.feature_names):
            missing_features = [f for f in self.feature_names if f not in latest_data]
            print(f"ê²½ê³ : {len(missing_features)}ê°œ íŠ¹ì„±ì´ ìµœì‹  ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤. 0ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            features = np.zeros(len(self.feature_names))
            for i, feature in enumerate(self.feature_names):
                if feature in latest_data:
                    features[i] = latest_data[feature]
            features = features.reshape(1, -1)
        else:
            features = latest_data[self.feature_names].values.reshape(1, -1)

        # 2. ê°œì„ : íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ ì•ˆì •ì„± ê°•í™”
        try:
            features_scaled = self.scaler.transform(features)
        except:
            print("ê²½ê³ : ìŠ¤ì¼€ì¼ë§ ì˜¤ë¥˜, ì›ë³¸ íŠ¹ì„± ì‚¬ìš©")
            features_scaled = features

        if self.prediction_type == 'classification':
            # 3. ê°œì„ : ë¶ˆí™•ì‹¤ì„± ì¶”ì • ë° ì‹ ë¢° êµ¬ê°„
            try:
                # ìƒìŠ¹/í•˜ë½ í™•ë¥ 
                proba = self.model.predict_proba(features_scaled)[0, 1]
                prediction = 1 if proba > 0.5 else 0

                predictions_df.iloc[0, 1] = prediction
                predictions_df.iloc[0, 2] = proba

                # ì‹ ë¢° êµ¬ê°„ ê³„ì‚° (ë² íƒ€ ë¶„í¬ ê°€ì •)
                if confidence_analysis:
                    alpha = 2  # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • ê°€ëŠ¥
                    beta = 2
                    conf_level = 0.9

                    # ë² ì´ì§€ì•ˆ ì‹ ë¢° êµ¬ê°„ (ë² íƒ€ ë¶„í¬)
                    from scipy.stats import beta as beta_dist

                    # ì‚¬ì „ ë¶„í¬ì— í™•ë¥  ë³‘í•©
                    alpha_post = alpha + (proba * 10)
                    beta_post = beta + ((1 - proba) * 10)

                    lower_bound = beta_dist.ppf((1 - conf_level) / 2, alpha_post, beta_post)
                    upper_bound = beta_dist.ppf(1 - (1 - conf_level) / 2, alpha_post, beta_post)

                    predictions_df.iloc[0, 3] = upper_bound
                    predictions_df.iloc[0, 4] = lower_bound

                    print(f"90% ì‹ ë¢° êµ¬ê°„: [{lower_bound:.4f}, {upper_bound:.4f}]")

                direction = "ìƒìŠ¹" if prediction == 1 else "í•˜ë½"
                print(f"í–¥í›„ {self.prediction_period}ì¼ ì˜ˆì¸¡: {direction} (í™•ì‹ ë„: {proba:.4f})")

                # 4. ê°œì„ : ë” ë‹¤ì–‘í•œ ì‹ í˜¸ íŒë‹¨
                if proba > 0.8:
                    signal = "ê°•í•œ ë§¤ìˆ˜"
                    strength = "ë§¤ìš° ë†’ìŒ"
                elif proba > self.confidence_threshold:
                    signal = "ë§¤ìˆ˜"
                    strength = "ë†’ìŒ"
                elif proba < 0.2:
                    signal = "ê°•í•œ ë§¤ë„"
                    strength = "ë§¤ìš° ë†’ìŒ"
                elif proba < 0.4:
                    signal = "ë§¤ë„"
                    strength = "ì¤‘ê°„"
                else:
                    signal = "ê´€ë§"
                    strength = "ë‚®ìŒ"

                print(f"ì¶”ì²œ ì‹ í˜¸: {signal} (ì‹ í˜¸ ê°•ë„: {strength})")

                # ì¶”ê°€: ê¸°ìˆ ì  ì§€í‘œ í™•ì¸
                if hasattr(self, 'data_with_features'):
                    tech_confirm = self._check_technical_indicators()
                    tech_score = sum(tech_confirm.values())
                    tech_max = len(tech_confirm)

                    print(f"ê¸°ìˆ ì  ì§€í‘œ í™•ì¸: {tech_score}/{tech_max} ì§€í‘œê°€ ì˜ˆì¸¡ ë°©í–¥ í™•ì¸")

                    # ì£¼ìš” ê¸°ìˆ ì  ì§€í‘œ ì¶œë ¥
                    for indicator, confirms in tech_confirm.items():
                        status = "í™•ì¸" if confirms else "ë¶ˆì¼ì¹˜"
                        print(f"  - {indicator}: {status}")
            except Exception as e:
                print(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
                predictions_df.iloc[0, 1] = 0
                predictions_df.iloc[0, 2] = 0.5
                print("ì˜¤ë¥˜ë¡œ ì¸í•´ ê¸°ë³¸ê°’(í™•ë¥  0.5) ì‚¬ìš©")
        else:  # regression
            # ê°€ê²© ì˜ˆì¸¡
            try:
                price_pred = self.model.predict(features_scaled)[0]
                predictions_df.iloc[0, 1] = price_pred

                # í™•ì‹ ë„ ëŒ€ì‹  ì˜ˆìƒ ìˆ˜ìµë¥  ê³„ì‚°
                expected_return = price_pred / latest_price - 1
                predictions_df.iloc[0, 2] = expected_return

                # ì˜ˆì¸¡ ì‹ ë¢° êµ¬ê°„ (ì‹œê³„ì—´ ëª¨ë¸ì˜ ë¶ˆí™•ì‹¤ì„± ê³ ë ¤)
                if confidence_analysis and hasattr(self, 'data_with_features'):
                    # ê³¼ê±° ì˜ˆì¸¡ ì˜¤ì°¨ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶ˆí™•ì‹¤ì„± ì¶”ì •
                    recent_errors = self._get_recent_prediction_errors(20)
                    error_std = recent_errors.std()

                    conf_level = 0.9
                    z_score = 1.645  # 90% ì‹ ë¢°ë„ì˜ z-ì ìˆ˜

                    upper_bound = price_pred + z_score * error_std
                    lower_bound = price_pred - z_score * error_std

                    predictions_df.iloc[0, 3] = upper_bound
                    predictions_df.iloc[0, 4] = lower_bound

                    print(f"90% ì‹ ë¢° êµ¬ê°„: [{lower_bound:.2f}, {upper_bound:.2f}]")

                print(f"í–¥í›„ {self.prediction_period}ì¼ ì˜ˆìƒ ê°€ê²©: {price_pred:.2f}")
                print(f"ì˜ˆìƒ ìˆ˜ìµë¥ : {expected_return:.4f} ({expected_return * 100:.2f}%)")

                # ì‹ í˜¸ íŒë‹¨ - ë” ì„¸ë°€í•œ ê¸°ì¤€
                if expected_return > 0.05:
                    signal = "ê°•í•œ ë§¤ìˆ˜"
                    strength = "ë§¤ìš° ë†’ìŒ"
                elif expected_return > 0.01:
                    signal = "ë§¤ìˆ˜"
                    strength = "ë†’ìŒ"
                elif expected_return < -0.05:
                    signal = "ê°•í•œ ë§¤ë„"
                    strength = "ë§¤ìš° ë†’ìŒ"
                elif expected_return < -0.01:
                    signal = "ë§¤ë„"
                    strength = "ì¤‘ê°„"
                else:
                    signal = "ê´€ë§"
                    strength = "ë‚®ìŒ"

                print(f"ì¶”ì²œ ì‹ í˜¸: {signal} (ì‹ í˜¸ ê°•ë„: {strength})")
            except Exception as e:
                print(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
                predictions_df.iloc[0, 1] = latest_price
                predictions_df.iloc[0, 2] = 0
                print("ì˜¤ë¥˜ë¡œ ì¸í•´ ìµœì‹  ê°€ê²© ì‚¬ìš©")

        return predictions_df


    # StockPredictionModel í´ë˜ìŠ¤ ë‚´ì— ì¶”ê°€í•  ê°œì„ ëœ ë©”ì„œë“œë“¤
    def create_features(self, advanced=True, stock_code=None):
        """íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì‹¤í–‰ - ê°œì„ ëœ ë²„ì „"""
        print("íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì‹œì‘...")
        df = self.data.copy()

        # 1. ê°œì„ : ì¬ë¬´ ì •ë³´ íŠ¹ì„± ì¶”ê°€ ë° í™•ì¥
        if stock_code is not None:
            financial_info = get_financial_info(stock_code)

            # ì£¼ìš” ì¬ë¬´ ì§€í‘œ ì¶”ê°€
            for key, value in financial_info.items():
                fin_col_name = f'FIN_{key}'
                df[fin_col_name] = value

                # PER, PBR ë“± ì£¼ìš” ì§€í‘œëŠ” ê°€ê²©ê³¼ì˜ ë¹„ìœ¨ íŠ¹ì„± ì¶”ê°€
                if key in ['PER', 'PBR', 'PSR', 'PCR']:
                    df[f'{key}_Ratio'] = df['Close'] / value if value != 0 else 0

                    # ì¶”ê°€: PER, PBR ë“±ì˜ ì‹œì¥ í‰ê·  ëŒ€ë¹„ ìƒëŒ€ê°’ (ì™¸ë¶€ ë°ì´í„° í•„ìš”)
                    # df[f'{key}_RelativeToMarket'] = value / market_avg[key] if key in market_avg else 1.0

        # 2. ê¸°ë³¸ ê°€ê²© íŠ¹ì„±
        df['PrevClose'] = df['Close'].shift(1)
        df['Return'] = df['Close'] / df['PrevClose'] - 1
        df['RangePercent'] = (df['High'] - df['Low']) / df['PrevClose']
        df['GapPercent'] = (df['Open'] - df['PrevClose']) / df['PrevClose']

        # 3. ê°œì„ : ì‹¬ë¦¬ì  ê°€ê²©ëŒ€ íŠ¹ì„± ì¶”ê°€
        df['PriceIntegerRatio'] = (df['Close'] % 1000) / 1000  # ì²œ ë‹¨ìœ„ ê°€ê²©ëŒ€ ë‚´ ìœ„ì¹˜
        df['PriceRoundNumber'] = (df['Close'] % 1000 < 50).astype(int)  # ì²œ ë‹¨ìœ„ ê°€ê²©ì— ê°€ê¹Œìš´ì§€

        # 4. ëŒ€ìƒ ë³€ìˆ˜ ìƒì„±
        if self.prediction_type == 'classification':
            # Nì¼ í›„ ì£¼ê°€ê°€ ì˜¤ë¥¼ ê²½ìš° 1, ì•„ë‹ˆë©´ 0
            future_return = df['Close'].shift(-self.prediction_period) / df['Close'] - 1
            df['Target'] = (future_return > 0).astype(int)

            # ì¶”ê°€: ìƒìŠ¹ í™•ë¥  ë²”ì£¼í™” (ë” ì„¸ë¶„í™”ëœ ì˜ˆì¸¡ ëª©í‘œ)
            # df['Target_3class'] = pd.qcut(future_return, 3, labels=[0, 1, 2])  # í•˜ë½, ë³´í•©, ìƒìŠ¹
        else:  # regression
            # Nì¼ í›„ ì£¼ê°€
            df['Target'] = df['Close'].shift(-self.prediction_period)

        # 5. ì´ë™í‰ê·  íŠ¹ì„± - ê°œì„ : ë¹„ì„ í˜• ìŠ¤ì¼€ì¼ë¡œ ë‹¤ì–‘í™”
        for period in [5, 10, 20, 50, 100]:
            df[f'MA_{period}'] = df['Close'].rolling(window=period).mean()
            df[f'MA_Ratio_{period}'] = df['Close'] / df[f'MA_{period}']
            df[f'Volume_MA_{period}'] = df['Volume'].rolling(window=period).mean()
            df[f'Volume_Ratio_{period}'] = df['Volume'] / df[f'Volume_MA_{period}']

            # ì¶”ê°€: ì£¼ê°€ì˜ ì´ë™í‰ê·  êµì°¨ ì‹œì  í¬ì°©
            df[f'MA_Cross_{period}'] = ((df['Close'] > df[f'MA_{period}']) &
                                    (df['Close'].shift(1) <= df[f'MA_{period}'].shift(1))).astype(int)

        # 6. ê¸°ìˆ ì  ì§€í‘œ - ê°œì„ : ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„°ë¡œ í™•ì¥
        # RSI ê¸°ê°„ ë‹¤ì–‘í™”
        for rsi_period in [9, 14, 25]:
            df[f'RSI_{rsi_period}'] = talib.RSI(df['Close'], timeperiod=rsi_period)

            # ì¶”ê°€: RSI ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ ì¡´ ì§„ì…/ì´íƒˆ ì‹ í˜¸
            df[f'RSI_{rsi_period}_Oversold'] = (df[f'RSI_{rsi_period}'] < 30).astype(int)
            df[f'RSI_{rsi_period}_Overbought'] = (df[f'RSI_{rsi_period}'] > 70).astype(int)
            df[f'RSI_{rsi_period}_CrossUp30'] = ((df[f'RSI_{rsi_period}'] > 30) &
                                            (df[f'RSI_{rsi_period}'].shift(1) <= 30)).astype(int)
            df[f'RSI_{rsi_period}_CrossDown70'] = ((df[f'RSI_{rsi_period}'] < 70) &
                                                (df[f'RSI_{rsi_period}'].shift(1) >= 70)).astype(int)

        # ê¸°ë³¸ RSI ìœ ì§€ (ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜ì„± ìœ„í•´)
        df['RSI'] = talib.RSI(df['Close'], timeperiod=14)

        # MACD ë³€í˜•
        for fast_period, slow_period in [(8, 17), (12, 26)]:
            macd, macd_signal, macd_hist = talib.MACD(
                df['Close'], fastperiod=fast_period, slowperiod=slow_period, signalperiod=9)
            df[f'MACD_{fast_period}_{slow_period}'] = macd
            df[f'MACD_Signal_{fast_period}_{slow_period}'] = macd_signal
            df[f'MACD_Hist_{fast_period}_{slow_period}'] = macd_hist

            # ì¶”ê°€: MACD ì‹œê·¸ë„ êµì°¨ (ê³¨ë“ /ë°ë“œ í¬ë¡œìŠ¤)
            df[f'MACD_GoldenCross_{fast_period}_{slow_period}'] = ((macd > macd_signal) &
                                                            (macd.shift(1) <= macd_signal.shift(1))).astype(int)
            df[f'MACD_DeadCross_{fast_period}_{slow_period}'] = ((macd < macd_signal) &
                                                            (macd.shift(1) >= macd_signal.shift(1))).astype(int)

        # ê¸°ë³¸ MACD ìœ ì§€ (ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜ì„± ìœ„í•´)
        macd, macd_signal, macd_hist = talib.MACD(df['Close'], fastperiod=12, slowperiod=26, signalperiod=9)
        df['MACD'] = macd
        df['MACD_Signal'] = macd_signal
        df['MACD_Hist'] = macd_hist

        # 7. ë³¼ë¦°ì € ë°´ë“œ ê°œì„ : ë‹¤ì–‘í•œ í‘œì¤€í¸ì°¨ì™€ ê¸°ê°„ ì ìš©
        for bb_period, stdev in [(20, 2), (20, 3), (50, 2)]:
            upper, middle, lower = talib.BBANDS(
                df['Close'], timeperiod=bb_period, nbdevup=stdev, nbdevdn=stdev, matype=0)
            df[f'BB_Upper_{bb_period}_{stdev}'] = upper
            df[f'BB_Middle_{bb_period}_{stdev}'] = middle
            df[f'BB_Lower_{bb_period}_{stdev}'] = lower
            df[f'BB_Width_{bb_period}_{stdev}'] = (upper - lower) / middle
            df[f'BB_Position_{bb_period}_{stdev}'] = (df['Close'] - lower) / (upper - lower)

            # ì¶”ê°€: ë³¼ë¦°ì € ë°´ë“œ ëŒíŒŒ ì‹ í˜¸
            df[f'BB_UpperBreakout_{bb_period}_{stdev}'] = ((df['Close'] > upper) &
                                                        (df['Close'].shift(1) <= upper.shift(1))).astype(int)
            df[f'BB_LowerBreakout_{bb_period}_{stdev}'] = ((df['Close'] < lower) &
                                                        (df['Close'].shift(1) >= lower.shift(1))).astype(int)

        # ê¸°ë³¸ ë³¼ë¦°ì € ë°´ë“œ ìœ ì§€ (ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜ì„± ìœ„í•´)
        upper, middle, lower = talib.BBANDS(df['Close'], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)
        df['BB_Upper'] = upper
        df['BB_Middle'] = middle
        df['BB_Lower'] = lower
        df['BB_Width'] = (upper - lower) / middle
        df['BB_Position'] = (df['Close'] - lower) / (upper - lower)

        # 8. ì¶”ì„¸ ì§€í‘œ ê°œì„ 
        for adx_period in [7, 14, 28]:
            df[f'ADX_{adx_period}'] = talib.ADX(df['High'], df['Low'], df['Close'], timeperiod=adx_period)
            df[f'PLUS_DI_{adx_period}'] = talib.PLUS_DI(df['High'], df['Low'], df['Close'], timeperiod=adx_period)
            df[f'MINUS_DI_{adx_period}'] = talib.MINUS_DI(df['High'], df['Low'], df['Close'], timeperiod=adx_period)

            # ì¶”ê°€: ADX ì¶”ì„¸ ê°•ë„ ë¶„ë¥˜
            df[f'ADX_StrongTrend_{adx_period}'] = (df[f'ADX_{adx_period}'] > 25).astype(int)
            df[f'ADX_VeryStrongTrend_{adx_period}'] = (df[f'ADX_{adx_period}'] > 50).astype(int)

            # ì¶”ê°€: DI êµì°¨ ì‹ í˜¸ (ì¶”ì„¸ ë°©í–¥ ì „í™˜)
            df[f'DI_CrossUp_{adx_period}'] = ((df[f'PLUS_DI_{adx_period}'] > df[f'MINUS_DI_{adx_period}']) &
                                            (df[f'PLUS_DI_{adx_period}'].shift(1) <= df[f'MINUS_DI_{adx_period}'].shift(1))).astype(int)
            df[f'DI_CrossDown_{adx_period}'] = ((df[f'PLUS_DI_{adx_period}'] < df[f'MINUS_DI_{adx_period}']) &
                                            (df[f'PLUS_DI_{adx_period}'].shift(1) >= df[f'MINUS_DI_{adx_period}'].shift(1))).astype(int)

        # ê¸°ë³¸ ADX ìœ ì§€ (ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜ì„± ìœ„í•´)
        df['ADX'] = talib.ADX(df['High'], df['Low'], df['Close'], timeperiod=14)

        # ATR(Average True Range) ë‹¤ì–‘í™” - ë³€ë™ì„± ì¸¡ì •
        for atr_period in [7, 14, 21]:
            df[f'ATR_{atr_period}'] = talib.ATR(df['High'], df['Low'], df['Close'], timeperiod=atr_period)
            df[f'ATR_Percent_{atr_period}'] = df[f'ATR_{atr_period}'] / df['Close']

        # ê¸°ë³¸ ATR ìœ ì§€
        df['ATR'] = talib.ATR(df['High'], df['Low'], df['Close'], timeperiod=14)
        df['ATR_Percent'] = df['ATR'] / df['Close']

        if advanced:
            # 9. ê³ ê¸‰ ê¸°ìˆ ì  ì§€í‘œ - ì¼ì¤‘ ê°€ê²© íŠ¹ì„±
            df['DayHigh_Ratio'] = df['High'] / df['Open']
            df['DayLow_Ratio'] = df['Low'] / df['Open']
            df['CloseOpen_Ratio'] = df['Close'] / df['Open']
            df['ClosePosition'] = (df['Close'] - df['Low']) / (df['High'] - df['Low'])

            # ì¶”ê°€: ìº”ë“¤ ìœ í˜• íŠ¹ì„±
            df['Doji'] = ((abs(df['Close'] - df['Open']) / (df['High'] - df['Low'])) < 0.1).astype(int)
            df['Bullish'] = (df['Close'] > df['Open']).astype(int)
            df['Bearish'] = (df['Close'] < df['Open']).astype(int)
            df['LongUpperShadow'] = ((df['High'] - np.maximum(df['Open'], df['Close'])) >
                                (abs(df['Open'] - df['Close']))).astype(int)
            df['LongLowerShadow'] = ((np.minimum(df['Open'], df['Close']) - df['Low']) >
                                (abs(df['Open'] - df['Close']))).astype(int)

            # 10. ëª¨ë©˜í…€ ì§€í‘œ í™•ì¥
            for period in [5, 10, 20, 60, 120]:
                df[f'ROC_{period}'] = talib.ROC(df['Close'], timeperiod=period)

                # ì¶”ê°€: ëª¨ë©˜í…€ ê°€ì†/ê°ì† í¬ì°©
                if period <= 60:  # ë‹¨ê¸°~ì¤‘ê¸° ëª¨ë©˜í…€ì— ëŒ€í•´ì„œë§Œ ê³„ì‚°
                    df[f'ROC_Accel_{period}'] = df[f'ROC_{period}'] - df[f'ROC_{period}'].shift(1)
                    df[f'ROC_Sign_{period}'] = np.sign(df[f'ROC_{period}'])
                    df[f'ROC_SignChange_{period}'] = (df[f'ROC_Sign_{period}'] != df[f'ROC_Sign_{period}'].shift(1)).astype(int)

            # 11. ê°ì¢… ì˜¤ì‹¤ë ˆì´í„° í™•ì¥
            # ìœŒë¦¬ì—„ìŠ¤ %R - ë‹¤ì–‘í•œ ê¸°ê°„
            for period in [7, 14, 28]:
                df[f'WILLR_{period}'] = talib.WILLR(df['High'], df['Low'], df['Close'], timeperiod=period)
                # ì¶”ê°€: ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ ì¡´ ì§„ì…/ì´íƒˆ
                df[f'WILLR_{period}_Oversold'] = (df[f'WILLR_{period}'] < -80).astype(int)
                df[f'WILLR_{period}_Overbought'] = (df[f'WILLR_{period}'] > -20).astype(int)

            # CCI (Commodity Channel Index) - ë‹¤ì–‘í•œ ê¸°ê°„
            for period in [7, 14, 20]:
                df[f'CCI_{period}'] = talib.CCI(df['High'], df['Low'], df['Close'], timeperiod=period)
                # ì¶”ê°€: CCI ì‹ í˜¸
                df[f'CCI_{period}_Positive'] = (df[f'CCI_{period}'] > 0).astype(int)
                df[f'CCI_{period}_Negative'] = (df[f'CCI_{period}'] < 0).astype(int)
                df[f'CCI_{period}_CrossZero'] = ((df[f'CCI_{period}'] > 0) &
                                            (df[f'CCI_{period}'].shift(1) <= 0)).astype(int)

            # ê¸°ë³¸ ì˜¤ì‹¤ë ˆì´í„° ìœ ì§€
            df['WILLR'] = talib.WILLR(df['High'], df['Low'], df['Close'], timeperiod=14)
            df['CCI'] = talib.CCI(df['High'], df['Low'], df['Close'], timeperiod=14)
            df['ULTOSC'] = talib.ULTOSC(df['High'], df['Low'], df['Close'], timeperiod1=7, timeperiod2=14, timeperiod3=28)
            df['STOCH_K'], df['STOCH_D'] = talib.STOCH(df['High'], df['Low'], df['Close'],
                                                    fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)

            # 12. ì¶”ê°€ ì¶”ì„¸ ì§€í‘œ í™•ì¥
            # AROON ì§€í‘œ - ë‹¤ì–‘í•œ ê¸°ê°„
            for period in [7, 14, 25]:
                df[f'AROON_UP_{period}'], df[f'AROON_DOWN_{period}'] = talib.AROON(df['High'], df['Low'], timeperiod=period)
                # ì¶”ê°€: AROON ì‹ í˜¸
                df[f'AROON_Bullish_{period}'] = (df[f'AROON_UP_{period}'] > df[f'AROON_DOWN_{period}']).astype(int)
                df[f'AROON_CrossUp_{period}'] = ((df[f'AROON_UP_{period}'] > df[f'AROON_DOWN_{period}']) &
                                            (df[f'AROON_UP_{period}'].shift(1) <= df[f'AROON_DOWN_{period}'].shift(1))).astype(int)

            # ê¸°ë³¸ AROON ìœ ì§€
            df['AROON_UP'], df['AROON_DOWN'] = talib.AROON(df['High'], df['Low'], timeperiod=14)

            # 13. ìº”ë“¤ìŠ¤í‹± íŒ¨í„´ ê°•í™” - ë” ë§ì€ íŒ¨í„´ í¬í•¨
            patterns = [
                'CDLDOJI', 'CDLHAMMER', 'CDLENGULFING', 'CDLMORNINGSTAR', 'CDLEVENINGSTAR',
                'CDLSHOOTINGSTAR', 'CDLHARAMI', 'CDLDARKCLOUDCOVER', 'CDLPIERCING',
                'CDLSPINNINGTOP', 'CDLMARUBOZU', 'CDLINVERTEDHAMMER', 'CDLHANGINGMAN',
                'CDLBELTHOLD', 'CDLCOUNTERATTACK',
                'CDLDOJISTAR', 'CDLDRAGONFLYDOJI', 'CDLHIGHWAVE'
            ]
            for pattern in patterns:
                if hasattr(talib, pattern):
                    try:
                        pattern_func = getattr(talib, pattern)
                        df[pattern] = pattern_func(df['Open'], df['High'], df['Low'], df['Close'])
                    except Exception as e:
                        print(f"íŒ¨í„´ {pattern} ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
                else:
                    print(f"ê²½ê³ : TA-Libì—ì„œ {pattern} íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")

            # ì¶”ê°€: ì¢…í•© íŒ¨í„´ ì ìˆ˜ (ê¸ì •ì  íŒ¨í„´ - ë¶€ì •ì  íŒ¨í„´)
            bullish_patterns = ['CDLHAMMER', 'CDLPIERCING', 'CDLMORNINGSTAR', 'CDLENGULFING']
            bearish_patterns = ['CDLSHOOTINGSTAR', 'CDLDARKCLOUDCOVER', 'CDLEVENINGSTAR']

            df['Pattern_Bullish_Count'] = sum([df[p] > 0 for p in bullish_patterns])
            df['Pattern_Bearish_Count'] = sum([df[p] < 0 for p in bearish_patterns])

            # 14. ì´ë™í‰ê·  êµì°¨ í™•ì¥
            ma_pairs = [(5, 10), (10, 20), (20, 50), (50, 100)]
            for short_ma, long_ma in ma_pairs:
                df[f'MA_{short_ma}_{long_ma}_Ratio'] = df[f'MA_{short_ma}'] / df[f'MA_{long_ma}']
                df[f'MA_{short_ma}_{long_ma}_Cross'] = (df[f'MA_{short_ma}'] > df[f'MA_{long_ma}']).astype(int)

                # ì¶”ê°€: ê³¨ë“  í¬ë¡œìŠ¤ / ë°ë“œ í¬ë¡œìŠ¤ ê°ì§€
                df[f'MA_{short_ma}_{long_ma}_GoldenCross'] = ((df[f'MA_{short_ma}'] > df[f'MA_{long_ma}']) &
                                                            (df[f'MA_{short_ma}'].shift(1) <= df[f'MA_{long_ma}'].shift(1))).astype(int)
                df[f'MA_{short_ma}_{long_ma}_DeadCross'] = ((df[f'MA_{short_ma}'] < df[f'MA_{long_ma}']) &
                                                        (df[f'MA_{short_ma}'].shift(1) >= df[f'MA_{long_ma}'].shift(1))).astype(int)

            # 15. ì—°ì† ìƒìŠ¹/í•˜ë½ íŒ¨í„´ - ì •ë°€í™”
            for i in range(1, 6):
                df[f'UpDay_{i}'] = (df['Return'].shift(i) > 0).astype(int)
                df[f'DownDay_{i}'] = (df['Return'].shift(i) < 0).astype(int)

                # ì¶”ê°€: ì—°ì† ìƒìŠ¹/í•˜ë½ì˜ ëˆ„ì  ìˆ˜ìµë¥ 
                if i > 1:
                    df[f'ConsecutiveReturn_{i}'] = df['Close'].shift(1) / df['Close'].shift(i) - 1

            # ì—°ì† ìƒìŠ¹/í•˜ë½ íŒ¨í„´
            for n in [2, 3, 5]:
                # nì¼ ì—°ì† ìƒìŠ¹
                up_cond = True
                for i in range(1, n+1):
                    up_cond = up_cond & (df[f'UpDay_{i}'] > 0)
                df[f'{n}DayUp'] = up_cond.astype(int)

                # nì¼ ì—°ì† í•˜ë½
                down_cond = True
                for i in range(1, n+1):
                    down_cond = down_cond & (df[f'DownDay_{i}'] > 0)
                df[f'{n}DayDown'] = down_cond.astype(int)

            # 16. ì§€ì—°ëœ ì§€í‘œ (1ì¼, 2ì¼, 3ì¼, 5ì¼, 10ì¼ ì „) - í™•ì¥
            delay_features = ['Return', 'RangePercent', 'RSI', 'MACD_Hist', 'BB_Position',
                            'ADX', 'ATR_Percent', 'ClosePosition']
            for lag in [1, 2, 3, 5, 10]:
                for col in delay_features:
                    df[f'{col}_Lag{lag}'] = df[col].shift(lag)

            # 17. ìµœê·¼ Nì¼ íŠ¹ì„± ê°•í™”
            for period in [3, 5, 10, 20, 60]:
                # ìµœê·¼ Nì¼ ìˆ˜ìµë¥  ë° ëˆ„ì  ìˆ˜ìµë¥ 
                df[f'Return_{period}d'] = df['Close'] / df['Close'].shift(period) - 1
                df[f'CumReturn_{period}d'] = (df['Close'] / df['Close'].shift(1)).rolling(period).apply(lambda x: x.prod() - 1)

                # ìµœê·¼ Nì¼ ë³€ë™ì„± ë° ë¹„ëŒ€ì¹­ì„±
                returns = df['Return'].rolling(period)
                df[f'Volatility_{period}d'] = returns.std()
                df[f'Skew_{period}d'] = returns.skew()
                df[f'Kurtosis_{period}d'] = returns.kurt()

                # ìµœê·¼ Nì¼ ìµœê³ /ìµœì € ëŒíŒŒ
                df[f'HighBreakout_{period}d'] = (df['High'] > df['High'].rolling(period).max().shift(1)).astype(int)
                df[f'LowBreakout_{period}d'] = (df['Low'] < df['Low'].rolling(period).min().shift(1)).astype(int)

                # í‰ê·  ê±°ë˜ëŸ‰ ëŒ€ë¹„ ìƒëŒ€ ê±°ë˜ëŸ‰ ë° ì¶”ì„¸
                df[f'RelVolume_{period}d'] = df['Volume'] / df['Volume'].rolling(period).mean()
                df[f'VolumeTrend_{period}d'] = (df['Volume'].rolling(period).mean() /
                                            df['Volume'].rolling(period).mean().shift(5) - 1)

            # 18. ì‹œê³„ì—´ ë° ê³„ì ˆì„± íŠ¹ì„± ê°•í™”
            # ì¶”ê°€: í™•ì¥ëœ ì‹œê°„ íŠ¹ì„±
            df['DayOfWeek'] = df['Date'].dt.dayofweek
            df['Month'] = df['Date'].dt.month
            df['WeekOfYear'] = df['Date'].dt.isocalendar().week.astype(int)
            df['Quarter'] = df['Date'].dt.quarter
            df['Year'] = df['Date'].dt.year

            # ì¶”ê°€: ì›”ì´ˆ/ì›”ë§, ë¶„ê¸°ì´ˆ/ë¶„ê¸°ë§ íŠ¹ì„±
            df['MonthStart'] = df['Date'].dt.is_month_start.astype(int)
            df['MonthEnd'] = df['Date'].dt.is_month_end.astype(int)
            df['QuarterStart'] = ((df['Date'].dt.month - 1) % 3 == 0) & (df['Date'].dt.day == 1)
            df['QuarterEnd'] = df['Date'].dt.is_quarter_end.astype(int)

            # ê³„ì ˆ ë”ë¯¸ ë³€ìˆ˜
            spring = (df['Month'] >= 3) & (df['Month'] <= 5)
            summer = (df['Month'] >= 6) & (df['Month'] <= 8)
            fall = (df['Month'] >= 9) & (df['Month'] <= 11)
            winter = (df['Month'] == 12) | (df['Month'] <= 2)

            df['Spring'] = spring.astype(int)
            df['Summer'] = summer.astype(int)
            df['Fall'] = fall.astype(int)
            df['Winter'] = winter.astype(int)

            # 19. ì£¼ê°„ ë° ì›”ê°„ ìˆ˜ìµë¥  í™•ì¥
            df['WeeklyReturn'] = df['Close'] / df['Close'].shift(5) - 1
            df['MonthlyReturn'] = df['Close'] / df['Close'].shift(20) - 1
            df['QuarterlyReturn'] = df['Close'] / df['Close'].shift(60) - 1

            # ì¶”ê°€: ì£¼/ì›”/ë¶„ê¸° ì„±ê³¼ ëŒ€ë¹„ í˜„ì¬ ì„±ê³¼ ë¹„êµ
            df['WeeklyOutperformance'] = df['Return'] / (df['WeeklyReturn'] / 5 + 1e-10)
            df['MonthlyOutperformance'] = df['Return'] / (df['MonthlyReturn'] / 20 + 1e-10)

            # 20. ë°©í–¥ ì¼ì¹˜ ì§€í‘œ í™•ì¥
            df['Direction_RSI'] = ((df['RSI'] > 50) == (df['Return'] > 0)).astype(int)
            df['Direction_MACD'] = ((df['MACD'] > df['MACD_Signal']) == (df['Return'] > 0)).astype(int)

            # ì¶”ê°€: ë” ë§ì€ ì§€í‘œì™€ì˜ ë°©í–¥ ì¼ì¹˜ì„±
            df['Direction_CCI'] = ((df['CCI'] > 0) == (df['Return'] > 0)).astype(int)
            df['Direction_ATR'] = ((df['ATR_Percent'] > df['ATR_Percent'].shift(1)) ==
                                (df['RangePercent'] > df['RangePercent'].shift(1))).astype(int)

            # 21. ì‹œì¥ ê°•ë„ ë©”íƒ€ íŠ¹ì„±
            # ì‹œì¥ ê°•ë„ ì§€ìˆ˜ (ì—¬ëŸ¬ ì§€í‘œì˜ ê°€ì¤‘ í•©ì‚°)
            rsi_signal = (df['RSI'] > 50).astype(int) * 2 - 1  # -1 or 1
            macd_signal = (df['MACD'] > df['MACD_Signal']).astype(int) * 2 - 1
            cci_signal = (df['CCI'] > 0).astype(int) * 2 - 1
            adx_signal = (df['PLUS_DI_14'] > df['MINUS_DI_14']).astype(int) * (df['ADX'] > 20).astype(int) * 2 - 1

            df['MarketStrength'] = (rsi_signal * 0.25 +
                                macd_signal * 0.25 +
                                cci_signal * 0.25 +
                                adx_signal * 0.25)

            # ì‹œì¥ ê°•ë„ì˜ ë³€í™”ìœ¨
            df['MarketStrengthChange'] = df['MarketStrength'] - df['MarketStrength'].shift(1)

            # 22. í´ëŸ¬ìŠ¤í„° ê°•ë„ íŠ¹ì„±
            # ì—¬ëŸ¬ ì§€í‘œì˜ ì¼ì¹˜ë„ë¥¼ ì ìˆ˜í™”
            bullish_signals = [
                (df['RSI'] > 50),
                (df['MACD'] > df['MACD_Signal']),
                (df['CCI'] > 0),
                (df['PLUS_DI_14'] > df['MINUS_DI_14']),
                (df['Close'] > df['MA_20']),
                (df['Close'] > df['MA_50']),
                (df['BB_Position'] > 0.5),
                (df['ROC_10'] > 0)
            ]

            df['BullishSignalCount'] = sum([signal.astype(int) for signal in bullish_signals])
            df['BullishConsensus'] = df['BullishSignalCount'] / len(bullish_signals)

            # ê°•í•œ ì¶”ì„¸ ì‹ í˜¸ (80% ì´ìƒ ì¼ì¹˜)
            df['StrongBullishSignal'] = (df['BullishConsensus'] >= 0.8).astype(int)
            df['StrongBearishSignal'] = (df['BullishConsensus'] <= 0.2).astype(int)

        # 23. ê°œì„ : NaN ê°’ ì²˜ë¦¬ (ì œê±° ëŒ€ì‹  ì±„ìš°ê¸°)
        # íŠ¹ì„±ë³„ ì ì ˆí•œ ì±„ìš°ê¸° ë°©ì‹ ì ìš©
        for col in df.columns:
            if col in ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']:
                continue

            # ê¸°ìˆ ì  ì§€í‘œëŠ” ì•ìª½ NaNì„ ìµœì´ˆê°’ìœ¼ë¡œ ì±„ì›€
            if any(col.startswith(prefix) for prefix in ['RSI', 'MACD', 'BB_', 'ATR', 'ADX', 'CCI', 'WILLR', 'AROON']):
                df[col] = df[col].fillna(method='bfill').fillna(0)

            # ë¹„ìœ¨ ì§€í‘œëŠ” 1ë¡œ ì±„ì›€ (ì¤‘ë¦½ì  ê°’)
            elif 'Ratio' in col:
                df[col] = df[col].fillna(1)

            # ì‹ í˜¸ ì§€í‘œëŠ” 0ìœ¼ë¡œ ì±„ì›€ (ì‹ í˜¸ ì—†ìŒ)
            elif any(term in col for term in ['Cross', 'Signal', 'Breakout', 'Bullish', 'Bearish']):
                df[col] = df[col].fillna(0)

            # ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ ì±„ì›€
            else:
                df[col] = df[col].fillna(0)

        print(f"íŠ¹ì„± ìƒì„± ë° NaN ì²˜ë¦¬ ì™„ë£Œ: {len(df)} í–‰")

        # íŠ¹ì„± ì´ë¦„ ì €ì¥ ì „ì— ë©”ëª¨ë¦¬ ìµœì í™”
        df = self.optimize_dataframe_memory(df)

        # íŠ¹ì„± ì´ë¦„ ì €ì¥
        features = [col for col in df.columns if col not in ['Date', 'Target', 'Open', 'High', 'Low', 'Close', 'Volume']]
        self.feature_names = features
        print(f"ìƒì„±ëœ íŠ¹ì„± ìˆ˜: {len(features)}")

        self.data_with_features = df
        return df

    def optimize_dataframe_memory(self, df):
        """ë°ì´í„°í”„ë ˆì„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”"""
        print("ë°ì´í„°í”„ë ˆì„ ë©”ëª¨ë¦¬ ìµœì í™” ì¤‘...")
        start_mem = df.memory_usage().sum() / 1024**2

        # float64ë¥¼ float32ë¡œ ë‹¤ìš´ìºìŠ¤íŒ…
        for col in df.select_dtypes(include=['float64']).columns:
            df[col] = df[col].astype('float32')

        # int64ë¥¼ int32ë¡œ ë‹¤ìš´ìºìŠ¤íŒ…
        for col in df.select_dtypes(include=['int64']).columns:
            # ìµœëŒ€ê°’ì´ 2^31-1ë³´ë‹¤ ì‘ì€ì§€ í™•ì¸
            if df[col].max() < 2147483647 and df[col].min() > -2147483648:
                df[col] = df[col].astype('int32')

        # object íƒ€ì… ì—´ì— ëŒ€í•œ ë©”ëª¨ë¦¬ ìµœì í™”
        for col in df.select_dtypes(include=['object']).columns:
            if col != 'Date':  # Date ì»¬ëŸ¼ì€ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
                num_unique_values = len(df[col].unique())
                num_total_values = len(df[col])
                if num_unique_values / num_total_values < 0.5:  # ê³ ìœ  ê°’ì´ 50% ë¯¸ë§Œì¸ ê²½ìš°
                    df[col] = df[col].astype('category')

        end_mem = df.memory_usage().sum() / 1024**2
        reduction = (start_mem - end_mem) / start_mem

        print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {start_mem:.2f} MB â†’ {end_mem:.2f} MB ({reduction:.1%} ê°ì†Œ)")
        return df

    def save_model(self, filepath):
        """
        ëª¨ë¸ ì €ì¥ - ìµœì í™”ëœ í¬ë§·

        Parameters:
        -----------
        filepath : str
            ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        """
        if self.model is None:
            raise ValueError("ë¨¼ì € train_model() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")

        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(filepath), exist_ok=True)

        # íŒŒì¼ í™•ì¥ì í™•ì¸
        if not filepath.endswith('.pkl') and not filepath.endswith('.bin'):
            filepath = filepath + '.bin'  # ê¸°ë³¸ í™•ì¥ì ì¶”ê°€

        if filepath.endswith('.bin'):
            # XGBoost ë„¤ì´í‹°ë¸Œ í¬ë§·ìœ¼ë¡œ ì €ì¥ (ë” ì‘ê³  ë¹ ë¦„)
            try:
                # ëª¨ë¸ë§Œ ì €ì¥
                model_path = filepath
                self.model.save_model(model_path)

                # ë©”íƒ€ë°ì´í„° ë³„ë„ ì €ì¥
                meta_path = filepath.replace('.bin', '.meta.pkl')
                meta_data = {
                    'scaler': self.scaler,
                    'feature_names': self.feature_names,
                    'prediction_type': self.prediction_type,
                    'prediction_period': self.prediction_period,
                    'confidence_threshold': self.confidence_threshold,
                    'test_accuracy': self.test_accuracy
                }
                with open(meta_path, 'wb') as f:
                    pickle.dump(meta_data, f, protocol=4)  # í”„ë¡œí† ì½œ 4ëŠ” ë” íš¨ìœ¨ì 

                print(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path} (XGBoost ë„¤ì´í‹°ë¸Œ í¬ë§·)")
                print(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {meta_path}")
                return
            except Exception as e:
                print(f"XGBoost ë„¤ì´í‹°ë¸Œ í¬ë§·ìœ¼ë¡œ ì €ì¥ ì‹¤íŒ¨, í”¼í´ë¡œ ëŒ€ì²´: {e}")

        # ê¸°ì¡´ ë°©ì‹ (í”¼í´)
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'feature_names': self.feature_names,
            'prediction_type': self.prediction_type,
            'prediction_period': self.prediction_period,
            'confidence_threshold': self.confidence_threshold,
            'test_accuracy': self.test_accuracy
        }

        # ìµœì í™”ëœ í”¼í´ ì €ì¥
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f, protocol=4)  # í”„ë¡œí† ì½œ 4ëŠ” ë” íš¨ìœ¨ì 

        print(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {filepath} (í”¼í´ í¬ë§·)")

    @classmethod
    def load_model(cls, filepath):
        """
        ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ

        Parameters:
        -----------
        filepath : str
            ëª¨ë¸ íŒŒì¼ ê²½ë¡œ

        Returns:
        --------
        StockPredictionModel
            ë¡œë“œëœ ëª¨ë¸ ê°ì²´
        """
        # ëª¨ë¸ íŒŒì¼ ë¡œë“œ
        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)

        # ëª¨ë¸ ê°ì²´ ìƒì„±
        prediction_type = model_data['prediction_type']
        prediction_period = model_data['prediction_period']
        confidence_threshold = model_data['confidence_threshold']

        model_instance = cls(
            prediction_type=prediction_type,
            prediction_period=prediction_period,
            confidence_threshold=confidence_threshold
        )

        # ëª¨ë¸ ì†ì„± ì„¤ì •
        model_instance.model = model_data['model']
        model_instance.scaler = model_data['scaler']
        model_instance.feature_names = model_data['feature_names']
        model_instance.test_accuracy = model_data.get('test_accuracy')

        print(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {filepath}")
        print(f"ì˜ˆì¸¡ ìœ í˜•: {prediction_type}")
        print(f"ì˜ˆì¸¡ ê¸°ê°„: {prediction_period}ì¼")

        return model_instance

    def select_important_features(self, threshold=0.01, method='importance', top_n=None):
        """ì¤‘ìš”ë„ê°€ ë†’ì€ íŠ¹ì„±ë§Œ ì„ íƒí•˜ê³  ìŠ¤ì¼€ì¼ëŸ¬ ì—…ë°ì´íŠ¸ - ê°œì„ ëœ ë²„ì „

        Parameters:
        -----------
        threshold : float
            íŠ¹ì„± ì¤‘ìš”ë„ ì„ê³„ê°’
        method : str
            íŠ¹ì„± ì„ íƒ ë°©ë²• ('importance' ë˜ëŠ” 'shap')
        top_n : int, optional
            ì„ íƒí•  ìƒìœ„ íŠ¹ì„± ìˆ˜ (ì§€ì • ì‹œ threshold ë¬´ì‹œ)
        """
        if self.model is None:
            raise ValueError("ë¨¼ì € train_model() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")

        # 1. ê°œì„ : ë‹¤ì–‘í•œ íŠ¹ì„± ì„ íƒ ë°©ë²• ì œê³µ
        if method == 'shap' and has_shap():
            try:
                import shap
                # SHAP ê°’ ê³„ì‚°
                explainer = shap.TreeExplainer(self.model)
                shap_values = explainer.shap_values(self.X_train)

                # ë¶„ë¥˜ ëª¨ë¸ì˜ ê²½ìš° ì²« ë²ˆì§¸ í´ë˜ìŠ¤ ë˜ëŠ” í‰ê·  SHAP ê°’ ì‚¬ìš©
                if isinstance(shap_values, list):
                    if self.prediction_type == 'classification':
                        shap_values = shap_values[1]  # ì–‘ì„± í´ë˜ìŠ¤ì˜ SHAP ê°’

                # íŠ¹ì„±ë³„ ì¤‘ìš”ë„ ê³„ì‚° (ì ˆëŒ€ê°’ í‰ê· )
                feature_importance = np.abs(shap_values).mean(axis=0)
                feature_importance = dict(zip(self.feature_names, feature_importance))

                print("SHAP ê¸°ë°˜ íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚° ì™„ë£Œ")
            except Exception as e:
                print(f"SHAP ê³„ì‚° ì˜¤ë¥˜, ê¸°ë³¸ ì¤‘ìš”ë„ ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´: {e}")
                feature_importance = dict(zip(self.feature_names, self.model.feature_importances_))
        else:
            # ê¸°ë³¸ íŠ¹ì„± ì¤‘ìš”ë„ ì‚¬ìš©
            feature_importance = dict(zip(self.feature_names, self.model.feature_importances_))

        # 2. ê°œì„ : top_n íŒŒë¼ë¯¸í„°ë¡œ ìƒìœ„ Nê°œ íŠ¹ì„± ì„ íƒ ì˜µì…˜ ì¶”ê°€
        if top_n is not None and top_n > 0:
            # ì¤‘ìš”ë„ìˆœìœ¼ë¡œ ìƒìœ„ Nê°œ íŠ¹ì„± ì„ íƒ
            sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
            top_n = min(top_n, len(sorted_features))  # íŠ¹ì„± ìˆ˜ ë³´ë‹¤ í¬ì§€ ì•Šë„ë¡
            selected_features = [f for f, _ in sorted_features[:top_n]]
            print(f"ìƒìœ„ {top_n}ê°œ ì¤‘ìš” íŠ¹ì„± ì„ íƒë¨")
        else:
            # ì„ê³„ê°’ ê¸°ë°˜ìœ¼ë¡œ íŠ¹ì„± ì„ íƒ
            selected_features = [f for f, imp in feature_importance.items()
                                if imp >= threshold]

            # 3. ê°œì„ : ìµœì†Œ íŠ¹ì„± ìˆ˜ ë³´ì¥
            if len(selected_features) < 10:
                # ìµœì†Œ 10ê°œ ì´ìƒì˜ íŠ¹ì„± ì„ íƒ
                sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
                selected_features = [f for f, _ in sorted_features[:max(10, len(selected_features))]]
                print(f"ì¤‘ìš” íŠ¹ì„±ì´ ì ì–´ ìƒìœ„ {len(selected_features)}ê°œ íŠ¹ì„± ì„ íƒ")

        print(f"ì„ íƒëœ ì¤‘ìš” íŠ¹ì„±: {len(selected_features)}/{len(self.feature_names)}")

        # 4. ê°œì„ : ì„ íƒëœ íŠ¹ì„±ì˜ ì¤‘ìš”ë„ ì¶œë ¥
        selected_importance = {f: feature_importance[f] for f in selected_features}
        sorted_selected = sorted(selected_importance.items(), key=lambda x: x[1], reverse=True)

        print("\nì„ íƒëœ íŠ¹ì„± ì¤‘ìš”ë„ (ìƒìœ„ 10ê°œ):")
        for feat, imp in sorted_selected[:10]:
            print(f"{feat}: {imp:.6f}")

        # ìŠ¤ì¼€ì¼ë§ë˜ì§€ ì•Šì€ ì›ë³¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        if hasattr(self, 'data_with_features'):
            df = self.data_with_features

            # íŠ¹ì„± ë° íƒ€ê²Ÿ ë¶„ë¦¬
            X_raw = df[self.feature_names]
            y = df['Target']

            # ì„ íƒëœ íŠ¹ì„±ë§Œ í•„í„°ë§
            X_raw_selected = X_raw[selected_features]

            # ì‹œê³„ì—´ ë¶„í•  (ì›ë³¸ prepare_dataì—ì„œì™€ ë™ì¼í•˜ê²Œ)
            test_size = 0.2
            split_idx = int(len(df) * (1 - test_size))
            X_train_raw = X_raw_selected.iloc[:split_idx]
            X_test_raw = X_raw_selected.iloc[split_idx:]
            y_train = y.iloc[:split_idx]
            y_test = y.iloc[split_idx:]

            # ìƒˆë¡œìš´ ìŠ¤ì¼€ì¼ëŸ¬ ìƒì„± ë° í•™ìŠµ
            self.scaler = StandardScaler()
            X_train_scaled = self.scaler.fit_transform(X_train_raw)
            X_test_scaled = self.scaler.transform(X_test_raw)

            # DataFrameìœ¼ë¡œ ë³€í™˜
            X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_raw.columns)
            X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_raw.columns)

            # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
            self.X_train = X_train_scaled
            self.X_test = X_test_scaled
            self.y_train = y_train
            self.y_test = y_test

            # íŠ¹ì„± ì´ë¦„ ì—…ë°ì´íŠ¸
            self.feature_names = selected_features

            # ëª¨ë¸ ì¬í•™ìŠµ
            print("íŠ¹ì„± ì„ íƒ í›„ ëª¨ë¸ ì¬í•™ìŠµ...")
            self.train_model(optimize=False)

            # 5. ê°œì„ : íŠ¹ì„± ì„ íƒ ì „í›„ ì„±ëŠ¥ ë¹„êµ
            if hasattr(self, 'test_accuracy') and hasattr(self, 'original_test_accuracy'):
                performance_change = self.test_accuracy - self.original_test_accuracy
                print(f"íŠ¹ì„± ì„ íƒ ì „í›„ ì„±ëŠ¥ ë³€í™”: {performance_change:.4f} ({performance_change * 100:.2f}%)")
        else:
            print("ê²½ê³ : ì›ë³¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ì—…ë°ì´íŠ¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.feature_names = selected_features

        return selected_features

    # ğŸ”§ XGBoost ë²„ì „ í˜¸í™˜ì„± ìˆ˜ì • - train_model ë©”ì„œë“œ ì™„ì „ êµì²´
    def train_model_fixed(self, optimize=True, n_iter=20, advanced_optimize=True):
        """XGBoost 2.1.4 GPU ì™„ì „ í˜¸í™˜ ë²„ì „"""
        
        if not hasattr(self, 'X_train'):
            raise ValueError("ë¨¼ì € prepare_data() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")

        print("ğŸ”¥ XGBoost 2.1.4 GPU ëª¨ë“œ í•™ìŠµ ì‹œì‘...")

        # í´ë˜ìŠ¤ ë¹„ìœ¨ í™•ì¸
        if self.prediction_type == 'classification':
            class_counts = self.y_train.value_counts()
            print(f"í•™ìŠµ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬: {dict(class_counts)}")
            if len(class_counts) > 1:
                scale_pos_weight = class_counts[0] / class_counts[1] if 1 in class_counts and 0 in class_counts else 1
            else:
                scale_pos_weight = 1
        else:
            scale_pos_weight = 1

        # ğŸ”¥ XGBoost 2.1.4 GPU íŒŒë¼ë¯¸í„°
        if self.prediction_type == 'classification':
            gpu_params = {
                'device': 'cuda',                    # âœ… í•µì‹¬!
                'tree_method': 'hist',               # âœ… í•µì‹¬!
                'objective': 'binary:logistic',
                'eval_metric': 'logloss',
                'learning_rate': 0.1,
                'n_estimators': 800,
                'max_depth': 8,
                'min_child_weight': 1,
                'subsample': 0.9,
                'colsample_bytree': 0.9,
                'gamma': 0,
                'reg_alpha': 0,
                'reg_lambda': 0.1,
                'scale_pos_weight': scale_pos_weight,
                'random_state': 42,
                'verbosity': 1,
                'n_jobs': 1,
                'max_bin': 512,
                'grow_policy': 'lossguide',
                'max_leaves': 1023
            }
            model = xgb.XGBClassifier(**gpu_params)
        else:
            gpu_params = {
                'device': 'cuda',
                'tree_method': 'hist',
                'objective': 'reg:squarederror',
                'eval_metric': 'rmse',
                'learning_rate': 0.1,
                'n_estimators': 800,
                'max_depth': 8,
                'min_child_weight': 1,
                'subsample': 0.9,
                'colsample_bytree': 0.9,
                'gamma': 0,
                'reg_alpha': 0,
                'reg_lambda': 0.1,
                'random_state': 42,
                'verbosity': 1,
                'n_jobs': 1,
                'max_bin': 512,
                'grow_policy': 'lossguide',
                'max_leaves': 1023
            }
            model = xgb.XGBRegressor(**gpu_params)

        print("âœ… GPU íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ")

        # ëª¨ë¸ í•™ìŠµ
        print("ğŸš€ GPU ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        
        try:
            eval_set = [(self.X_train, self.y_train), (self.X_test, self.y_test)]
            
            try:
                model = self.train_with_xgb_compatibility(model)
                print("âœ… XGBoost 2.1.4 ì½œë°± ë°©ì‹ ì„±ê³µ")
            except:
                model.fit(self.X_train, self.y_train)
                print("âœ… ê¸°ë³¸ í•™ìŠµ ì™„ë£Œ")
                
        except Exception as e:
            print(f"âš ï¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
            model.fit(self.X_train, self.y_train)

        # GPU ë©”ëª¨ë¦¬ í™•ì¸
        try:
            import torch
            if torch.cuda.is_available():
                memory_used = torch.cuda.memory_allocated(0) / 1024**2
                print(f"ğŸ”¥ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_used:.1f}MB")
        except:
            pass

        self.model = model

        # í…ŒìŠ¤íŠ¸ ì •í™•ë„ ê³„ì‚°
        if self.prediction_type == 'classification':
            from sklearn.metrics import accuracy_score
            y_pred = self.model.predict(self.X_test)
            self.test_accuracy = accuracy_score(self.y_test, y_pred)
        else:
            from sklearn.metrics import r2_score
            y_pred = self.model.predict(self.X_test)
            self.test_accuracy = r2_score(self.y_test, y_pred)

        print(f"ğŸ‰ GPU ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! í…ŒìŠ¤íŠ¸ ì •í™•ë„: {self.test_accuracy:.4f}")
        
        return model

    def evaluate_model(self):
        """
        ëª¨ë¸ ì„±ëŠ¥ í‰ê°€

        Returns:
        --------
        dict
            í‰ê°€ ì§€í‘œ
        """
        if self.model is None:
            raise ValueError("ë¨¼ì € train_model() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")

        print("ëª¨ë¸ í‰ê°€ ì¤‘...")

        # ì˜ˆì¸¡
        if self.prediction_type == 'classification':
            y_pred = self.model.predict(self.X_test)

            # AUC ê³„ì‚° ì‹œ ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€
            try:
                y_pred_proba = self.model.predict_proba(self.X_test)[:, 1]

                # í´ë˜ìŠ¤ê°€ í•˜ë‚˜ë§Œ ìˆëŠ”ì§€ í™•ì¸
                if len(np.unique(self.y_test)) < 2:
                    print("ê²½ê³ : í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— í´ë˜ìŠ¤ê°€ í•˜ë‚˜ë§Œ ìˆì–´ AUCë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    auc = 0.5  # ê¸°ë³¸ê°’ìœ¼ë¡œ 0.5 ì„¤ì •
                else:
                    auc = roc_auc_score(self.y_test, y_pred_proba)
            except Exception as e:
                print(f"AUC ê³„ì‚° ì˜¤ë¥˜: {e}")
                auc = 0.5  # ê¸°ë³¸ê°’ìœ¼ë¡œ 0.5 ì„¤ì •

            # ë‹¤ë¥¸ í‰ê°€ ì§€í‘œ ê³„ì‚° ì‹œì—ë„ ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€
            try:
                accuracy = accuracy_score(self.y_test, y_pred)
                precision = precision_score(self.y_test, y_pred, zero_division=0)
                recall = recall_score(self.y_test, y_pred, zero_division=0)
                f1 = f1_score(self.y_test, y_pred, zero_division=0)
            except Exception as e:
                print(f"í‰ê°€ ì§€í‘œ ê³„ì‚° ì˜¤ë¥˜: {e}")
                accuracy = precision = recall = f1 = 0

            # í‰ê°€ ê²°ê³¼ ì¶œë ¥
            print(f"ì •í™•ë„: {accuracy:.4f}")
            print(f"ì •ë°€ë„: {precision:.4f}")
            print(f"ì¬í˜„ìœ¨: {recall:.4f}")
            print(f"F1 ì ìˆ˜: {f1:.4f}")
            print(f"AUC: {auc:.4f}")

            # ë¶„ë¥˜ ë¦¬í¬íŠ¸
            try:
                print("\në¶„ë¥˜ ë¦¬í¬íŠ¸:")
                print(classification_report(self.y_test, y_pred))
            except Exception as e:
                print(f"ë¶„ë¥˜ ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")

            # í˜¼ë™ í–‰ë ¬ - ê·¸ë˜í”„ ìƒì„±í•˜ì§€ ì•ŠìŒ
            try:
                cm = confusion_matrix(self.y_test, y_pred)
                # ì½˜ì†”ì—ë§Œ ì¶œë ¥
                print("í˜¼ë™ í–‰ë ¬:")
                print(cm)
            except Exception as e:
                print(f"í˜¼ë™ í–‰ë ¬ ê³„ì‚° ì˜¤ë¥˜: {e}")

            # í…ŒìŠ¤íŠ¸ ì •í™•ë„ ì €ì¥
            self.test_accuracy = accuracy

            return {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'auc': auc
            }
        else:  # regression
            y_pred = self.model.predict(self.X_test)

            # í‰ê°€ ì§€í‘œ
            try:
                mse = mean_squared_error(self.y_test, y_pred)
                rmse = np.sqrt(mse)
                r2 = r2_score(self.y_test, y_pred)
            except Exception as e:
                print(f"í‰ê°€ ì§€í‘œ ê³„ì‚° ì˜¤ë¥˜: {e}")
                mse = rmse = 0
                r2 = 0

            # í‰ê°€ ê²°ê³¼ ì¶œë ¥
            print(f"MSE: {mse:.4f}")
            print(f"RMSE: {rmse:.4f}")
            print(f"R2 ì ìˆ˜: {r2:.4f}")

            # í…ŒìŠ¤íŠ¸ ì •í™•ë„ (R2) ì €ì¥
            self.test_accuracy = r2

            return {
                'mse': mse,
                'rmse': rmse,
                'r2': r2
            }

    def plot_feature_importance(self, top_n=20):
        """
        íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”

        Parameters:
        -----------
        top_n : int
            í‘œì‹œí•  ìƒìœ„ íŠ¹ì„± ìˆ˜
        """
        if self.model is None:
            raise ValueError("ë¨¼ì € train_model() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")

        # íŠ¹ì„± ì¤‘ìš”ë„ ì¶”ì¶œ
        importance = self.model.feature_importances_
        indices = np.argsort(importance)[::-1]

        # ìƒìœ„ Nê°œ íŠ¹ì„± ì„ íƒ
        if top_n > len(self.feature_names):
            top_n = len(self.feature_names)

        top_indices = indices[:top_n]
        top_features = [self.feature_names[i] for i in top_indices]
        top_importance = importance[top_indices]

        # ì‹œê°í™”
        plt.figure(figsize=(12, 8))
        plt.barh(range(top_n), top_importance, align='center')
        plt.yticks(range(top_n), top_features)
        plt.xlabel('ì¤‘ìš”ë„')
        plt.title(f'ìƒìœ„ {top_n}ê°œ íŠ¹ì„± ì¤‘ìš”ë„')
        plt.gca().invert_yaxis()  # ì¤‘ìš”ë„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        plt.tight_layout()
        # plt.show()

        # ì¤‘ìš”ë„ ì •ë³´ ë°˜í™˜
        return dict(zip(top_features, top_importance))

    def enhanced_prediction(self, days=1, ensemble=True, bootstrap_samples=10):
        """í–¥ìƒëœ ì‹ ë¢°ë„ì™€ ì •í™•ë„ë¥¼ ì œê³µí•˜ëŠ” ì˜ˆì¸¡ ë©”ì„œë“œ - ê°œì„ ëœ ë²„ì „"""
        # ê¸°ë³¸ ì˜ˆì¸¡ ìˆ˜í–‰
        base_prediction = self.predict_future(days)

        if self.prediction_type != 'classification':
            return base_prediction  # íšŒê·€ ëª¨ë¸ì€ ê¸°ë³¸ ì˜ˆì¸¡ë§Œ ìˆ˜í–‰

        # ìµœì‹  ë°ì´í„°
        latest_data = self.data_with_features.iloc[-1]
        features = latest_data[self.feature_names].values.reshape(1, -1)
        features_scaled = self.scaler.transform(features)

        # 1. ì•™ìƒë¸” ì˜ˆì¸¡ (ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œë§)
        if ensemble and bootstrap_samples > 1:
            ensemble_predictions = []

            for _ in range(bootstrap_samples):
                # ë°ì´í„° ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œë§
                n_samples = len(self.X_train)
                indices = np.random.choice(n_samples, n_samples, replace=True)
                X_boot = self.X_train.iloc[indices] if isinstance(self.X_train, pd.DataFrame) else self.X_train[indices]
                y_boot = self.y_train.iloc[indices] if isinstance(self.y_train, pd.Series) else self.y_train[indices]

                # ë¶€íŠ¸ìŠ¤íŠ¸ë© ëª¨ë¸ í•™ìŠµ
                boot_model = xgb.XGBClassifier(**self.model.get_params())
                boot_model.fit(X_boot, y_boot)

                # ì˜ˆì¸¡
                boot_proba = boot_model.predict_proba(features_scaled)[0, 1]
                ensemble_predictions.append(boot_proba)

            # ì•™ìƒë¸” ê²°ê³¼ ê³„ì‚°
            ensemble_mean = np.mean(ensemble_predictions)
            ensemble_std = np.std(ensemble_predictions)

            print(f"ì•™ìƒë¸” ì˜ˆì¸¡ (í‰ê· ): {ensemble_mean:.4f}")
            print(f"ì•™ìƒë¸” ë¶ˆí™•ì‹¤ì„± (í‘œì¤€í¸ì°¨): {ensemble_std:.4f}")

            # ì•™ìƒë¸” ì‹ ë¢° êµ¬ê°„
            conf_level = 0.9
            z_score = 1.645  # 90% ì‹ ë¢° êµ¬ê°„
            lower = max(0, ensemble_mean - z_score * ensemble_std)
            upper = min(1, ensemble_mean + z_score * ensemble_std)

            print(f"90% ì‹ ë¢° êµ¬ê°„: [{lower:.4f}, {upper:.4f}]")

            # ê¸°ë³¸ ì˜ˆì¸¡ ì—…ë°ì´íŠ¸
            base_confidence = base_prediction['Confidence'].iloc[0]

            # ì•™ìƒë¸” ê²°ê³¼ì™€ ê¸°ë³¸ ì˜ˆì¸¡ ê²°í•© (ê°€ì¤‘í‰ê· )
            adjusted_confidence = 0.7 * ensemble_mean + 0.3 * base_confidence
        else:
            adjusted_confidence = base_prediction['Confidence'].iloc[0]

        # 2. ë‹¤ì¤‘ ê¸°ê°„ ì‹ í˜¸ì˜ ì¼ê´€ì„± í™•ì¸
        multi_period_consistent = True
        try:
            # ì—¬ëŸ¬ ê¸°ê°„ì˜ ê³¼ê±° ì˜ˆì¸¡ ì¼ê´€ì„± í™•ì¸
            for lookback in [0, 1, 2, 3]:
                if lookback > 0 and len(self.data_with_features) > lookback:
                    past_data = self.data_with_features.iloc[-(lookback+1)]
                    past_features = past_data[self.feature_names].values.reshape(1, -1)
                    past_features_scaled = self.scaler.transform(past_features)
                    past_proba = self.model.predict_proba(past_features_scaled)[0, 1]

                    # í˜„ì¬ ì˜ˆì¸¡ê³¼ ê³¼ê±° ì˜ˆì¸¡ì˜ ë°©í–¥ ì¼ì¹˜ ì—¬ë¶€
                    current_bullish = adjusted_confidence > 0.5
                    past_bullish = past_proba > 0.5

                    if current_bullish != past_bullish:
                        multi_period_consistent = False
                        break
        except:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¬´ì‹œ
            pass

        # 3. ì‹œì¥ ìƒíƒœ í™•ì¸
        recent_data = self.data_with_features.tail(20)
        market_trend = recent_data['Close'].pct_change().mean() > 0
        market_vol = recent_data['Return'].std()

        # ì¼ê´€ì„± ë° ì‹œì¥ ìƒíƒœì— ë”°ë¥¸ í™•ì‹ ë„ ì¡°ì •
        adjusted_confidence_original = adjusted_confidence

        # ì‹œì¥ ì¶”ì„¸ì™€ ì˜ˆì¸¡ ë°©í–¥ì´ ì¼ì¹˜í•˜ë©´ í™•ì‹ ë„ ìƒìŠ¹
        prediction = 1 if adjusted_confidence > 0.5 else 0
        if (market_trend and prediction == 1) or (not market_trend and prediction == 0):
            adjustment_factor = 1.15  # 15% ìƒìŠ¹
        else:
            adjustment_factor = 0.9  # 10% ê°ì†Œ

        # ë³€ë™ì„± ì ìš©
        vol_factor = 1.0
        if market_vol > 0.03:  # 3% ì´ìƒ ë³€ë™ì„±
            vol_factor = 0.9  # 10% ê°ì†Œ
        elif market_vol < 0.01:  # 1% ë¯¸ë§Œ ë³€ë™ì„±
            vol_factor = 1.1  # 10% ìƒìŠ¹

        # ì¼ê´€ì„± ì ìš©
        consistency_factor = 1.1 if multi_period_consistent else 0.95

        # ì¡°ì •ëœ í™•ì‹ ë„ ê³„ì‚°
        adjusted_confidence = adjusted_confidence * adjustment_factor * vol_factor * consistency_factor

        # ë²”ìœ„ ë‚´ë¡œ ì¡°ì •
        if prediction == 1:
            adjusted_confidence = min(0.99, max(0.51, adjusted_confidence))
        else:
            adjusted_confidence = min(0.49, max(0.01, adjusted_confidence))

        # 4. ê¸°ìˆ ì  ì§€í‘œ í™•ì¸
        tech_confirmation = 0
        try:
            confirmations = self._check_technical_indicators()
            tech_confirmation = sum(confirmations.values())

            # ê¸°ìˆ ì  ì§€í‘œ ì¼ì¹˜ë„ì— ë”°ë¥¸ í™•ì‹ ë„ ì¡°ì •
            if tech_confirmation >= len(confirmations) * 0.7:  # 70% ì´ìƒ ì¼ì¹˜
                adjusted_confidence = adjusted_confidence * 1.1  # 10% ìƒìŠ¹
                # ë²”ìœ„ ë‚´ë¡œ ì¡°ì •
                if prediction == 1:
                    adjusted_confidence = min(0.99, adjusted_confidence)
                else:
                    adjusted_confidence = max(0.01, adjusted_confidence)
        except:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¬´ì‹œ
            pass

        # 5. ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ì—…ë°ì´íŠ¸
        enhanced_pred = base_prediction.copy()
        enhanced_pred['Confidence'].iloc[0] = adjusted_confidence

        # ì¡°ì • ì›ì¸ ì„¤ëª…
        print(f"\ní™•ì‹ ë„ ì¡°ì •: {adjusted_confidence_original:.4f} â†’ {adjusted_confidence:.4f}")
        print(f"- ì‹œì¥ ì¶”ì„¸ ì˜í–¥: {'ì¼ì¹˜' if (market_trend and prediction == 1) or (not market_trend and prediction == 0) else 'ë¶ˆì¼ì¹˜'}")
        print(f"- ë³€ë™ì„± ì˜í–¥: {market_vol:.4f} ({'ë†’ìŒ' if market_vol > 0.03 else 'ë³´í†µ' if market_vol > 0.01 else 'ë‚®ìŒ'})")
        print(f"- ê¸°ê°„ ì¼ê´€ì„±: {'ìˆìŒ' if multi_period_consistent else 'ì—†ìŒ'}")
        print(f"- ê¸°ìˆ ì  ì§€í‘œ í™•ì¸: {tech_confirmation}/{len(confirmations) if 'confirmations' in locals() and confirmations else 0}")

        # 6. ë§¤ìš° ê°•í•œ ì‹ í˜¸ì¼ ê²½ìš° ì¶”ê°€ í‘œì‹œ
        strong_signal = adjusted_confidence > 0.8 or adjusted_confidence < 0.2
        if strong_signal:
            strength = "ë§¤ìš° ê°•í•œ ë§¤ìˆ˜" if adjusted_confidence > 0.8 else "ë§¤ìš° ê°•í•œ ë§¤ë„"
            print(f"\n{strength} ì‹ í˜¸ ê°ì§€: {adjusted_confidence:.2f} í™•ì‹ ë„")

        # 7. ìœ„í—˜ í‰ê°€
        if hasattr(self, 'backtest_results'):
            risk_level = "ë†’ìŒ" if self.backtest_results.get('max_drawdown', 0) < -0.1 else "ì¤‘ê°„"
            print(f"ìœ„í—˜ ìˆ˜ì¤€: {risk_level} (ìµœëŒ€ ì†ì‹¤: {self.backtest_results.get('max_drawdown', 0):.2%})")

        return enhanced_pred

    def backtest(self, initial_capital=10000, transaction_cost=0.001, stop_loss=0.03, take_profit=0.05):
        """ë°±í…ŒìŠ¤íŠ¸ ìˆ˜í–‰ - ê°œì„ ëœ ë²„ì „"""
        if self.model is None:
            raise ValueError("ë¨¼ì € train_model() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")

        print("ë°±í…ŒìŠ¤íŠ¸ ìˆ˜í–‰ ì¤‘...")

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        test_data = self.data_with_features.iloc[-len(self.X_test):].reset_index(drop=True)

        # 1. ê°œì„ : ì´ë™ ìœˆë„ìš° ë°©ì‹ìœ¼ë¡œ ë” í˜„ì‹¤ì ì¸ ì˜ˆì¸¡
        if len(test_data) > 50:  # ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ìˆì„ ê²½ìš°
            use_walk_forward = True
            print("ì´ë™ ìœˆë„ìš° ë°±í…ŒìŠ¤íŠ¸ ë°©ì‹ ì‚¬ìš©")
        else:
            use_walk_forward = False

        # ì˜ˆì¸¡
        if self.prediction_type == 'classification':
            if use_walk_forward:
                # ì´ë™ ìœˆë„ìš° ì˜ˆì¸¡
                window_size = 30  # ì´ˆê¸° í•™ìŠµ ê¸°ê°„
                test_proba = np.zeros(len(test_data))

                for i in range(window_size, len(test_data)):
                    # í˜„ì¬ ë°ì´í„°ê¹Œì§€ í•™ìŠµ
                    train_window = self.data_with_features.iloc[:-(len(test_data)-i)]
                    window_model = xgb.XGBClassifier(**self.model.get_params())

                    # íŠ¹ì„± ë° íƒ€ê²Ÿ ì¤€ë¹„
                    X_win = train_window[self.feature_names]
                    y_win = train_window['Target']

                    # NaN ì²˜ë¦¬
                    X_win = X_win.fillna(0)

                    # ìŠ¤ì¼€ì¼ë§
                    scaler = StandardScaler()
                    X_win_scaled = scaler.fit_transform(X_win)

                    # ëª¨ë¸ í•™ìŠµ
                    window_model.fit(X_win_scaled, y_win)

                    # í˜„ì¬ ë°ì´í„°í¬ì¸íŠ¸ ì˜ˆì¸¡
                    current_features = test_data.iloc[i][self.feature_names].values.reshape(1, -1)
                    current_scaled = scaler.transform(current_features)
                    test_proba[i] = window_model.predict_proba(current_scaled)[0, 1]

                # ì˜ˆì¸¡ê°’ ì €ì¥
                test_data['PredictionProba'] = test_proba
                test_data['Prediction'] = (test_data['PredictionProba'] > 0.5).astype(int)
                test_data['Signal'] = (test_data['PredictionProba'] > self.confidence_threshold).astype(int)
            else:
                # ê¸°ë³¸ ì˜ˆì¸¡ ë°©ì‹
                test_data['PredictionProba'] = self.model.predict_proba(self.X_test)[:, 1]
                test_data['Prediction'] = (test_data['PredictionProba'] > 0.5).astype(int)
                test_data['Signal'] = (test_data['PredictionProba'] > self.confidence_threshold).astype(int)
        else:  # regression
            if use_walk_forward:
                # ì´ë™ ìœˆë„ìš° ì˜ˆì¸¡ (íšŒê·€ ëª¨ë¸ìš©)
                window_size = 30
                test_pred = np.zeros(len(test_data))

                for i in range(window_size, len(test_data)):
                    # ì´í•˜ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„
                    pass
            else:
                # ê¸°ë³¸ ì˜ˆì¸¡ ë°©ì‹
                test_data['Prediction'] = self.model.predict(self.X_test)
                # ë‹¤ìŒ ì˜ˆì¸¡ ê°€ê²©ì´ í˜„ì¬ ê°€ê²©ë³´ë‹¤ ë†’ìœ¼ë©´ ë§¤ìˆ˜ ì‹ í˜¸
                test_data['Signal'] = (test_data['Prediction'] > test_data['Close']).astype(int)

        # 2. ê°œì„ : í™•ì‹ ë„ì— ë”°ë¥¸ í¬ì§€ì…”ë‹ ì‚¬ì´ì¦ˆ ì¡°ì •
        test_data['Position'] = test_data['Signal'].shift(1).fillna(0).astype(int)

        # í™•ì‹ ë„ ê¸°ë°˜ í¬ì§€ì…˜ ì‚¬ì´ì¦ˆ (0.6~1.0)
        if self.prediction_type == 'classification':
            # 0.5~1.0 ë²”ìœ„ì˜ í™•ì‹ ë„ì— ë”°ë¼ 0.6~1.0 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§
            test_data['PositionSize'] = test_data['PredictionProba'].apply(
                lambda x: 0.6 + 0.4 * (2 * abs(x - 0.5)) if x >= 0.5 else 0
            ).shift(1).fillna(0)
        else:
            # íšŒê·€ ëª¨ë¸ì˜ ê²½ìš° ì˜ˆì¸¡ëœ ìˆ˜ìµë¥ ì˜ í¬ê¸°ì— ë”°ë¼ í¬ì§€ì…˜ ì‚¬ì´ì¦ˆ ì¡°ì •
            expected_return = (test_data['Prediction'] / test_data['Close'] - 1)
            test_data['PositionSize'] = expected_return.apply(
                lambda x: min(1.0, max(0.6, 0.6 + 0.4 * min(1, x / 0.05))) if x > 0 else 0
            ).shift(1).fillna(0)

        # ìˆ˜ìµë¥  ê³„ì‚°
        test_data['Returns'] = test_data['Close'] / test_data['Close'].shift(1) - 1
        test_data['Strategy_Returns'] = test_data['Position'] * test_data['PositionSize'] * test_data['Returns']

        # 3. ê°œì„ : ì†ì ˆ/ìµì ˆ ë¡œì§ ì¶”ê°€
        if stop_loss > 0 or take_profit > 0:
            # ì†ì ˆ/ìµì ˆ ì ìš©
            positions = []  # í˜„ì¬ í¬ì§€ì…˜ ì¶”ì 
            entry_prices = []  # ì§„ì… ê°€ê²© ì¶”ì 

            for i in range(len(test_data)):
                if i == 0:
                    positions.append(0)
                    entry_prices.append(0)
                    continue

                prev_position = positions[-1]
                prev_entry = entry_prices[-1]

                # ìƒˆ í¬ì§€ì…˜ ì‹œê·¸ë„
                new_position = test_data['Position'].iloc[i]
                position_size = test_data['PositionSize'].iloc[i]

                if prev_position == 0 and new_position > 0:
                    # ìƒˆë¡œìš´ ë§¤ìˆ˜ ì§„ì…
                    positions.append(new_position)
                    entry_prices.append(test_data['Close'].iloc[i])
                elif prev_position > 0:
                    current_price = test_data['Close'].iloc[i]
                    returns = current_price / prev_entry - 1

                    # ì†ì ˆ/ìµì ˆ ì¡°ê±´ í™•ì¸
                    if returns <= -stop_loss or returns >= take_profit:
                        # í¬ì§€ì…˜ ì²­ì‚°
                        positions.append(0)
                        entry_prices.append(0)

                        # ì‹¤ì œ ìˆ˜ìµë¥  ì—…ë°ì´íŠ¸
                        test_data.loc[i, 'Strategy_Returns'] = (
                            prev_position * position_size * returns - transaction_cost
                        )
                    else:
                        # í¬ì§€ì…˜ ìœ ì§€
                        positions.append(new_position)
                        entry_prices.append(prev_entry)
                else:
                    # ì´ì „ê³¼ ë™ì¼í•œ í¬ì§€ì…˜ ìœ ì§€
                    positions.append(new_position)
                    entry_prices.append(
                        prev_entry if new_position == prev_position else
                        (test_data['Close'].iloc[i] if new_position > 0 else 0)
                    )

            test_data['Actual_Position'] = positions
            test_data['Entry_Price'] = entry_prices

            # ìµœì¢… ì „ëµ ìˆ˜ìµë¥  ì—…ë°ì´íŠ¸
            test_data['Strategy_Returns_SL_TP'] = test_data['Actual_Position'] * test_data['PositionSize'] * test_data['Returns']

            # ì†ì ˆ/ìµì ˆ ì´ë²¤íŠ¸ ì¶”ì 
            test_data['Stop_Loss'] = ((test_data['Actual_Position'].shift(1) > 0) &
                                (test_data['Actual_Position'] == 0) &
                                (test_data['Close'] < test_data['Entry_Price'].shift(1) * (1 - stop_loss)))

            test_data['Take_Profit'] = ((test_data['Actual_Position'].shift(1) > 0) &
                                    (test_data['Actual_Position'] == 0) &
                                    (test_data['Close'] > test_data['Entry_Price'].shift(1) * (1 + take_profit)))

            # ì†ì ˆ/ìµì ˆ í›„ ì „ëµ ìˆ˜ìµë¥  ì‚¬ìš©
            test_data['Strategy_Returns'] = test_data['Strategy_Returns_SL_TP']

        # 4. ê°œì„ : ê±°ë˜ ë¹„ìš© ê³„ì‚° ì •êµí™”
        # ê±°ë˜ ë°œìƒ ì‹œì  íŒŒì•…
        test_data['Trade'] = test_data['Position'].diff().abs()

        # ë§¤ìˆ˜/ë§¤ë„ ì‹œ ë‹¤ë¥¸ ê±°ë˜ ë¹„ìš© ì ìš© (ë§¤ë„ ì‹œ ë” ë†’ì€ ë¹„ìš©)
        buy_cost = transaction_cost
        sell_cost = transaction_cost * 1.2  # ë§¤ë„ ì‹œ ì•½ê°„ ë” ë†’ì€ ë¹„ìš©

        test_data['Buy'] = ((test_data['Position'].diff() > 0)).astype(int)
        test_data['Sell'] = ((test_data['Position'].diff() < 0)).astype(int)

        test_data['Cost'] = (test_data['Buy'] * buy_cost + test_data['Sell'] * sell_cost) * test_data['PositionSize']
        test_data['Strategy_Returns_Net'] = test_data['Strategy_Returns'] - test_data['Cost']

        # 5. ê°œì„ : ëˆ„ì  ìˆ˜ìµ ë° ë“œë¡œë‹¤ìš´ ê³„ì‚°
        test_data['Cumulative_Returns'] = (1 + test_data['Returns']).cumprod()
        test_data['Strategy_Cumulative_Returns'] = (1 + test_data['Strategy_Returns_Net']).cumprod()

        # ë“œë¡œë‹¤ìš´ ê³„ì‚°
        test_data['BuyHold_Peak'] = test_data['Cumulative_Returns'].cummax()
        test_data['Strategy_Peak'] = test_data['Strategy_Cumulative_Returns'].cummax()

        test_data['BuyHold_Drawdown'] = (test_data['Cumulative_Returns'] / test_data['BuyHold_Peak'] - 1)
        test_data['Strategy_Drawdown'] = (test_data['Strategy_Cumulative_Returns'] / test_data['Strategy_Peak'] - 1)

        # 6. ê°œì„ : ë°±í…ŒìŠ¤íŠ¸ ì„±ê³¼ ì§€í‘œ í™•ì¥
        # ê¸°ë³¸ ì„±ê³¼ ì§€í‘œ
        total_return = test_data['Strategy_Cumulative_Returns'].iloc[-1] - 1
        buy_hold_return = test_data['Cumulative_Returns'].iloc[-1] - 1

        # ì—°ê°„ ìˆ˜ìµë¥ 
        days = (test_data['Date'].iloc[-1] - test_data['Date'].iloc[0]).days
        annual_return = (1 + total_return) ** (365 / max(days, 1)) - 1
        buy_hold_annual = (1 + buy_hold_return) ** (365 / max(days, 1)) - 1

        # ìƒ¤í”„ ë¹„ìœ¨
        daily_returns = test_data['Strategy_Returns_Net']
        daily_risk_free = 0.03 / 252  # ì—° 3% ë¬´ìœ„í—˜ ìˆ˜ìµë¥  ê°€ì •
        excess_returns = daily_returns - daily_risk_free
        sharpe_ratio = np.sqrt(252) * excess_returns.mean() / max(daily_returns.std(), 1e-6)

        # ì¹¼ë§ˆ ë¹„ìœ¨ (Calmar Ratio) - ì—°ê°„ ìˆ˜ìµë¥  / ìµœëŒ€ ë‚™í­
        max_drawdown = test_data['Strategy_Drawdown'].min()
        calmar_ratio = annual_return / abs(max_drawdown) if max_drawdown < 0 else float('inf')

        # ìŠ¹ë¥  ë° ì†ìµë¹„
        profitable_trades = test_data[test_data['Position'] == 1]['Returns'] > 0
        win_rate = profitable_trades.mean() if len(profitable_trades) > 0 else 0

        # í‰ê·  ìˆ˜ìµ/ì†ì‹¤ ë¹„ìœ¨
        avg_win = test_data.loc[test_data['Position'] == 1, 'Returns'][
            test_data.loc[test_data['Position'] == 1, 'Returns'] > 0
        ].mean() if len(profitable_trades[profitable_trades]) > 0 else 0

        avg_loss = test_data.loc[test_data['Position'] == 1, 'Returns'][
            test_data.loc[test_data['Position'] == 1, 'Returns'] < 0
        ].mean() if len(profitable_trades[~profitable_trades]) > 0 else 0

        profit_loss_ratio = abs(avg_win / avg_loss) if avg_loss < 0 else float('inf')

        # ìµœëŒ€ ì—°ì† ì†ì‹¤/ì´ìµ
        consecutive_wins = 0
        consecutive_losses = 0
        max_consecutive_wins = 0
        max_consecutive_losses = 0

        for i in range(len(test_data)):
            if test_data['Position'].iloc[i] == 1:
                if test_data['Returns'].iloc[i] > 0:
                    consecutive_wins += 1
                    consecutive_losses = 0
                elif test_data['Returns'].iloc[i] < 0:
                    consecutive_losses += 1
                    consecutive_wins = 0

                max_consecutive_wins = max(max_consecutive_wins, consecutive_wins)
                max_consecutive_losses = max(max_consecutive_losses, consecutive_losses)

        # ì¼í‰ê·  ê°€ê²© ë³€ë™í­ ê³„ì‚°
        try:
            avg_daily_range = ((test_data['High'] - test_data['Low']) / test_data['Close']).mean()
        except Exception as e:
            print(f"ì¼í‰ê·  ë³€ë™í­ ê³„ì‚° ì˜¤ë¥˜: {e}")
            avg_daily_range = 0.03  # ê¸°ë³¸ê°’ìœ¼ë¡œ 3% ì„¤ì •

        # 7. ê°œì„ : ê²°ê³¼ ì‹œê°í™” ë° ì¶œë ¥
        print(f"\n===== ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ =====")
        print(f"ì´ ìˆ˜ìµë¥ : {total_return:.4f} ({total_return * 100:.2f}%) vs. ë§¤ìˆ˜ í›„ ë³´ìœ : {buy_hold_return:.4f} ({buy_hold_return * 100:.2f}%)")
        print(f"ì—°ê°„ ìˆ˜ìµë¥ : {annual_return:.4f} ({annual_return * 100:.2f}%) vs. ë§¤ìˆ˜ í›„ ë³´ìœ : {buy_hold_annual:.4f} ({buy_hold_annual * 100:.2f}%)")
        print(f"ìƒ¤í”„ ë¹„ìœ¨: {sharpe_ratio:.4f}")
        print(f"ì¹¼ë§ˆ ë¹„ìœ¨: {calmar_ratio:.4f}")
        print(f"ìµœëŒ€ ì†ì‹¤: {max_drawdown:.4f} ({max_drawdown * 100:.2f}%)")
        print(f"ìŠ¹ë¥ : {win_rate:.4f} ({win_rate * 100:.2f}%)")
        print(f"ì†ìµë¹„: {profit_loss_ratio:.2f}")
        print(f"ìµœëŒ€ ì—°ì† ì´ìµ: {max_consecutive_wins}, ìµœëŒ€ ì—°ì† ì†ì‹¤: {max_consecutive_losses}")
        print(f"ì´ ê±°ë˜ íšŸìˆ˜: {test_data['Trade'].sum() / 2:.0f}")

        if 'Stop_Loss' in test_data and 'Take_Profit' in test_data:
            sl_count = test_data['Stop_Loss'].sum()
            tp_count = test_data['Take_Profit'].sum()
            print(f"ì†ì ˆ íšŸìˆ˜: {sl_count}, ìµì ˆ íšŸìˆ˜: {tp_count}")

        # ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
        self.backtest_results = {
            'total_return': total_return,
            'buy_hold_return': buy_hold_return,
            'annual_return': annual_return,
            'sharpe_ratio': sharpe_ratio,
            'calmar_ratio': calmar_ratio,
            'max_drawdown': max_drawdown,
            'win_rate': win_rate,
            'profit_loss_ratio': profit_loss_ratio,
            'max_consecutive_wins': max_consecutive_wins,
            'max_consecutive_losses': max_consecutive_losses,
            'trade_count': test_data['Trade'].sum() / 2,
            'avg_daily_range': avg_daily_range,
            'test_data': test_data  # ë¶„ì„ì„ ìœ„í•´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥
        }

        return self.backtest_results

def get_financial_info(stock_code):
        """
        ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ì¬ë¬´ì •ë³´ ìŠ¤í¬ë˜í•‘

        Parameters:
        -----------
        stock_code : str
            ì¢…ëª© ì½”ë“œ

        Returns:
        --------
        dict
            ì¬ë¬´ ì •ë³´ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        """
        import requests
        from bs4 import BeautifulSoup
        import pandas as pd

        try:
            # ë„¤ì´ë²„ ê¸ˆìœµ ì¢…ëª© í˜ì´ì§€ URL
            url = f"https://finance.naver.com/item/main.naver?code={stock_code}"

            # í˜ì´ì§€ ìš”ì²­
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
            response = requests.get(url, headers=headers)
            response.encoding = 'euc-kr'

            # BeautifulSoupë¡œ HTML íŒŒì‹±
            soup = BeautifulSoup(response.text, 'html.parser')

            # ì¬ë¬´ì •ë³´ ì¶”ì¶œ
            financial_info = {}

            # íˆ¬ìì§€í‘œ í…Œì´ë¸”
            finance_table = soup.select('#tab_con1 > div:nth-child(3) > table > tbody > tr')

            # PER, PBR, ROE ë“± ê¸°ë³¸ íˆ¬ìì§€í‘œ ì¶”ì¶œ
            for row in finance_table:
                th_tags = row.find_all('th')
                td_tags = row.find_all('td', class_='num')

                if len(th_tags) > 0 and len(td_tags) > 0:
                    indicator_name = th_tags[0].text.strip()
                    # ê°€ì¥ ìµœê·¼ ë¶„ê¸° ë°ì´í„° ì‚¬ìš©
                    indicator_value = td_tags[0].text.strip().replace('%', '').replace(',', '')

                    try:
                        indicator_value = float(indicator_value)
                        financial_info[indicator_name] = indicator_value
                    except:
                        pass

            # ë” ë§ì€ ì •ë³´ê°€ í•„ìš”í•˜ë©´ ì—¬ê¸°ì— ì¶”ê°€ ìŠ¤í¬ë˜í•‘ ì½”ë“œ ì‘ì„±
            # ì˜ˆ: ë§¤ì¶œì•¡, ì˜ì—…ì´ìµ, ìˆœì´ìµ ë“±

            return financial_info

        except Exception as e:
            print(f"ì¬ë¬´ì •ë³´ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
            return {}

def create_ensemble_model(stock_code, period='2y', prediction_period=5):
        """
        ì¬ë¬´ì •ë³´ì™€ ê¸°ìˆ ì  ì§€í‘œë¥¼ ê²°í•©í•œ ì•™ìƒë¸” ëª¨ë¸ ìƒì„±

        Parameters:
        -----------
        stock_code : str
            ì¢…ëª© ì½”ë“œ
        period : str
            ë¶„ì„ ê¸°ê°„
        prediction_period : int
            ì˜ˆì¸¡ ê¸°ê°„

        Returns:
        --------
        dict
            ì•™ìƒë¸” ì˜ˆì¸¡ ê²°ê³¼
        """
        # ì£¼ê°€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        import yfinance as yf
        ticker = f"{stock_code}.KS"
        session = requests.Session(impersonate="chrome")
        stock = yf.Ticker(ticker,session=session)
        df = stock.history(period=period)
        df.reset_index(inplace=True)

        # 1. ê¸°ìˆ ì  ì§€í‘œ ëª¨ë¸
        tech_model = StockPredictionModel(prediction_period=prediction_period)
        tech_model.load_data(df=df)
        tech_model.create_features(advanced=True)
        tech_model.prepare_data(test_size=0.2)
        tech_model.train_model(optimize=True, n_iter=10)
        tech_model.select_important_features(threshold=0.01)
        tech_prediction = tech_model.predict_future()

        # 2. ì¬ë¬´ ì •ë³´ í™œìš© ëª¨ë¸
        financial_model = StockPredictionModel(prediction_period=prediction_period)
        financial_model.load_data(df=df)
        financial_model.create_features(advanced=True, stock_code=stock_code)
        financial_model.prepare_data(test_size=0.2)
        financial_model.train_model(optimize=True, n_iter=10)
        financial_model.select_important_features(threshold=0.01)
        financial_prediction = financial_model.predict_future()

        # 3. ì•™ìƒë¸” (ê°€ì¤‘ í‰ê· )
        tech_pred = tech_prediction['Prediction'].iloc[0]
        tech_conf = tech_prediction['Confidence'].iloc[0]
        fin_pred = financial_prediction['Prediction'].iloc[0]
        fin_conf = financial_prediction['Confidence'].iloc[0]

        # ê¸°ìˆ ì  ì§€í‘œì™€ ì¬ë¬´ ì •ë³´ì˜ ê°€ì¤‘ì¹˜ ì„¤ì • (60:40)
        ensemble_pred = tech_pred * 0.6 + fin_pred * 0.4
        ensemble_conf = tech_conf * 0.6 + fin_conf * 0.4

        final_prediction = 1 if ensemble_pred > 0.5 else 0
        final_confidence = ensemble_conf if final_prediction == 1 else 1 - ensemble_conf

        return {
            'prediction': final_prediction,
            'confidence': final_confidence,
            'tech_prediction': tech_pred,
            'tech_confidence': tech_conf,
            'fin_prediction': fin_pred,
            'fin_confidence': fin_conf
        }

def create_enhanced_ensemble_model(stock_code, period='2y', prediction_period=5):
    """ë‹¤ì¤‘ ëª¨ë¸ ë° ì‹œì  ì•™ìƒë¸”ë¡œ ì •í™•ë„ í–¥ìƒ"""
    # ì£¼ê°€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    import yfinance as yf
    ticker = f"{stock_code}.KS"
    session = requests.Session(impersonate="chrome")
    stock = yf.Ticker(ticker,session=session)
    df = stock.history(period=period)
    df.reset_index(inplace=True)

    # ë‹¤ì–‘í•œ ì˜ˆì¸¡ ê¸°ê°„ì˜ ëª¨ë¸ ê²°ê³¼ ìˆ˜ì§‘
    period_results = []
    for pred_period in [1, 3, 5, 10]:
        # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
        model = StockPredictionModel(prediction_period=pred_period)
        model.load_data(df=df)
        model.create_features(advanced=True, stock_code=stock_code if pred_period == prediction_period else None)
        model.prepare_data(test_size=0.2)
        # ë¹ ë¥¸ í•™ìŠµ (ì£¼ê¸°ê°„ë§Œ ìµœì í™”)
        optimize = (pred_period == prediction_period)
        model.train_model(optimize=optimize, n_iter=10 if optimize else 5)

        if optimize:
            model.select_important_features(threshold=0.01)

        # í–¥ìƒëœ ì˜ˆì¸¡ ìˆ˜í–‰
        if hasattr(model, 'enhanced_prediction'):
            prediction = model.enhanced_prediction()
        else:
            prediction = model.predict_future()

        # ê²°ê³¼ ì €ì¥
        pred = prediction['Prediction'].iloc[0]
        conf = prediction['Confidence'].iloc[0]

        # ì˜ˆì¸¡ ê¸°ê°„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì„¤ì • (ì£¼ ê¸°ê°„ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
        weight = 2.0 if pred_period == prediction_period else 1.0

        period_results.append((pred_period, pred, conf, weight))

    # ê°€ì¤‘ íˆ¬í‘œë¡œ ì•™ìƒë¸”
    weighted_sum = sum(p * c * w for _, p, c, w in period_results)
    total_weight = sum(c * w for _, _, c, w in period_results)

    # ì˜ˆì¸¡ ë° ì‹ ë¢°ë„ ê³„ì‚°
    ensemble_pred = weighted_sum / total_weight if total_weight > 0 else 0.5
    final_prediction = 1 if ensemble_pred > 0.5 else 0

    # ì‹ ë¢°ë„ ê³„ì‚°
    # ê° ëª¨ë¸ì˜ í™•ì‹ ë„ì™€ ì˜ˆì¸¡ì´ ì „ì²´ ê²°ê³¼ì™€ ì¼ì¹˜í• ìˆ˜ë¡ ë†’ì€ ì‹ ë¢°ë„
    agreement_factor = sum(1 for _, p, _, _ in period_results if (p > 0.5) == (final_prediction == 1))
    agreement_ratio = agreement_factor / len(period_results)

    # ì£¼ ëª¨ë¸ì˜ í™•ì‹ ë„ ì°¾ê¸°
    main_confidence = next((c for p, _, c, _ in period_results if p == prediction_period), 0.6)

    # ìµœì¢… í™•ì‹ ë„ ê³„ì‚° (ì£¼ ëª¨ë¸ í™•ì‹ ë„ * ì¼ì¹˜ë„)
    final_confidence = main_confidence * (0.7 + 0.3 * agreement_ratio)

    return {
        'prediction': final_prediction,
        'confidence': final_confidence,
        'models': period_results
    }

# ê°œì„ ëœ ì•™ìƒë¸” ì˜ˆì¸¡ ëª¨ë¸
def ensemble_predictions(stock_code, periods=[1, 3, 5, 10]):
    """ì—¬ëŸ¬ ì˜ˆì¸¡ ê¸°ê°„ì˜ ëª¨ë¸ì„ ì•™ìƒë¸”í•˜ì—¬ ì˜ˆì¸¡"""
    results = []

    # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    import yfinance as yf
    ticker = f"{stock_code}.KS"
    session = requests.Session(impersonate="chrome")
    stock = yf.Ticker(ticker,session=session)
    df = stock.history(period="5y")  # 5ë…„ ë°ì´í„°ë¡œ í™•ì¥
    df.reset_index(inplace=True)

    for period in periods:
        # ëª¨ë¸ ìƒì„±
        model = StockPredictionModel(prediction_period=period)

        # ë°ì´í„° ì¤€ë¹„ ë° ëª¨ë¸ í•™ìŠµ
        model.load_data(df=df)
        model.create_features(advanced=True)
        model.prepare_data(test_size=0.2)
        model.train_model(optimize=True, n_iter=10)  # ìµœì í™” í™œì„±í™”

        # íŠ¹ì„± ì„ íƒ ì ìš©
        model.select_important_features(threshold=0.01)

        # ë¯¸ë˜ ì˜ˆì¸¡
        prediction = model.predict_future()
        results.append((period, prediction['Prediction'].iloc[0], prediction['Confidence'].iloc[0]))

    # ë‹¤ìˆ˜ê²° ë˜ëŠ” ê°€ì¤‘ íˆ¬í‘œë¡œ ìµœì¢… ê²°ì •
    # ì˜ˆì‹œ: í™•ì‹ ë„ë¡œ ê°€ì¤‘ í‰ê· 
    weighted_sum = sum(conf * pred for _, pred, conf in results)
    total_conf = sum(conf for _, _, conf in results)

    final_prediction = 1 if weighted_sum/total_conf > 0.5 else 0
    confidence = weighted_sum/total_conf if final_prediction == 1 else 1 - weighted_sum/total_conf

    return {'prediction': final_prediction, 'confidence': confidence, 'models': results}

class StockAnalyzer:
    """
    ë‹¤ì¤‘ ì£¼ì‹ ë¶„ì„ ë° ìŠ¤í¬ë¦¬ë‹ì„ ìœ„í•œ í´ë˜ìŠ¤
    StockPredictionModelì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìˆ˜ì˜ ì£¼ì‹ì„ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
    """

    def __init__(self):
        """
        ì£¼ì‹ ë¶„ì„ê¸° ì´ˆê¸°í™”
        """
        self.stock_data = {}
        self.analysis_results = {}

    def _analyze_stock_helper(self, args):
        """ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ í—¬í¼ ë©”ì„œë“œ"""
        code, company = args
        try:
            return code, self.analyze_stock(code, company, period='2y', prediction_period=5)  # ê°œì„ : 5ë…„ ë°ì´í„° ì‚¬ìš©
        except Exception as e:
            print(f"{code} ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return code, None
    def manage_gpu_memory(self):
        """GPU ë©”ëª¨ë¦¬ ì •ë¦¬ í•¨ìˆ˜"""
        import gc
        gc.collect()

        try:
            # CUDA ë©”ëª¨ë¦¬ í™•ì¸ ë° ì •ë¦¬
            import subprocess
            result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.free', '--format=csv'],
                                    stdout=subprocess.PIPE, text=True)
            print(f"GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n{result.stdout}")

            # XGBoost ë‚´ë¶€ CUDA ë©”ëª¨ë¦¬ ì •ë¦¬
            try:
                import xgboost as xgb
                xgb.config_context(verbosity=0)
                print("XGBoost CUDA ìºì‹œ ì •ë¦¬ ì‹œë„")
            except:
                pass

            # PyTorch CUDA ë©”ëª¨ë¦¬ ì •ë¦¬ (ì„¤ì¹˜ëœ ê²½ìš°)
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    print("PyTorch CUDA ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
            except (ImportError, AttributeError):
                pass

            print("GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            print(f"GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œë„ ì¤‘ ì˜¤ë¥˜: {e}")

    def get_krx_stock_codes(self):
        """
        í•œêµ­ ê±°ë˜ì†Œ(KRX) ì¢…ëª© ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
        """
        try:
            # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì‹œë„
            parsers = ['html5lib', 'lxml', 'bs4']

            for parser in parsers:
                try:
                    # macOSì—ì„œ SSL ì¸ì¦ì„œ ê²€ì¦ ë¬¸ì œ í•´ê²°
                    import ssl
                    ssl._create_default_https_context = ssl._create_unverified_context

                    # KRX ì¢…ëª© ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
                    krx = pd.read_html('http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&searchType=13',
                                    header=0, encoding='euc-kr', flavor=parser)[0]
                    krx = krx[['ì¢…ëª©ì½”ë“œ', 'íšŒì‚¬ëª…']]
                    krx['ì¢…ëª©ì½”ë“œ'] = krx['ì¢…ëª©ì½”ë“œ'].apply(lambda x: f'{x:06d}')
                    krx = krx.rename(columns={'ì¢…ëª©ì½”ë“œ': 'code', 'íšŒì‚¬ëª…': 'company'})

                    print(f"KRX ì¢…ëª© ìˆ˜: {len(krx)} (parser: {parser})")
                    return krx
                except Exception as e:
                    print(f"{parser} íŒŒì„œ ì‚¬ìš© ì‹¤íŒ¨: {e}")

            # ëª¨ë“  íŒŒì„œê°€ ì‹¤íŒ¨í•˜ë©´ ì˜ˆì‹œ ë°ì´í„° ë°˜í™˜
            raise Exception("ëª¨ë“  íŒŒì„œê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"KRX ì¢…ëª© ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ì˜ˆì‹œ ì½”ë“œ ë°˜í™˜ (ì‹¤íŒ¨ ì‹œ)
            return pd.DataFrame({
                'code': ['005930', '000660', '035720', '051910', '035420'],
                'company': ['ì‚¼ì„±ì „ì', 'SKí•˜ì´ë‹‰ìŠ¤', 'ì¹´ì¹´ì˜¤', 'LGí™”í•™', 'NAVER']
            })

    # StockAnalyzer í´ë˜ìŠ¤ ë‚´ë¶€ì— ì¶”ê°€ (ë‹¤ë¥¸ ë©”ì„œë“œë“¤ê³¼ ê°™ì€ ë ˆë²¨ì—)
    def analyze_in_batches(self, stock_codes, batch_size=None, period='2y', prediction_period=5, workers=1, advanced_features=True):
        """ğŸ”¥ GPU ë©”ëª¨ë¦¬ ìµœì í™” ë°°ì¹˜ ì²˜ë¦¬ (ì •í™•ë„ ìœ ì§€)"""
        import gc
        
        # ğŸ”¥ GPU ë©”ëª¨ë¦¬ ê¸°ë°˜ ë°°ì¹˜ í¬ê¸° ìµœì í™”
        if batch_size is None:
            try:
                import torch
                if torch.cuda.is_available():
                    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                    if total_memory >= 14:  # T4 GPU
                        batch_size = 100      # 80 â†’ 50 (ì•ˆì •ì„± í™•ë³´)
                    elif total_memory >= 10:
                        batch_size = 35
                    else:
                        batch_size = 25
                    print(f"ğŸš€ GPU ìµœì í™” ë°°ì¹˜: {batch_size}")
                else:
                    batch_size = 15
            except:
                batch_size = 20

        all_results = {}

        if isinstance(stock_codes, pd.DataFrame):
            codes_list = list(zip(stock_codes['code'], stock_codes['company']))
        else:
            codes_list = [(code, None) for code in stock_codes]

        total_batches = (len(codes_list) + batch_size - 1) // batch_size
        print(f"ğŸ”¥ GPU ë°°ì¹˜ ì²˜ë¦¬: {len(codes_list)}ê°œ â†’ {total_batches}ë°°ì¹˜")

        for i in range(0, len(codes_list), batch_size):
            batch = codes_list[i:i+batch_size]
            print(f"\nğŸš€ ë°°ì¹˜ {i//batch_size + 1}/{total_batches} ì²˜ë¦¬... ({len(batch)}ê°œ)")

            batch_results = {}
            for j, (code, company) in enumerate(batch):
                try:
                    print(f"  âš¡ {j+1}/{len(batch)}: {company or code}")
                    result = self.analyze_stock(
                        code, company, period,
                        prediction_period=prediction_period,
                        advanced_features=advanced_features  # True ìœ ì§€ (ì •í™•ë„ ìœ„í•´)
                    )
                    if result is not None:
                        batch_results[code] = result
                        
                    # ğŸ”¥ ìŠ¤ë§ˆíŠ¸ ë©”ëª¨ë¦¬ ê´€ë¦¬
                    if (j + 1) % 5 == 0:  # 5ê°œë§ˆë‹¤ ì •ë¦¬ (10 â†’ 5)
                        gc.collect()
                        try:
                            import torch
                            if torch.cuda.is_available():
                                torch.cuda.empty_cache()
                        except:
                            pass
                            
                except Exception as e:
                    print(f"    âŒ {code} ì‹¤íŒ¨: {e}")

            all_results.update(batch_results)

            # ë°°ì¹˜ ì™„ë£Œ í›„ ì² ì €í•œ ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
            except:
                pass

            success_rate = len(batch_results) / len(batch) * 100
            print(f"âœ… ë°°ì¹˜ ì™„ë£Œ - ì„±ê³µë¥ : {success_rate:.1f}% ëˆ„ì : {len(all_results)}ê°œ")

        self.analysis_results.update(all_results)
        print(f"ğŸ‰ ìµœì í™” ë¶„ì„ ì™„ë£Œ! {len(all_results)}ê°œ ì„±ê³µ")
        return all_results

    def download_stock_data(self, stock_code, period='2y', proxy=None):  # ê°œì„ : ê¸°ë³¸ê°’ 5yë¡œ ë³€ê²½
        """
        Yahoo Financeì—ì„œ ì£¼ì‹ ë°ì´í„° ë‹¤ìš´ë¡œë“œ

        Parameters:
        -----------
        stock_code : str
            ì¢…ëª© ì½”ë“œ
        period : str
            ë‹¤ìš´ë¡œë“œ ê¸°ê°„ ('1d', '5d', '1mo', '3mo', '6mo', '1y', '2y', '5y', '10y', 'max')
        proxy : str, optional
            í”„ë¡ì‹œ ì„œë²„ URL

        Returns:
        --------
        DataFrame
            ì£¼ê°€ ë°ì´í„°
        """
        try:
            # í•œêµ­ ì£¼ì‹ì€ ì¢…ëª©ì½”ë“œ.KS í˜•ì‹ìœ¼ë¡œ ìš”ì²­
            ticker = f"{stock_code}.KS"

            # Yahoo Financeì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            session = requests.Session(impersonate="chrome")
            stock = yf.Ticker(ticker,session=session)
            df = stock.history(period=period)

            # ì¸ë±ìŠ¤ë¥¼ Date ì—´ë¡œ ë³€í™˜
            df.reset_index(inplace=True)
            df.rename(columns={'Date': 'Date', 'Open': 'Open', 'High': 'High',
                             'Low': 'Low', 'Close': 'Close', 'Volume': 'Volume'}, inplace=True)

            # í•„ìš”í•œ ì—´ë§Œ ì„ íƒ
            df = df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]

            return df
        except Exception as e:
            print(f"{stock_code} ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def analyze_all_stocks_parallel(self, stock_codes=None, period='2y', max_stocks=None, prediction_period=5, workers=None):
        """
        ë‹¤ìˆ˜ì˜ ì£¼ì‹ì„ ë³‘ë ¬ë¡œ ë¶„ì„

        Parameters:
        -----------
        stock_codes : DataFrame or list, optional
            ë¶„ì„í•  ì¢…ëª© ì½”ë“œ ëª©ë¡
        period : str
            ë¶„ì„ ê¸°ê°„
        max_stocks : int, optional
            ìµœëŒ€ ë¶„ì„ ì¢…ëª© ìˆ˜
        prediction_period : int
            ì˜ˆì¸¡ ê¸°ê°„ (ì¼)
        workers : int
            ë³‘ë ¬ ì²˜ë¦¬ì— ì‚¬ìš©í•  ì‘ì—…ì ìˆ˜

        Returns:
        --------
        dict
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # ThreadPoolExecutorë¥¼ ì‚¬ìš© (matplotlib ë¬¸ì œ ë°©ì§€)
        from concurrent.futures import ThreadPoolExecutor, as_completed

        # matplotlib ë°±ì—”ë“œë¥¼ 'Agg'ë¡œ ì„¤ì •í•˜ì—¬ UI ì°½ì´ ì—´ë¦¬ì§€ ì•Šë„ë¡ í•¨
        import matplotlib
        matplotlib.use('Agg')

        # XGBoost ê²½ê³  ë©”ì‹œì§€ ì–µì œ
        import warnings
        warnings.filterwarnings("ignore", message="Dataset is empty, or contains only positive or negative samples")

        import os
        if workers is None:
            try:
                available_cpus = os.cpu_count()
                # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ì— ë”°ë¼ ì ì ˆí•œ ì‘ì—…ì ìˆ˜ ê²°ì •
                import psutil
                available_memory_gb = psutil.virtual_memory().available / (1024**3)

                # ë©”ëª¨ë¦¬ ê¸°ë°˜ ì‘ì—…ì ìˆ˜ ì¡°ì • (ê° ì‘ì—…ìê°€ ì•½ 2GB ì‚¬ìš©í•œë‹¤ê³  ê°€ì •)
                memory_based_workers = max(1, int(available_memory_gb / 2))

                # CPUì™€ ë©”ëª¨ë¦¬ ê¸°ë°˜ ì¤‘ ë” ì‘ì€ ê°’ ì„ íƒ
                workers = min(available_cpus, memory_based_workers)

                # ë„ˆë¬´ ë§ì€ ì‘ì—…ìëŠ” ì˜¤íˆë ¤ ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥
                workers = min(workers, 8)
            except:
                workers = 4  # ê¸°ë³¸ê°’

        print(f"ì´ {len(codes_list)}ê°œ ì¢…ëª© ë³‘ë ¬ ë¶„ì„ ì‹œì‘ (ì‘ì—…ì: {workers}ëª…, ì‹œìŠ¤í…œ CPU: {os.cpu_count()}ê°œ)...")

        if stock_codes is None:
            # KRX ì¢…ëª© ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
            stock_codes = self.get_krx_stock_codes()

        # ë°ì´í„°í”„ë ˆì„ì¸ ê²½ìš° ì²˜ë¦¬
        if isinstance(stock_codes, pd.DataFrame):
            codes_list = list(zip(stock_codes['code'], stock_codes['company']))
        else:
            codes_list = [(code, None) for code in stock_codes]

        # ìµœëŒ€ ì¢…ëª© ìˆ˜ ì œí•œ
        if max_stocks is not None:
            codes_list = codes_list[:max_stocks]

        print(f"ì´ {len(codes_list)}ê°œ ì¢…ëª© ë³‘ë ¬ ë¶„ì„ ì‹œì‘ (ì‘ì—…ì: {workers}ëª…)...")

        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        results = {}

        # ê° ì¢…ëª© ë¶„ì„ì„ ìœ„í•œ í•¨ìˆ˜
        def _analyze_stock_wrapper(args):
            code, company = args
            try:
                # ì¢…ëª©ë³„ ë¶„ì„ ìˆ˜í–‰ - advanced_features=Falseë¡œ ê³ ì •í•˜ì—¬ ì˜¤ë¥˜ ë°©ì§€
                result = self.analyze_stock(code, company, period, prediction_period,
                                        advanced_features=False)  # í•­ìƒ Falseë¡œ ì„¤ì •
                return code, result
            except AttributeError as e:
                if "no attribute 'CDL" in str(e):
                    print(f"{code} ë¶„ì„ ì‹¤íŒ¨: TA-Lib íŒ¨í„´ í•¨ìˆ˜ ëˆ„ë½ - {e}")
                    # ì´ë¯¸ advanced_features=Falseë¡œ ì„¤ì •í–ˆìœ¼ë¯€ë¡œ ì¬ì‹œë„ ë¡œì§ ì œê±°
                    return code, None
                else:
                    print(f"{code} ë¶„ì„ ì‹¤íŒ¨: {e}")
                    return code, None
            except Exception as e:
                print(f"{code} ë¶„ì„ ì‹¤íŒ¨: {e}")
                return code, None

        # ThreadPoolExecutorë¡œ ë³‘ë ¬ ì²˜ë¦¬
        with ThreadPoolExecutor(max_workers=workers) as executor:
            # ì‘ì—… ì œì¶œ
            futures = []
            for code_company in codes_list:
                future = executor.submit(_analyze_stock_wrapper, code_company)
                futures.append(future)

            # ì§„í–‰ ìƒí™© í‘œì‹œ
            for future in tqdm(as_completed(futures), total=len(futures), desc="ì£¼ì‹ ë³‘ë ¬ ë¶„ì„ ì¤‘"):
                try:
                    code, result = future.result()
                    if result is not None:
                        results[code] = result
                except Exception as e:
                    print(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    continue

        print(f"\në¶„ì„ ì™„ë£Œ: {len(results)}ê°œ ì¢…ëª© (ì„±ê³µ: {len(results)}, ì‹¤íŒ¨: {len(codes_list) - len(results)})")

        # ê²°ê³¼ ì €ì¥
        self.analysis_results = results

        return results

    def filter_stocks_by_quality(self, stock_codes, min_volume=500000, min_days=200):
        """
        ê³ í’ˆì§ˆ ì£¼ì‹ë§Œ í•„í„°ë§ - ë” ì—„ê²©í•œ ê¸°ì¤€ ì ìš©

        Parameters:
        -----------
        stock_codes : DataFrame
            ë¶„ì„í•  ì¢…ëª© ì½”ë“œ ëª©ë¡
        min_volume : int
            ìµœì†Œ í‰ê·  ê±°ë˜ëŸ‰
        min_days : int
            ìµœì†Œ ê±°ë˜ì¼ ìˆ˜

        Returns:
        --------
        DataFrame
            í•„í„°ë§ëœ ì¢…ëª© ëª©ë¡
        """
        filtered_stocks = []

        print(f"ê±°ë˜ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ì¢…ëª© í•„í„°ë§ ì¤‘... (ìµœì†Œ ê±°ë˜ëŸ‰: {min_volume:,}ì£¼)")

        for code, company in tqdm(zip(stock_codes['code'], stock_codes['company']),
                                total=len(stock_codes), desc="ì£¼ì‹ í•„í„°ë§"):
            try:
                # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
                df = self.download_stock_data(code, period='2y')

                if df is None or len(df) < min_days * 0.8:  # ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ì œì™¸
                    continue

                # 1. ê±°ë˜ëŸ‰ í•„í„°
                avg_volume = df['Volume'].mean()
                recent_volume = df['Volume'].tail(20).mean()

                # 2. ë³€ë™ì„± í•„í„° (ê·¹ë‹¨ì  ë³€ë™ì„± ì œì™¸)
                returns = df['Close'].pct_change().dropna()
                volatility = returns.std()

                # 3. ê°€ê²© í•„í„° (ë„ˆë¬´ ë‚®ì€ ê°€ê²© ì œì™¸)
                avg_price = df['Close'].mean()

                # 4. ìœ ë™ì„± í•„í„° (ê±°ë˜ì¼ë³„ ê°€ê²© ë³€ë™ê³¼ ê±°ë˜ëŸ‰ì˜ ê´€ê³„)
                price_volume_corr = df['Close'].pct_change().abs().corr(df['Volume'])

                # 5. ì¶”ì„¸ ê°•ë„ í•„í„° (ADX ì¶”ì„¸ ì§€í‘œ ì‚¬ìš©)
                if len(df) >= 30:  # ADX ê³„ì‚°ì— í•„ìš”í•œ ìµœì†Œ ë°ì´í„°
                    try:
                        df['ADX'] = talib.ADX(df['High'], df['Low'], df['Close'], timeperiod=14)
                        avg_adx = df['ADX'].mean()
                    except:
                        avg_adx = 0
                else:
                    avg_adx = 0

                # 6. ì´ìƒì¹˜ ë¹ˆë„ í•„í„° (ê·¹ë‹¨ì  ê°€ê²© ë³€ë™ ì¼ìˆ˜)
                outlier_threshold = 3 * volatility
                outlier_pct = (returns.abs() > outlier_threshold).mean()

                # 7. ì¢…ëª© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
                quality_score = 0

                # ê±°ë˜ëŸ‰ ì ìˆ˜ (ìµœëŒ€ 3ì )
                if avg_volume >= min_volume * 2:
                    quality_score += 3
                elif avg_volume >= min_volume * 1.5:
                    quality_score += 2
                elif avg_volume >= min_volume:
                    quality_score += 1

                # ìµœê·¼ ê±°ë˜ëŸ‰ ì ìˆ˜ (ìµœëŒ€ 2ì )
                if recent_volume >= min_volume:
                    quality_score += 1
                    if recent_volume >= avg_volume * 0.9:  # ìµœê·¼ ê±°ë˜ëŸ‰ì´ í‰ê· ì˜ 90% ì´ìƒ
                        quality_score += 1

                # ë³€ë™ì„± ì ìˆ˜ (ìµœëŒ€ 2ì )
                if volatility < 0.04:  # 4% ì´í•˜ ë³€ë™ì„±
                    quality_score += 2
                elif volatility < 0.06:  # 6% ì´í•˜ ë³€ë™ì„±
                    quality_score += 1

                # ê°€ê²© ì ìˆ˜ (ìµœëŒ€ 2ì )
                if avg_price >= 10000:  # ë§Œì› ì´ìƒ
                    quality_score += 2
                elif avg_price >= 5000:  # 5ì²œì› ì´ìƒ
                    quality_score += 1

                # ì¶”ì„¸ ì ìˆ˜ (ìµœëŒ€ 2ì )
                if avg_adx >= 25:  # ê°•í•œ ì¶”ì„¸
                    quality_score += 2
                elif avg_adx >= 15:  # ì¤‘ê°„ ì¶”ì„¸
                    quality_score += 1

                # ì´ìƒì¹˜ ì ìˆ˜ (ìµœëŒ€ 1ì )
                if outlier_pct <= 0.01:  # 1% ì´í•˜ ì´ìƒì¹˜
                    quality_score += 1

                # ë°ì´í„° ì¶©ë¶„ì„± ì ìˆ˜ (ìµœëŒ€ 1ì )
                if len(df) >= min_days:
                    quality_score += 1

                # í’ˆì§ˆ ì ìˆ˜ê°€ 6ì  ì´ìƒì¸ ì¢…ëª©ë§Œ ì„ íƒ (ì´ 13ì  ë§Œì )
                if quality_score >= 6:
                    filtered_stocks.append({
                        'code': code,
                        'company': company,
                        'quality_score': quality_score,
                        'avg_volume': avg_volume,
                        'volatility': volatility,
                        'avg_price': avg_price,
                        'avg_adx': avg_adx
                    })

            except Exception as e:
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ í•´ë‹¹ ì¢…ëª© ê±´ë„ˆë›°ê¸°
                continue

        # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        filtered_df = pd.DataFrame(filtered_stocks)

        if not filtered_df.empty:
            # í’ˆì§ˆ ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            filtered_df = filtered_df.sort_values('quality_score', ascending=False)

            # í’ˆì§ˆ ë“±ê¸‰ ì¶”ê°€
            conditions = [
                (filtered_df['quality_score'] >= 10),
                (filtered_df['quality_score'] >= 8),
                (filtered_df['quality_score'] >= 6)
            ]
            grades = ['A', 'B', 'C']
            filtered_df['quality_grade'] = np.select(conditions, grades, default='D')

        print(f"í•„í„°ë§ ê²°ê³¼: {len(filtered_df)}ê°œ ì¢…ëª© ì„ íƒë¨ (ì „ì²´ {len(stock_codes)}ê°œ ì¤‘)")

        if not filtered_df.empty:
            print("\nìƒìœ„ 10ê°œ ê³ í’ˆì§ˆ ì¢…ëª©:")
            top_10 = filtered_df.head(10)[['code', 'company', 'quality_score', 'quality_grade', 'avg_volume']]
            top_10['avg_volume'] = top_10['avg_volume'].map(lambda x: f"{int(x):,}")
            print(top_10.to_string(index=False))

        return filtered_df[['code', 'company', 'quality_score', 'quality_grade']]

    def analyze_stock(self, stock_code, company_name=None, period='2y', prediction_period=5, use_financials=False, advanced_features=True):
        """ğŸ”¥ ê°œë³„ ì¢…ëª© ìµœì í™” ë¶„ì„ (ì •í™•ë„ ìœ ì§€)"""
        try:
            # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            df = self.download_stock_data(stock_code, period=period)
            if df is None or len(df) < 100:
                return None

            # ğŸ”¥ ê±°ë˜ëŸ‰ ê¸°ì¤€ ì™„í™” (ë” ë§ì€ ì¢…ëª© í¬í•¨)
            if df['Volume'].mean() < 200000:  # 500000 â†’ 200000 (ê¸°íšŒ í™•ëŒ€)
                return None

            # ëª¨ë¸ ì´ˆê¸°í™”
            model = StockPredictionModel(
                prediction_type='classification',
                prediction_period=prediction_period,
                confidence_threshold=0.7
            )

            model.load_data(df=df)
            
            # ğŸ”¥ íŠ¹ì„± ìƒì„± (advanced=True ìœ ì§€ - ì •í™•ë„ ìœ„í•´)
            model.create_features(advanced=advanced_features, stock_code=None)  # ì¬ë¬´ì •ë³´ëŠ” ì œì™¸ (ì†ë„)
            model.prepare_data(test_size=0.2)

            # ğŸ”¥ ë‹¨ê³„ë³„ í•™ìŠµ (ì •í™•ë„ í™•ë³´)
            # 1ë‹¨ê³„: ê¸°ë³¸ í•™ìŠµ
            model.train_model(optimize=False)
            
            # 2ë‹¨ê³„: íŠ¹ì„± ì„ íƒ (ì¤‘ìš”ë„ ê¸°ë°˜)
            try:
                model.select_important_features(threshold=0.005, top_n=None)  # ì„ê³„ê°’ ë‚®ì¶¤ (ë” ë§ì€ íŠ¹ì„± ìœ ì§€)
            except:
                pass  # íŠ¹ì„± ì„ íƒ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            
            # 3ë‹¨ê³„: ìµœì¢… í•™ìŠµ
            model.train_model(optimize=False)  # ë¹ ë¥¸ í•™ìŠµì´ì§€ë§Œ ì•™ìƒë¸”ë¡œ ì •í™•ë„ í™•ë³´

            # í‰ê°€
            try:
                metrics = model.evaluate_model()
            except:
                metrics = {'accuracy': 0.5, 'precision': 0, 'recall': 0, 'f1': 0, 'auc': 0.5}

            # ğŸ”¥ ê°„ì†Œí™”ëœ ë°±í…ŒìŠ¤íŠ¸ (í•µì‹¬ ì§€í‘œë§Œ)
            try:
                backtest_results = model.backtest(
                    transaction_cost=0.001, 
                    stop_loss=0.03, 
                    take_profit=0.05
                )
            except:
                backtest_results = {
                    'total_return': 0, 'buy_hold_return': 0, 'annual_return': 0,
                    'sharpe_ratio': 0, 'max_drawdown': 0, 'win_rate': 0.5, 'trade_count': 0
                }

            # ì˜ˆì¸¡
            future_prediction = model.predict_future(days=1)
            prediction_signal = "ë§¤ìˆ˜" if future_prediction['Prediction'].iloc[0] == 1 else "ë§¤ë„"
            prediction_confidence = future_prediction['Confidence'].iloc[0]

            # ê²°ê³¼ ë°˜í™˜
            return {
                'stock_code': stock_code,
                'company_name': company_name,
                'accuracy': model.test_accuracy or 0.5,
                'metrics': metrics,
                'backtest': backtest_results,
                'latest_price': df['Close'].iloc[-1],
                'prediction_signal': prediction_signal,
                'prediction_confidence': prediction_confidence,
                'volatility': df['Close'].pct_change().std(),
                'avg_volume': df['Volume'].mean()
            }

        except Exception as e:
            print(f"ë¶„ì„ ì‹¤íŒ¨ {stock_code}: {e}")
            return None

    def analyze_all_stocks(self, stock_codes=None, period='2y', max_stocks=None, prediction_period=5):  # ê°œì„ : 5yë¡œ ë³€ê²½
        """
        ë‹¤ìˆ˜ì˜ ì£¼ì‹ ë¶„ì„ ë° ìŠ¤í¬ë¦¬ë‹

        Parameters:
        -----------
        stock_codes : DataFrame or list, optional
            ë¶„ì„í•  ì¢…ëª© ì½”ë“œ ëª©ë¡
        period : str
            ë¶„ì„ ê¸°ê°„
        max_stocks : int, optional
            ìµœëŒ€ ë¶„ì„ ì¢…ëª© ìˆ˜
        prediction_period : int
            ì˜ˆì¸¡ ê¸°ê°„ (ì¼)

        Returns:
        --------
        dict
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if stock_codes is None:
            # KRX ì¢…ëª© ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
            stock_codes = self.get_krx_stock_codes()

        # ë°ì´í„°í”„ë ˆì„ì¸ ê²½ìš° ì²˜ë¦¬
        if isinstance(stock_codes, pd.DataFrame):
            codes_list = list(zip(stock_codes['code'], stock_codes['company']))
        else:
            codes_list = [(code, None) for code in stock_codes]

        # ìµœëŒ€ ì¢…ëª© ìˆ˜ ì œí•œ
        if max_stocks is not None:
            codes_list = codes_list[:max_stocks]

        print(f"ì´ {len(codes_list)}ê°œ ì¢…ëª© ë¶„ì„ ì‹œì‘...")

        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        results = {}

        # í”„ë¡œê·¸ë ˆìŠ¤ë°”ë¡œ ì§„í–‰ ìƒí™© í‘œì‹œ
        for i, (code, company) in enumerate(tqdm(codes_list, desc="ì£¼ì‹ ë¶„ì„ ì¤‘")):
            result = self.analyze_stock(code, company, period, prediction_period)
            if result is not None:
                results[code] = result

        print(f"\në¶„ì„ ì™„ë£Œ: {len(results)}ê°œ ì¢…ëª© (ì„±ê³µ: {len(results)}, ì‹¤íŒ¨: {len(codes_list) - len(results)})")

        # ê²°ê³¼ ì €ì¥
        self.analysis_results = results

        return results

    def get_top_stocks(self, criteria='combined_score', top_n=10, ascending=False):
        """
        íŠ¹ì • ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ ì¢…ëª© ì„ íƒ - ê°œì„ ëœ ë³µí•© ì ìˆ˜

        Parameters:
        -----------
        criteria : str
            ì •ë ¬ ê¸°ì¤€ ('combined_score', 'backtest_return', 'accuracy', 'sharpe_ratio', 'win_rate' ë“±)
        top_n : int
            ë°˜í™˜í•  ìƒìœ„ ì¢…ëª© ìˆ˜
        ascending : bool
            ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ ì—¬ë¶€

        Returns:
        --------
        DataFrame
            ìƒìœ„ ì¢…ëª© ë°ì´í„°í”„ë ˆì„
        """
        if not self.analysis_results:
            raise ValueError("ë¨¼ì € analyze_all_stocks() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")

        # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        results_data = []

        for code, result in self.analysis_results.items():
            if result is None:
                continue

            data = {
                'code': code,
                'company': result.get('company_name', code),
                'accuracy': result['accuracy'],
                'backtest_return': result['backtest']['total_return'],
                'buy_hold_return': result['backtest']['buy_hold_return'],
                'annual_return': result['backtest']['annual_return'],
                'sharpe_ratio': result['backtest']['sharpe_ratio'],
                'calmar_ratio': result['backtest'].get('calmar_ratio', 0),
                'max_drawdown': result['backtest']['max_drawdown'],
                'win_rate': result['backtest']['win_rate'],
                'profit_loss_ratio': result['backtest'].get('profit_loss_ratio', 1),
                'prediction_signal': result['prediction_signal'],
                'prediction_confidence': result.get('prediction_confidence', 0),
                'latest_price': result.get('latest_price', 0),
                'volatility': result.get('volatility', 0),
                'avg_volume': result.get('avg_volume', 0)
            }

            # ë³µí•© ì ìˆ˜ ê³„ì‚° (ì—¬ëŸ¬ ì§€í‘œì˜ ê°€ì¤‘ í‰ê· )
            if criteria == 'combined_score':
                # ë³µí•© ì ìˆ˜ ìš”ì†Œë“¤ ì •ê·œí™” (0~1 ë²”ìœ„ë¡œ)
                backtest_score = min(max(data['backtest_return'] / 0.5, 0), 1)  # 50% ìˆ˜ìµë¥ ê¹Œì§€ ìŠ¤ì¼€ì¼
                accuracy_score = data['accuracy']
                sharpe_score = min(max(data['sharpe_ratio'] / 3, 0), 1)  # ìƒ¤í”„ 3ê¹Œì§€ ìŠ¤ì¼€ì¼
                win_rate_score = data['win_rate']
                max_drawdown_score = 1 - min(abs(data['max_drawdown']) / 0.3, 1)  # 30% ì†ì‹¤ê¹Œì§€ ìŠ¤ì¼€ì¼

                # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ë³µí•© ì ìˆ˜ ê³„ì‚°
                data['combined_score'] = (
                    backtest_score * 0.3 +       # ë°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥  (30%)
                    accuracy_score * 0.2 +        # ëª¨ë¸ ì •í™•ë„ (20%)
                    sharpe_score * 0.2 +          # ìƒ¤í”„ ë¹„ìœ¨ (20%)
                    win_rate_score * 0.15 +       # ìŠ¹ë¥  (15%)
                    max_drawdown_score * 0.15     # ìµœëŒ€ ì†ì‹¤ (15%)
                )

            results_data.append(data)

        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df_results = pd.DataFrame(results_data)

        # ë³µí•© ì ìˆ˜ ì—†ì„ ê²½ìš° ê³„ì‚°
        if 'combined_score' not in df_results.columns and criteria == 'combined_score':
            # ì •ê·œí™” í•¨ìˆ˜
            def normalize(series, min_val, max_val):
                return (series - min_val) / (max_val - min_val) if max_val > min_val else series * 0

            # ì •ê·œí™”ëœ ì§€í‘œ ê³„ì‚°
            backtest_norm = normalize(df_results['backtest_return'],
                                    df_results['backtest_return'].min(),
                                    df_results['backtest_return'].max())

            accuracy_norm = normalize(df_results['accuracy'],
                                    df_results['accuracy'].min(),
                                    df_results['accuracy'].max())

            sharpe_norm = normalize(df_results['sharpe_ratio'],
                                df_results['sharpe_ratio'].min(),
                                df_results['sharpe_ratio'].max())

            win_rate_norm = normalize(df_results['win_rate'],
                                    df_results['win_rate'].min(),
                                    df_results['win_rate'].max())

            # ë“œë¡œë‹¤ìš´ì€ ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ
            drawdown_norm = 1 - normalize(df_results['max_drawdown'].abs(),
                                        df_results['max_drawdown'].abs().min(),
                                        df_results['max_drawdown'].abs().max())

            # ë³µí•© ì ìˆ˜ ê³„ì‚°
            df_results['combined_score'] = (
                backtest_norm * 0.3 +
                accuracy_norm * 0.2 +
                sharpe_norm * 0.2 +
                win_rate_norm * 0.15 +
                drawdown_norm * 0.15
            )

        # ê¸°ì¤€ì— ë”°ë¼ ì •ë ¬
        if criteria not in df_results.columns:
            print(f"ê²½ê³ : '{criteria}' ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'combined_score'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            sort_col = 'combined_score'
        else:
            sort_col = criteria

        # ì •ë ¬ ë° ìƒìœ„ ì¢…ëª© ì„ íƒ
        df_sorted = df_results.sort_values(sort_col, ascending=ascending)
        top_stocks = df_sorted.head(top_n)

        # ê²°ê³¼ ì¶œë ¥
        print(f"\n===== {criteria} ê¸°ì¤€ ìƒìœ„ {top_n}ê°œ ì¢…ëª© =====")
        display_cols = ['code', 'company', sort_col, 'backtest_return', 'accuracy', 'sharpe_ratio', 'win_rate', 'prediction_signal']

        # ì¶œë ¥ìš© í¬ë§· ë°ì´í„°
        display_df = top_stocks[display_cols].copy()

        # í¼ì„¼íŠ¸ í¬ë§·íŒ…
        for col in ['backtest_return', 'accuracy', 'win_rate']:
            if col in display_df.columns:
                display_df[col] = display_df[col].map(lambda x: f"{x:.2%}")

        # ì†Œìˆ˜ì  í¬ë§·íŒ…
        for col in ['sharpe_ratio', 'combined_score']:
            if col in display_df.columns:
                display_df[col] = display_df[col].map(lambda x: f"{x:.3f}")

        print(display_df.to_string(index=False))

        return top_stocks

    def plot_top_stocks(self, criteria='backtest_return', top_n=10, ascending=False):
        """
        ìƒìœ„ ì¢…ëª© ì„±ê³¼ ì‹œê°í™”

        Parameters:
        -----------
        criteria : str
            ì •ë ¬ ê¸°ì¤€
        top_n : int
            í‘œì‹œí•  ìƒìœ„ ì¢…ëª© ìˆ˜
        ascending : bool
            ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ ì—¬ë¶€
        """
        # ìƒìœ„ ì¢…ëª© ê°€ì ¸ì˜¤ê¸°
        top_stocks = self.get_top_stocks(criteria, top_n, ascending)

        # ë°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥  ì‹œê°í™”
        plt.figure(figsize=(12, 6))
        bars = plt.bar(top_stocks['company'], top_stocks['backtest_return'] * 100)

        # ë§¤ìˆ˜ í›„ ë³´ìœ  ìˆ˜ìµë¥  ì¶”ê°€
        plt.bar(top_stocks['company'], top_stocks['buy_hold_return'] * 100, alpha=0.5, color='gray')

        # ê·¸ë˜í”„ ê¾¸ë¯¸ê¸°
        plt.title(f'ìƒìœ„ {top_n}ê°œ ì¢…ëª© ë°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥ ')
        plt.xlabel('ì¢…ëª©ëª…')
        plt.ylabel('ìˆ˜ìµë¥  (%)')
        plt.xticks(rotation=45, ha='right')
        plt.grid(axis='y', alpha=0.3)

        # ìˆ˜ìµë¥  í‘œì‹œ
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 1,
                    f'{height:.1f}%', ha='center', va='bottom')

        plt.tight_layout()
        # plt.show()

        # ì •í™•ë„ vs ìƒ¤í”„ ë¹„ìœ¨ ì‚°ì ë„
        plt.figure(figsize=(10, 6))
        scatter = plt.scatter(top_stocks['accuracy'], top_stocks['sharpe_ratio'],
                            s=top_stocks['backtest_return'] * 1000, alpha=0.6,
                            c=top_stocks['win_rate'], cmap='viridis')

        # ì¢…ëª©ëª… í‘œì‹œ
        for i, txt in enumerate(top_stocks['company']):
            plt.annotate(txt, (top_stocks['accuracy'].iloc[i], top_stocks['sharpe_ratio'].iloc[i]),
                        xytext=(5, 5), textcoords='offset points')

        plt.title('ì •í™•ë„ vs ìƒ¤í”„ ë¹„ìœ¨')
        plt.xlabel('ì •í™•ë„')
        plt.ylabel('ìƒ¤í”„ ë¹„ìœ¨')
        plt.grid(True, alpha=0.3)
        plt.colorbar(scatter, label='ìŠ¹ë¥ ')

        plt.tight_layout()
        # plt.show()

    # ê°œì„ : ìµœì í™”ëœ ê²°ê³¼ë§Œ ì €ì¥í•˜ëŠ” ë©”ì„œë“œ
    def save_optimized_results(self, all_results_df, filename):
        """
        ìµœì í™”ëœ ê²°ê³¼ë§Œ CSVì— ì €ì¥ - ê°œì„ ëœ ë²„ì „

        Parameters:
        -----------
        all_results_df : DataFrame
            ëª¨ë“  ë¶„ì„ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
        filename : str
            ì €ì¥í•  íŒŒì¼ ì´ë¦„

        Returns:
        --------
        DataFrame
            í•„í„°ë§ëœ ê³ í’ˆì§ˆ ê²°ê³¼
        """
        # 1. í•„ìˆ˜ ì—´ í™•ì¸ ë° ì²˜ë¦¬
        essential_cols = [
            'ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…', 'í˜„ì¬ê°€',
            'ì˜ˆì¸¡ë°©í–¥', 'ì˜ˆì¸¡í™•ì‹ ë„', 'ê±°ë˜ê²°ì •',
            'ëª©í‘œê°€', 'ì†ì ˆê°€',  # ëª©í‘œê°€/ì†ì ˆê°€ëŠ” ì¤‘ìš”í•œ ë§¤ë§¤ ì§€í‘œ
            'ì •í™•ë„', 'ìŠ¹ë¥ ', 'ë°±í…ŒìŠ¤íŠ¸ìˆ˜ìµë¥ '
        ]

        # ëˆ„ë½ëœ ì—´ ì²˜ë¦¬
        missing_cols = [col for col in essential_cols if col not in all_results_df.columns]
        if missing_cols:
            print(f"ê²½ê³ : ë‹¤ìŒ ì—´ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_cols}")
            # ëˆ„ë½ëœ ì—´ ì¶”ê°€ (ê¸°ë³¸ê°’ìœ¼ë¡œ)
            for col in missing_cols:
                if col == 'ì¢…ëª©ì½”ë“œ' or col == 'ì¢…ëª©ëª…':
                    continue  # ì´ ì—´ë“¤ì€ ë°˜ë“œì‹œ ìˆì–´ì•¼ í•¨
                all_results_df[col] = None

        # ì‚¬ìš© ê°€ëŠ¥í•œ ì—´ë§Œ ì„ íƒ
        available_cols = [col for col in essential_cols if col in all_results_df.columns]
        optimized_df = all_results_df[available_cols].copy()

        # 2. ê±°ë˜ ê°€ëŠ¥í•œ ì¢…ëª©ë§Œ í•„í„°ë§ (ê´€ë§ ì œì™¸)
        if 'ê±°ë˜ê²°ì •' in optimized_df.columns:
            action_df = optimized_df[optimized_df['ê±°ë˜ê²°ì •'] != 'ê´€ë§']
        else:
            # ê±°ë˜ê²°ì • ì—´ì´ ì—†ìœ¼ë©´ ì˜ˆì¸¡ë°©í–¥ìœ¼ë¡œ ëŒ€ì²´
            optimized_df['ê±°ë˜ê²°ì •'] = optimized_df['ì˜ˆì¸¡ë°©í–¥'].apply(
                lambda x: x if x in ['ë§¤ìˆ˜', 'ë§¤ë„'] else 'ê´€ë§'
            )
            action_df = optimized_df[optimized_df['ê±°ë˜ê²°ì •'] != 'ê´€ë§']

        # í–‰ì´ ì—†ìœ¼ë©´ ì²˜ë¦¬
        if len(action_df) == 0:
            print("ê²½ê³ : ê±°ë˜ ê°€ëŠ¥í•œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            action_df = optimized_df

        # 3. ê°œì„ : ë‹¤ì–‘í•œ í’ˆì§ˆ í•„í„° ì ìš©
        # 3.1. í™•ì‹ ë„ í•„í„°
        confidence_filter = (
            (action_df['ì˜ˆì¸¡í™•ì‹ ë„'] >= 0.55) if 'ì˜ˆì¸¡í™•ì‹ ë„' in action_df.columns
            else pd.Series([True] * len(action_df))
        )

        # 3.2. ì •í™•ë„ í•„í„°
        accuracy_filter = (
            (action_df['ì •í™•ë„'] >= 0.55) if 'ì •í™•ë„' in action_df.columns
            else pd.Series([True] * len(action_df))
        )

        # 3.3. ìŠ¹ë¥  í•„í„°
        winrate_filter = (
            (action_df['ìŠ¹ë¥ '] >= 0.5) if 'ìŠ¹ë¥ ' in action_df.columns
            else pd.Series([True] * len(action_df))
        )

        # 3.4. ë°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥  í•„í„°
        return_filter = (
            (action_df['ë°±í…ŒìŠ¤íŠ¸ìˆ˜ìµë¥ '] > 0) if 'ë°±í…ŒìŠ¤íŠ¸ìˆ˜ìµë¥ ' in action_df.columns
            else pd.Series([True] * len(action_df))
        )

        # ì¡°í•©ëœ í•„í„° ì ìš©
        combined_filter = confidence_filter & accuracy_filter & winrate_filter & return_filter
        high_quality = action_df[combined_filter]

        # í•„í„°ë§ ê²°ê³¼ê°€ ë„ˆë¬´ ì œí•œì ì¸ ê²½ìš° ë” ê´€ëŒ€í•œ í•„í„° ì ìš©
        if len(high_quality) < 5 and len(action_df) > 5:
            print("ê²½ê³ : ì—„ê²©í•œ í•„í„°ë§ í›„ ì¢…ëª©ì´ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ë” ê´€ëŒ€í•œ ê¸°ì¤€ ì ìš©...")

            # ë” ê´€ëŒ€í•œ í•„í„°
            relaxed_filter = (
                (action_df['ì˜ˆì¸¡í™•ì‹ ë„'] >= 0.5 if 'ì˜ˆì¸¡í™•ì‹ ë„' in action_df.columns else True) &
                (action_df['ì •í™•ë„'] >= 0.52 if 'ì •í™•ë„' in action_df.columns else True)
            )

            high_quality = action_df[relaxed_filter]

        # ì—¬ì „íˆ ê²°ê³¼ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ëª¨ë“  ê±°ë˜ ê°€ëŠ¥ ì¢…ëª© ì‚¬ìš©
        if len(high_quality) < 3 and len(action_df) > 0:
            print("ê²½ê³ : í•„í„°ë§ í›„ ì¢…ëª©ì´ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ëª¨ë“  ê±°ë˜ ê°€ëŠ¥ ì¢…ëª© ì‚¬ìš©...")
            high_quality = action_df

        # 4. ì¢…í•© ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
        if len(high_quality) > 0:
            # ì •ê·œí™” í•¨ìˆ˜
            def normalize(series, default=0.5):
                if len(series) == 0:
                    return pd.Series([default])

                min_val = series.min()
                max_val = series.max()

                if max_val == min_val:
                    return pd.Series([0.5] * len(series))

                return (series - min_val) / (max_val - min_val)

            # ê°€ëŠ¥í•œ ì—´ì— ëŒ€í•´ì„œë§Œ ì ìˆ˜ ê³„ì‚°
            score_components = []

            if 'ì˜ˆì¸¡í™•ì‹ ë„' in high_quality.columns:
                conf_norm = normalize(high_quality['ì˜ˆì¸¡í™•ì‹ ë„'])
                score_components.append(conf_norm * 0.4)  # 40% ê°€ì¤‘ì¹˜

            if 'ì •í™•ë„' in high_quality.columns:
                acc_norm = normalize(high_quality['ì •í™•ë„'])
                score_components.append(acc_norm * 0.3)  # 30% ê°€ì¤‘ì¹˜

            if 'ìŠ¹ë¥ ' in high_quality.columns:
                win_norm = normalize(high_quality['ìŠ¹ë¥ '])
                score_components.append(win_norm * 0.15)  # 15% ê°€ì¤‘ì¹˜

            if 'ë°±í…ŒìŠ¤íŠ¸ìˆ˜ìµë¥ ' in high_quality.columns:
                ret_norm = normalize(high_quality['ë°±í…ŒìŠ¤íŠ¸ìˆ˜ìµë¥ '])
                score_components.append(ret_norm * 0.15)  # 15% ê°€ì¤‘ì¹˜

            # ì¢…í•© ì ìˆ˜ ê³„ì‚°
            if score_components:
                high_quality['ì¢…í•©ì ìˆ˜'] = sum(score_components)
            else:
                # ì ìˆ˜ ê³„ì‚°ì´ ë¶ˆê°€ëŠ¥í•˜ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
                high_quality['ì¢…í•©ì ìˆ˜'] = 0.5

            # ì •ë ¬
            high_quality = high_quality.sort_values('ì¢…í•©ì ìˆ˜', ascending=False)

        # 5. ì €ì¥
        try:
            high_quality.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"ìµœì í™”ëœ ê²°ê³¼ {len(high_quality)}ê°œê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")
            # ë°±ì—… ìœ„ì¹˜ì— ì €ì¥ ì‹œë„
            try:
                backup_filename = filename.replace('.csv', '_backup.csv')
                high_quality.to_csv(backup_filename, index=False, encoding='utf-8-sig')
                print(f"ë°±ì—… íŒŒì¼ë¡œ ì €ì¥: {backup_filename}")
            except:
                print("íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        return high_quality

    #   í–¥ìƒëœ ë©”ì¸ í•¨ìˆ˜ (í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì§€ì )
    def run_stock_analysis_pipeline(filter_by_volume=True, batch_size=100, period='2y', save_to_drive=False, drive_path=None):
        """
        ì „ì²´ ì£¼ì‹ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        Parameters:
        -----------
        filter_by_volume : bool
            ê±°ë˜ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ì¢…ëª© í•„í„°ë§ ì—¬ë¶€
        batch_size : int
            ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸°
        period : str
            ë¶„ì„ ê¸°ê°„
        save_to_drive : bool
            Google Driveì— ê²°ê³¼ ì €ì¥ ì—¬ë¶€
        drive_path : str, optional
            Google Drive ì €ì¥ ê²½ë¡œ
        """
        try:
            print("ì „ì²´ ì£¼ì‹ ë¶„ì„ ì‹œì‘...")

            # í•„ìš”í•œ íŒ¨í‚¤ì§€ í™•ì¸
            try:
                import html5lib
                print("html5lib íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            except ImportError:
                print("ê²½ê³ : html5lib íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
                print("pip install html5lib ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")

            # matplotlib ë°±ì—”ë“œ ì„¤ì •
            import matplotlib
            matplotlib.use('Agg')

            import warnings
            warnings.filterwarnings("ignore", message="Dataset is empty")
            warnings.filterwarnings("ignore", message="contains only positive or negative samples")

            # Google Drive ë§ˆìš´íŠ¸ (ì˜µì…˜)
            if save_to_drive:
                try:
                    from google.colab import drive
                    drive.mount('/content/drive')

                    # ì €ì¥ ê²½ë¡œ ì„¤ì •
                    if drive_path is None:
                        drive_path = "/content/drive/MyDrive/ì£¼ì‹ë¶„ì„ê²°ê³¼/"

                    import os
                    os.makedirs(drive_path, exist_ok=True)
                    print(f"Google Drive ë§ˆìš´íŠ¸ ì™„ë£Œ. ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {drive_path}")
                except Exception as e:
                    print(f"Google Drive ë§ˆìš´íŠ¸ ì˜¤ë¥˜: {e}")
                    save_to_drive = False
                    print("ë¡œì»¬ ì €ì¥ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")

            # StockAnalyzer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            analyzer = StockAnalyzer()

            # KRX ì¢…ëª© ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
            krx_stocks = analyzer.get_krx_stock_codes()
            print(f"ì´ {len(krx_stocks)}ê°œ ì¢…ëª© ì¡°íšŒë¨")

            # í•„í„°ë§ ì ìš©
            if filter_by_volume:
                print("ê±°ë˜ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ì¢…ëª© í•„í„°ë§ ì¤‘...")
                filtered_stocks = analyzer.filter_stocks_by_quality(
                    krx_stocks,
                    min_volume=500000,  # 50ë§Œì£¼ ì´ìƒ
                    min_days=200  # 200ì¼ ì´ìƒ ê±°ë˜ ë°ì´í„°
                )
                print(f"í•„í„°ë§ ê²°ê³¼: {len(filtered_stocks)}ê°œ ì¢…ëª© ì„ íƒë¨")
                analysis_targets = filtered_stocks
            else:
                analysis_targets = krx_stocks

            # ëª¨ë¸ ì‹ ë¢°ë„ ë° ê±°ë˜ ì„ê³„ê°’ ì„¤ì •
            buy_confidence_threshold = 0.55  # ë§¤ìˆ˜ í™•ì‹ ë„ ì„ê³„ê°’ (55%)
            sell_confidence_threshold = 0.55  # ë§¤ë„ í™•ì‹ ë„ ì„ê³„ê°’ (55%)
            min_accuracy = 0.55  # ìµœì†Œ ëª¨ë¸ ì •í™•ë„ (55%)
            min_win_rate = 0.5  # ìµœì†Œ ìŠ¹ë¥  (50%)

            # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë¶„ì„ ìˆ˜í–‰
            print(f"ë°°ì¹˜ í¬ê¸° {batch_size}ë¡œ ë¶„ì„ ì‹œì‘...")
            results = analyzer.analyze_in_batches(
                stock_codes=analysis_targets,
                batch_size=batch_size,
                period=period,
                prediction_period=5,
                workers=4
            )

            # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
            results_data = []
            for code, result in results.items():
                if result is None:
                    continue

                # ì˜ˆì¸¡ ì‹ ë¢°ë„ ë° ë°©í–¥ ê°€ì ¸ì˜¤ê¸°
                prediction_signal = result.get('prediction_signal', '')
                prediction_confidence = result.get('prediction_confidence', 0)
                accuracy = result.get('accuracy', 0)
                win_rate = result.get('backtest', {}).get('win_rate', 0)

                # ê±°ë˜ ê²°ì • (ë§¤ìˆ˜/ë§¤ë„/ê´€ë§)
                trading_decision = "ê´€ë§"
                action_reason = ""

                # ë§¤ìˆ˜ ì‹ í˜¸ (í™•ì‹ ë„, ì •í™•ë„, ìŠ¹ë¥  ê¸°ì¤€ ì¶©ì¡± ì‹œ)
                if (prediction_signal == "ë§¤ìˆ˜" and
                    (prediction_confidence >= buy_confidence_threshold * 0.95 or  # ì•½ê°„ ë‚®ì¶¤ (ë” ë§ì€ ê¸°íšŒ í¬ì°©)
                    (accuracy >= min_accuracy and win_rate >= min_win_rate))):
                    trading_decision = "ë§¤ìˆ˜"
                    action_reason = f"í™•ì‹ ë„({prediction_confidence:.2%})ê°€ ì¢‹ê±°ë‚˜ ëª¨ë¸ ì„±ëŠ¥(ì •í™•ë„:{accuracy:.2%}, ìŠ¹ë¥ :{win_rate:.2%})ì´ ì–‘í˜¸í•¨"
                # ë§¤ë„ ì‹ í˜¸ (í™•ì‹ ë„, ì •í™•ë„, ìŠ¹ë¥  ëª¨ë‘ ì„ê³„ê°’ ì´ìƒì¼ ë•Œ)
                elif (prediction_signal == "ë§¤ë„" and
                    prediction_confidence >= sell_confidence_threshold and
                    accuracy >= min_accuracy and
                    win_rate >= min_win_rate):
                    trading_decision = "ë§¤ë„"
                    action_reason = f"í™•ì‹ ë„({prediction_confidence:.2%})ê°€ ë†’ê³  ëª¨ë¸ ì„±ëŠ¥(ì •í™•ë„:{accuracy:.2%}, ìŠ¹ë¥ :{win_rate:.2%})ì´ ì¢‹ìŒ"
                # ê´€ë§ (ê¸°ì¤€ ë¯¸ë‹¬)
                else:
                    reasons = []
                    if prediction_confidence < max(buy_confidence_threshold, sell_confidence_threshold):
                        reasons.append(f"í™•ì‹ ë„ ë¶€ì¡±({prediction_confidence:.2%})")
                    if accuracy < min_accuracy:
                        reasons.append(f"ì •í™•ë„ ë¶€ì¡±({accuracy:.2%})")
                    if win_rate < min_win_rate:
                        reasons.append(f"ìŠ¹ë¥  ë¶€ì¡±({win_rate:.2%})")
                    if reasons:
                        action_reason = ", ".join(reasons)
                    else:
                        action_reason = "ê¸°ì¤€ ë¯¸ë‹¬"

                # ë§¤ìˆ˜ í›„ ëª©í‘œê°€ ë° ì†ì ˆê°€ ê³„ì‚° - ë” ì •êµí•œ ê³„ì‚°
                current_price = result.get('latest_price', 0)
                avg_range = result.get('backtest', {}).get('avg_daily_range', 0)
                volatility = result.get('volatility', 0.03)  # ê¸°ë³¸ê°’ 3%

                if avg_range == 0:  # avg_daily_rangeê°€ ì—†ìœ¼ë©´ ë³€ë™ì„± ì‚¬ìš©
                    avg_range = current_price * volatility

                # ë§¤ìˆ˜ ì‹œë‚˜ë¦¬ì˜¤: ì˜ˆìƒ ìŠ¹ë¥ ê³¼ ë³€ë™ì„±ì— ë”°ë¥¸ ìœ„í—˜/ë³´ìƒ ì¡°ì •
                # ìŠ¹ë¥ ì´ ë†’ì„ìˆ˜ë¡ ì†ì ˆí­ì€ ì‘ê²Œ, ëª©í‘œê°€ëŠ” í¬ê²Œ ì„¤ì •
                if win_rate > 0.65:  # ë†’ì€ ìŠ¹ë¥ 
                    risk_reward_ratio = 3.0  # 3:1 ìœ„í—˜/ë³´ìƒ ë¹„ìœ¨
                    stop_loss_pct = 0.03  # 3% ì†ì ˆ
                elif win_rate > 0.55:  # ì¤‘ê°„ ìŠ¹ë¥ 
                    risk_reward_ratio = 2.0  # 2:1 ìœ„í—˜/ë³´ìƒ ë¹„ìœ¨
                    stop_loss_pct = 0.04  # 4% ì†ì ˆ
                else:  # ë‚®ì€ ìŠ¹ë¥ 
                    risk_reward_ratio = 1.5  # 1.5:1 ìœ„í—˜/ë³´ìƒ ë¹„ìœ¨
                    stop_loss_pct = 0.05  # 5% ì†ì ˆ

                # ë³€ë™ì„± ì¡°ì •
                stop_loss_pct = max(stop_loss_pct, volatility * 0.8)  # ë³€ë™ì„±ì˜ ìµœì†Œ 80%

                # ëª©í‘œê°€ ë° ì†ì ˆê°€ ê³„ì‚°
                take_profit_pct = stop_loss_pct * risk_reward_ratio
                target_price = current_price * (1 + take_profit_pct)
                stop_loss = current_price * (1 - stop_loss_pct)

                # ì˜ˆìƒ ë³´ìœ  ê¸°ê°„ - ë°±í…ŒìŠ¤íŠ¸ í‰ê·  ê±°ë˜ ê¸°ê°„ í™œìš©
                avg_trade_days = result.get('backtest', {}).get('avg_trade_days', 7)

                if avg_trade_days and avg_trade_days > 0:
                    if avg_trade_days < 3:
                        holding_period = "1-3 ê±°ë˜ì¼"
                    elif avg_trade_days < 7:
                        holding_period = "3-7 ê±°ë˜ì¼"
                    elif avg_trade_days < 14:
                        holding_period = "1-2ì£¼"
                    else:
                        holding_period = "2ì£¼ ì´ìƒ"
                else:
                    holding_period = "5-10 ê±°ë˜ì¼" if prediction_signal == "ë§¤ìˆ˜" else "ì¦‰ì‹œ ë§¤ë„"

                # ì¢…í•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ì—¬ëŸ¬ ì§€í‘œì˜ ê°€ì¤‘ í‰ê· )
                quality_score = (
                    (prediction_confidence if prediction_signal == "ë§¤ìˆ˜" else 0) * 0.3 +  # 30% í™•ì‹ ë„
                    accuracy * 0.25 +  # 25% ì •í™•ë„
                    win_rate * 0.25 +  # 25% ìŠ¹ë¥ 
                    (result['backtest']['total_return'] * 2 if result['backtest']['total_return'] > 0 else 0) * 0.15 +  # 15% ë°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥ 
                    (result['backtest']['sharpe_ratio'] / 2 if result['backtest']['sharpe_ratio'] > 0 else 0) * 0.05  # 5% ìƒ¤í”„ ë¹„ìœ¨
                )

                # í’ˆì§ˆ ë“±ê¸‰ ë¶€ì—¬
                if quality_score >= 0.8:
                    quality_grade = "A"
                elif quality_score >= 0.7:
                    quality_grade = "B"
                elif quality_score >= 0.6:
                    quality_grade = "C"
                elif quality_score >= 0.5:
                    quality_grade = "D"
                else:
                    quality_grade = "F"

                # í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ
                data = {
                    'ì¢…ëª©ì½”ë“œ': code,
                    'ì¢…ëª©ëª…': result.get('company_name', code),
                    'í˜„ì¬ê°€': current_price,
                    'ì˜ˆì¸¡ë°©í–¥': prediction_signal,
                    'ì˜ˆì¸¡í™•ì‹ ë„': prediction_confidence,
                    'ê±°ë˜ê²°ì •': trading_decision,
                    'ê²°ì •ì´ìœ ': action_reason,
                    'ëª©í‘œê°€': round(target_price) if trading_decision == "ë§¤ìˆ˜" else None,
                    'ì†ì ˆê°€': round(stop_loss) if trading_decision == "ë§¤ìˆ˜" else None,
                    'ì˜ˆìƒë³´ìœ ê¸°ê°„': holding_period if trading_decision == "ë§¤ìˆ˜" else None,
                    'ì •í™•ë„': accuracy,
                    'ìŠ¹ë¥ ': win_rate,
                    'ë°±í…ŒìŠ¤íŠ¸ìˆ˜ìµë¥ ': result['backtest']['total_return'] if 'backtest' in result else 0,
                    'ìƒ¤í”„ë¹„ìœ¨': result['backtest']['sharpe_ratio'] if 'backtest' in result else 0,
                    'í’ˆì§ˆì ìˆ˜': quality_score,
                    'í’ˆì§ˆë“±ê¸‰': quality_grade
                }
                results_data.append(data)

            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            all_results_df = pd.DataFrame(results_data)

            # ê±°ë˜ ê²°ì •ë³„ë¡œ ë¶„ë¥˜
            buy_recommendations = all_results_df[all_results_df['ê±°ë˜ê²°ì •'] == "ë§¤ìˆ˜"].sort_values('ì˜ˆì¸¡í™•ì‹ ë„', ascending=False)
            sell_recommendations = all_results_df[all_results_df['ê±°ë˜ê²°ì •'] == "ë§¤ë„"].sort_values('ì˜ˆì¸¡í™•ì‹ ë„', ascending=False)
            hold_recommendations = all_results_df[all_results_df['ê±°ë˜ê²°ì •'] == "ê´€ë§"]

            # ê²°ê³¼ ì €ì¥ íŒŒì¼ëª… ì¤€ë¹„
            from datetime import datetime
            today_date = datetime.now().strftime("%Y%m%d")

            # ì €ì¥ ê²½ë¡œ ì„¤ì •
            save_path = drive_path if save_to_drive else ""

            # ìµœì í™”ëœ ê²°ê³¼ ì €ì¥
            optimized_file = f"{save_path}optimized_signals_{today_date}.csv"
            analyzer.save_optimized_results(all_results_df, optimized_file)

            # ìƒìœ„ 20ê°œ ìµœì í™” ì¢…ëª© ì¶”ì¶œ
            print("\nìƒìœ„ 20ê°œ ìµœì í™” ì¢…ëª© ì¶”ì¶œ ì¤‘...")

            # CSV íŒŒì¼ ë¡œë“œ (ì§ì ‘ ê²°ê³¼ ì‚¬ìš©)
            top_signals = analyzer.save_optimized_results(all_results_df, f"{save_path}temp_signals.csv")

            # ì¢…í•© ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
            if 'í’ˆì§ˆì ìˆ˜' in top_signals.columns:
                buy_signals = top_signals.sort_values('í’ˆì§ˆì ìˆ˜', ascending=False)
            else:
                # ë§¤ìˆ˜ ì‹ í˜¸ë§Œ í•„í„°ë§
                buy_signals = top_signals[top_signals['ê±°ë˜ê²°ì •'] == 'ë§¤ìˆ˜']

                # ê° ì§€í‘œì— ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ì¢…í•© ì ìˆ˜ ê³„ì‚°
                components = []
                weights = []

                if 'ì˜ˆì¸¡í™•ì‹ ë„' in buy_signals.columns:
                    components.append(buy_signals['ì˜ˆì¸¡í™•ì‹ ë„'])
                    weights.append(0.3)  # 30% ê°€ì¤‘ì¹˜

                if 'ì •í™•ë„' in buy_signals.columns:
                    components.append(buy_signals['ì •í™•ë„'])
                    weights.append(0.3)  # 30% ê°€ì¤‘ì¹˜

                if 'ìŠ¹ë¥ ' in buy_signals.columns:
                    components.append(buy_signals['ìŠ¹ë¥ '])
                    weights.append(0.2)  # 20% ê°€ì¤‘ì¹˜

                if 'ë°±í…ŒìŠ¤íŠ¸ìˆ˜ìµë¥ ' in buy_signals.columns:
                    # ìˆ˜ìµë¥  ìŠ¤ì¼€ì¼ë§ (ìµœëŒ€ 50%ê¹Œì§€ë§Œ ê³ ë ¤)
                    scaled_return = buy_signals['ë°±í…ŒìŠ¤íŠ¸ìˆ˜ìµë¥ '].apply(lambda x: min(x, 0.5) / 0.5)
                    components.append(scaled_return)
                    weights.append(0.2)  # 20% ê°€ì¤‘ì¹˜

                # ì¢…í•© ì ìˆ˜ ê³„ì‚°
                if components:
                    total_weight = sum(weights)
                    buy_signals['ì¢…í•©ì ìˆ˜'] = sum(c * w / total_weight for c, w in zip(components, weights))
                else:
                    buy_signals['ì¢…í•©ì ìˆ˜'] = 0.5

                # ì¢…í•© ì ìˆ˜ë¡œ ì •ë ¬
                buy_signals = buy_signals.sort_values('ì¢…í•©ì ìˆ˜', ascending=False)

            # ìƒìœ„ 20ê°œ ì¢…ëª© ì¶”ì¶œ
            top_20 = buy_signals.head(20)

            # ê²°ê³¼ ì €ì¥
            top_20_file = f"{save_path}top_20_ìµœì í™”ì¢…ëª©_{today_date}.csv"
            top_20.to_csv(top_20_file, index=False, encoding='utf-8-sig')
            print(f"\nìƒìœ„ 20ê°œ ìµœì í™” ì¢…ëª©ì´ {top_20_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

            # ì½˜ì†”ì— ìƒìœ„ 20ê°œ ì¢…ëª© ì¶œë ¥
            print("\n" + "="*100)
            print(f"ì¢…í•© ì ìˆ˜ ê¸°ì¤€ ìƒìœ„ 20ê°œ ì¢…ëª©")
            print("="*100)

            # í‘œì‹œí•  ì—´ ì„ íƒ
            if 'ì¢…í•©ì ìˆ˜' in top_20.columns:
                display_cols = ['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'ëª©í‘œê°€', 'ì†ì ˆê°€', 'ì¢…í•©ì ìˆ˜', 'ì •í™•ë„', 'ìŠ¹ë¥ ', 'ë°±í…ŒìŠ¤íŠ¸ìˆ˜ìµë¥ ']
            else:
                display_cols = ['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'ëª©í‘œê°€', 'ì†ì ˆê°€', 'ì •í™•ë„', 'ìŠ¹ë¥ ', 'ë°±í…ŒìŠ¤íŠ¸ìˆ˜ìµë¥ ']

            # ì‚¬ìš© ê°€ëŠ¥í•œ ì—´ë§Œ ì„ íƒ
            display_cols = [col for col in display_cols if col in top_20.columns]

            # ì¶œë ¥ í˜•ì‹ ì§€ì •
            formatted_top_20 = top_20[display_cols].copy()

            # í¼ì„¼íŠ¸ í¬ë§·íŒ…
            for col in ['ì •í™•ë„', 'ìŠ¹ë¥ ', 'ì˜ˆì¸¡í™•ì‹ ë„', 'ì¢…í•©ì ìˆ˜']:
                if col in formatted_top_20.columns:
                    formatted_top_20[col] = formatted_top_20[col].apply(lambda x: f"{x:.2%}" if pd.notnull(x) else "")

            # ê°€ê²© í¬ë§·íŒ…
            for col in ['í˜„ì¬ê°€', 'ëª©í‘œê°€', 'ì†ì ˆê°€']:
                if col in formatted_top_20.columns:
                    formatted_top_20[col] = formatted_top_20[col].apply(lambda x: f"{int(x):,}" if pd.notnull(x) else "")

            print(formatted_top_20.to_string(index=False))

            # 1. ë§¤ìˆ˜ ì¶”ì²œ ì¢…ëª© ì €ì¥
            if len(buy_recommendations) > 0:
                buy_file = f"{save_path}buy_signals_{today_date}.csv"
                buy_recommendations.to_csv(buy_file, index=False, encoding='utf-8-sig')
                print(f"\në§¤ìˆ˜ ì¶”ì²œ ì¢…ëª© {len(buy_recommendations)}ê°œê°€ {buy_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

                # ì½˜ì†”ì— ë§¤ìˆ˜ ì¶”ì²œ ìƒìœ„ ì¢…ëª© ì¶œë ¥
                print("\n" + "="*100)
                print(f"ë§¤ìˆ˜ ì¶”ì²œ ìƒìœ„ ì¢…ëª© (ì´ {len(buy_recommendations)}ê°œ)")
                print("="*100)

                display_cols = ['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'ì˜ˆì¸¡í™•ì‹ ë„', 'ëª©í‘œê°€', 'ì†ì ˆê°€', 'ì˜ˆìƒë³´ìœ ê¸°ê°„', 'ì •í™•ë„', 'ìŠ¹ë¥ ', 'í’ˆì§ˆë“±ê¸‰']
                display_cols = [col for col in display_cols if col in buy_recommendations.columns]

                top_buys = buy_recommendations[display_cols].head(min(10, len(buy_recommendations)))

                # ì¶œë ¥ í˜•ì‹ ì§€ì •
                for col in ['ì˜ˆì¸¡í™•ì‹ ë„', 'ì •í™•ë„', 'ìŠ¹ë¥ ']:
                    if col in top_buys.columns:
                        top_buys[col] = top_buys[col].apply(lambda x: f"{x:.2%}")

                for col in ['í˜„ì¬ê°€', 'ëª©í‘œê°€', 'ì†ì ˆê°€']:
                    if col in top_buys.columns:
                        top_buys[col] = top_buys[col].apply(lambda x: f"{int(x):,}" if pd.notnull(x) else "")

                print(top_buys.to_string(index=False))
            else:
                print("\në§¤ìˆ˜ ì¶”ì²œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

            # 2. ë§¤ë„ ì¶”ì²œ ì¢…ëª© ì €ì¥
            if len(sell_recommendations) > 0:
                sell_file = f"{save_path}sell_signals_{today_date}.csv"
                sell_recommendations.to_csv(sell_file, index=False, encoding='utf-8-sig')
                print(f"\në§¤ë„ ì¶”ì²œ ì¢…ëª© {len(sell_recommendations)}ê°œê°€ {sell_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

                # ì½˜ì†”ì— ë§¤ë„ ì¶”ì²œ ìƒìœ„ ì¢…ëª© ì¶œë ¥
                print("\n" + "="*100)
                print(f"ë§¤ë„ ì¶”ì²œ ìƒìœ„ ì¢…ëª© (ì´ {len(sell_recommendations)}ê°œ)")
                print("="*100)

                display_cols = ['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'ì˜ˆì¸¡í™•ì‹ ë„', 'ì •í™•ë„', 'ìŠ¹ë¥ ', 'í’ˆì§ˆë“±ê¸‰']
                display_cols = [col for col in display_cols if col in sell_recommendations.columns]

                top_sells = sell_recommendations[display_cols].head(min(10, len(sell_recommendations)))

                # ì¶œë ¥ í˜•ì‹ ì§€ì •
                for col in ['ì˜ˆì¸¡í™•ì‹ ë„', 'ì •í™•ë„', 'ìŠ¹ë¥ ']:
                    if col in top_sells.columns:
                        top_sells[col] = top_sells[col].apply(lambda x: f"{x:.2%}")

                if 'í˜„ì¬ê°€' in top_sells.columns:
                    top_sells['í˜„ì¬ê°€'] = top_sells['í˜„ì¬ê°€'].apply(lambda x: f"{int(x):,}")

                print(top_sells.to_string(index=False))
            else:
                print("\në§¤ë„ ì¶”ì²œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

            # 3. ì „ì²´ ë¶„ì„ ê²°ê³¼ ì €ì¥
            all_results_file = f"{save_path}all_stock_analysis_{today_date}.csv"
            all_results_df.to_csv(all_results_file, index=False, encoding='utf-8-sig')
            print(f"\nì „ì²´ ë¶„ì„ ê²°ê³¼ {len(all_results_df)}ê°œê°€ {all_results_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

            # 4. HTML ë³´ê³ ì„œ ìƒì„± ë° ì €ì¥
            try:
                html_report = analyzer.generate_report(top_n=30, format='html')
                report_file = f"{save_path}stock_report_{today_date}.html"

                with open(report_file, 'w', encoding='utf-8') as f:
                    f.write(html_report)

                print(f"\nHTML ë³´ê³ ì„œê°€ {report_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"HTML ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {e}")

            print("\në¶„ì„ ë° ê±°ë˜ ì‹ í˜¸ ìƒì„± ì™„ë£Œ!")

            # 5. Google Drive ì €ì¥ í™•ì¸
            if save_to_drive:
                print("\nGoogle Driveì— ëª¨ë“  íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                print(f"ì €ì¥ ìœ„ì¹˜: {drive_path}")

        except Exception as e:
            print(f"\nì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()

    def generate_report(self, top_n=20, format='text'):
        """
        ë¶„ì„ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„± - ê°œì„ ëœ ë²„ì „

        Parameters:
        -----------
        top_n : int
            ë³´ê³ ì„œì— í¬í•¨í•  ìƒìœ„ ì¢…ëª© ìˆ˜
        format : str
            ë³´ê³ ì„œ í˜•ì‹ ('text' ë˜ëŠ” 'html')

        Returns:
        --------
        str
            ë³´ê³ ì„œ í…ìŠ¤íŠ¸/HTML
        """
        if not self.analysis_results:
            raise ValueError("ë¨¼ì € analyze_all_stocks() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")

        # ìƒìœ„ ì¢…ëª© ê°€ì ¸ì˜¤ê¸°
        top_backtest = self.get_top_stocks('backtest_return', top_n)
        top_accuracy = self.get_top_stocks('accuracy', top_n)
        top_sharpe = self.get_top_stocks('sharpe_ratio', top_n)
        top_combined = self.get_top_stocks('combined_score', top_n)

        # ë§¤ìˆ˜ ì‹ í˜¸ê°€ ìˆëŠ” ì¢…ëª© ê°€ì ¸ì˜¤ê¸°
        buy_signals = [result for code, result in self.analysis_results.items()
                    if result is not None and result['prediction_signal'] == "ë§¤ìˆ˜"]

        # ì‹ ë¢°ë„ë³„ë¡œ ì •ë ¬
        buy_signals_sorted = sorted(buy_signals, key=lambda x: x.get('prediction_confidence', 0), reverse=True)

        # í…ìŠ¤íŠ¸ í˜•ì‹ ë³´ê³ ì„œ
        if format == 'text':
            # ë³´ê³ ì„œ ìƒì„±
            report = []

            # í˜„ì¬ ë‚ ì§œ ì¶”ê°€
            from datetime import datetime
            report.append("=" * 80)
            report.append(f"ì£¼ì‹ ë¶„ì„ ë³´ê³ ì„œ - {datetime.now().strftime('%Y-%m-%d %H:%M')}")
            report.append(f"ë¶„ì„ ì¢…ëª© ìˆ˜: {len(self.analysis_results)}")
            report.append("=" * 80)

            # ìš”ì•½ í†µê³„
            report.append("\n[ìš”ì•½ í†µê³„]")
            valid_results = [r for r in self.analysis_results.values() if r is not None]
            all_returns = [result['backtest']['total_return'] for result in valid_results]
            all_accuracies = [result['accuracy'] for result in valid_results]
            all_sharpes = [result['backtest']['sharpe_ratio'] for result in valid_results]
            all_win_rates = [result['backtest']['win_rate'] for result in valid_results]

            report.append(f"í‰ê·  ë°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥ : {np.mean(all_returns):.4f} ({np.mean(all_returns) * 100:.2f}%)")
            report.append(f"í‰ê·  ëª¨ë¸ ì •í™•ë„: {np.mean(all_accuracies):.4f} ({np.mean(all_accuracies) * 100:.2f}%)")
            report.append(f"í‰ê·  ìƒ¤í”„ ë¹„ìœ¨: {np.mean(all_sharpes):.4f}")
            report.append(f"í‰ê·  ìŠ¹ë¥ : {np.mean(all_win_rates):.4f} ({np.mean(all_win_rates) * 100:.2f}%)")
            report.append(f"ë§¤ìˆ˜ ì‹ í˜¸ ì¢…ëª© ìˆ˜: {len(buy_signals)} ({len(buy_signals) / len(valid_results) * 100:.2f}%)")

            # ì¢…í•© ì ìˆ˜ ìƒìœ„ ì¢…ëª©
            report.append("\n\n[ì¢…í•© ì ìˆ˜ ìƒìœ„ ì¢…ëª©]")
            report.append("ìˆœìœ„\tì¢…ëª©ì½”ë“œ\tì¢…ëª©ëª…\t\tì¢…í•©ì ìˆ˜\të°±í…ŒìŠ¤íŠ¸ìˆ˜ìµë¥ \tì •í™•ë„\tìƒ¤í”„ë¹„ìœ¨\tì˜ˆì¸¡ì‹ í˜¸")
            report.append("-" * 80)

            for i, (_, row) in enumerate(top_combined.iterrows(), 1):
                code = row['code']
                company = row['company']
                combined_score = row['combined_score']
                backtest_return = row['backtest_return'] * 100
                accuracy = row['accuracy'] * 100
                sharpe = row['sharpe_ratio']
                signal = row['prediction_signal']

                report.append(f"{i}\t{code}\t{company:<10}\t{combined_score:.3f}\t{backtest_return:.2f}%\t{accuracy:.2f}%\t{sharpe:.2f}\t{signal}")

            # ë°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥  ìƒìœ„ ì¢…ëª©
            report.append("\n\n[ë°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥  ìƒìœ„ ì¢…ëª©]")
            report.append("ìˆœìœ„\tì¢…ëª©ì½”ë“œ\tì¢…ëª©ëª…\t\tìˆ˜ìµë¥ \tì •í™•ë„\tìƒ¤í”„ë¹„ìœ¨\tì˜ˆì¸¡ì‹ í˜¸")
            report.append("-" * 80)

            for i, (_, row) in enumerate(top_backtest.iterrows(), 1):
                code = row['code']
                company = row['company']
                backtest_return = row['backtest_return'] * 100
                accuracy = row['accuracy'] * 100
                sharpe = row['sharpe_ratio']
                signal = row['prediction_signal']

                report.append(f"{i}\t{code}\t{company:<10}\t{backtest_return:.2f}%\t{accuracy:.2f}%\t{sharpe:.2f}\t{signal}")

            # ë§¤ìˆ˜ ì‹ í˜¸ ì¢…ëª© (ì‹ ë¢°ë„ìˆœ)
            report.append("\n\n[ë§¤ìˆ˜ ì‹ í˜¸ ì¢…ëª© (ì‹ ë¢°ë„ìˆœ)]")
            report.append("ì¢…ëª©ì½”ë“œ\tì¢…ëª©ëª…\t\tì‹ ë¢°ë„\të°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥ \tì •í™•ë„\tìŠ¹ë¥ \tìµœëŒ€ì†ì‹¤")
            report.append("-" * 80)

            for i, result in enumerate(buy_signals_sorted[:min(20, len(buy_signals_sorted))], 1):
                code = result['stock_code']
                company = result.get('company_name', code)
                confidence = result.get('prediction_confidence', 0) * 100
                backtest_return = result['backtest']['total_return'] * 100
                accuracy = result['accuracy'] * 100
                win_rate = result['backtest']['win_rate'] * 100
                max_drawdown = result['backtest']['max_drawdown'] * 100

                report.append(f"{code}\t{company:<10}\t{confidence:.2f}%\t{backtest_return:.2f}%\t{accuracy:.2f}%\t{win_rate:.2f}%\t{max_drawdown:.2f}%")

            # ì¶”ê°€: ìƒê´€ê´€ê³„ ë¶„ì„
            report.append("\n\n[ì„±ëŠ¥ ì§€í‘œ ìƒê´€ê´€ê³„ ë¶„ì„]")
            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            metrics_df = pd.DataFrame([
                {
                    'backtest_return': result['backtest']['total_return'],
                    'accuracy': result['accuracy'],
                    'sharpe_ratio': result['backtest']['sharpe_ratio'],
                    'win_rate': result['backtest']['win_rate'],
                    'max_drawdown': result['backtest']['max_drawdown']
                }
                for result in valid_results
            ])

            # ìƒê´€ê´€ê³„ ê³„ì‚°
            corr_matrix = metrics_df.corr()

            # ì£¼ìš” ìƒê´€ê´€ê³„ ì¶œë ¥
            report.append("ë°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥ ê³¼ ë‹¤ë¥¸ ì§€í‘œì˜ ìƒê´€ê´€ê³„:")
            for col in ['accuracy', 'sharpe_ratio', 'win_rate', 'max_drawdown']:
                corr = corr_matrix.loc['backtest_return', col]
                report.append(f"- {col}: {corr:.4f}")

            # íˆ¬ì ì „ëµ ì œì•ˆ
            report.append("\n\n[íˆ¬ì ì „ëµ ì œì•ˆ]")

            # ì‹œì¥ ìƒí™© ë¶„ì„
            market_bullish = len([r for r in buy_signals if r.get('prediction_confidence', 0) > 0.7]) > len(buy_signals) / 3

            if market_bullish:
                report.append("í˜„ì¬ ë¶„ì„ ê²°ê³¼ëŠ” ì „ë°˜ì ìœ¼ë¡œ ìƒìŠ¹ ì¶”ì„¸ë¥¼ ì‹œì‚¬í•©ë‹ˆë‹¤.")
                if len(buy_signals) > 10:
                    report.append("ë‹¤ìˆ˜ì˜ ë§¤ìˆ˜ ì‹ í˜¸ê°€ ìˆì–´, ë‹¤ìŒê³¼ ê°™ì€ ê³ ë ¤ì‚¬í•­ì„ ì œì•ˆí•©ë‹ˆë‹¤:")
                    report.append("1. í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì‚°: ë§¤ìˆ˜ ì‹ í˜¸ ìƒìœ„ 5-10ê°œ ì¢…ëª©ì— ìë³¸ì„ ë¶„ì‚° íˆ¬ì")
                    report.append("2. ë‹¨ê³„ì  ì§„ì…: ì „ì²´ íˆ¬ìê¸ˆì˜ 60%ë¥¼ ì´ˆê¸°ì— íˆ¬ìí•˜ê³ , ë‚˜ë¨¸ì§€ëŠ” ì¶”ê°€ í•˜ë½ ì‹œ ë¶„í•  ë§¤ìˆ˜")
                    report.append("3. ì² ì €í•œ ì†ì ˆ: ê° ì¢…ëª©ë³„ 3% ì†ì ˆë¼ì¸ ì„¤ì •")
                else:
                    report.append("ì œí•œëœ ë§¤ìˆ˜ ì‹ í˜¸ë§Œ ìˆì–´, ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤:")
                    report.append("1. ì„ ë³„ì  íˆ¬ì: ë§¤ìˆ˜ ì‹ í˜¸ ì¤‘ ì¢…í•© ì ìˆ˜ ìƒìœ„ 3-5ê°œ ì¢…ëª©ì—ë§Œ ì§‘ì¤‘")
                    report.append("2. ìë³¸ ë³´ì¡´: ì „ì²´ íˆ¬ìê¸ˆì˜ 30-40%ë§Œ íˆ¬ìí•˜ê³  ë‚˜ë¨¸ì§€ëŠ” í˜„ê¸ˆ ë³´ìœ ")
            else:
                report.append("í˜„ì¬ ë¶„ì„ ê²°ê³¼ëŠ” ì‹œì¥ì˜ ë¶ˆí™•ì‹¤ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.")
                report.append("1. ë°©ì–´ì  í¬ì§€ì…˜: ë§¤ìˆ˜ ì‹ í˜¸ê°€ ì œí•œì ì´ë¯€ë¡œ ì „ì²´ ìë³¸ì˜ 20-30%ë§Œ íˆ¬ì ê³ ë ¤")
                report.append("2. ì•ˆì „ ìì‚° ìœ ì§€: ë‚˜ë¨¸ì§€ ìë³¸ì€ í˜„ê¸ˆ ë˜ëŠ” ì €ìœ„í—˜ ìì‚°ìœ¼ë¡œ ë³´ìœ ")

            report.append("\nì°¸ê³ : ì´ ë³´ê³ ì„œëŠ” íˆ¬ì ì°¸ê³ ìš©ì´ë©°, ì‹¤ì œ íˆ¬ì ê²°ì •ì€ ë³¸ì¸ì˜ íŒë‹¨ì— ë”°ë¼ ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.")

            return "\n".join(report)

        elif format == 'html':
            # HTML í˜•ì‹ ë³´ê³ ì„œ (ì¢€ ë” ì‹œê°ì ìœ¼ë¡œ ë³´ê¸° ì¢‹ê²Œ)
            html = []
            html.append("<html><head>")
            html.append("<style>")
            html.append("body { font-family: Arial, sans-serif; margin: 20px; }")
            html.append("h1, h2 { color: #2c3e50; }")
            html.append("table { border-collapse: collapse; width: 100%; margin-bottom: 20px; }")
            html.append("th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }")
            html.append("th { background-color: #f2f2f2; color: #333; }")
            html.append("tr:nth-child(even) { background-color: #f9f9f9; }")
            html.append(".buy { color: #27ae60; font-weight: bold; }")
            html.append(".sell { color: #e74c3c; font-weight: bold; }")
            html.append(".summary-box { background-color: #f8f9fa; border: 1px solid #ddd; padding: 15px; border-radius: 5px; margin-bottom: 20px; }")
            html.append("</style>")
            html.append("</head><body>")

            # í—¤ë” ë° ìš”ì•½
            from datetime import datetime
            html.append(f"<h1>ì£¼ì‹ ë¶„ì„ ë³´ê³ ì„œ</h1>")
            html.append(f"<p>ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M')}</p>")

            # ìš”ì•½ í†µê³„
            valid_results = [r for r in self.analysis_results.values() if r is not None]
            all_returns = [result['backtest']['total_return'] for result in valid_results]
            all_accuracies = [result['accuracy'] for result in valid_results]
            all_sharpes = [result['backtest']['sharpe_ratio'] for result in valid_results]
            all_win_rates = [result['backtest']['win_rate'] for result in valid_results]

            html.append("<div class='summary-box'>")
            html.append("<h2>ìš”ì•½ í†µê³„</h2>")
            html.append("<table>")
            html.append("<tr><th>ì§€í‘œ</th><th>í‰ê· ê°’</th></tr>")
            html.append(f"<tr><td>ë¶„ì„ ì¢…ëª© ìˆ˜</td><td>{len(valid_results)}</td></tr>")
            html.append(f"<tr><td>ë§¤ìˆ˜ ì‹ í˜¸ ì¢…ëª© ìˆ˜</td><td>{len(buy_signals)} ({len(buy_signals) / len(valid_results) * 100:.2f}%)</td></tr>")
            html.append(f"<tr><td>í‰ê·  ë°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥ </td><td>{np.mean(all_returns):.4f} ({np.mean(all_returns) * 100:.2f}%)</td></tr>")
            html.append(f"<tr><td>í‰ê·  ëª¨ë¸ ì •í™•ë„</td><td>{np.mean(all_accuracies):.4f} ({np.mean(all_accuracies) * 100:.2f}%)</td></tr>")
            html.append(f"<tr><td>í‰ê·  ìƒ¤í”„ ë¹„ìœ¨</td><td>{np.mean(all_sharpes):.4f}</td></tr>")
            html.append(f"<tr><td>í‰ê·  ìŠ¹ë¥ </td><td>{np.mean(all_win_rates):.4f} ({np.mean(all_win_rates) * 100:.2f}%)</td></tr>")
            html.append("</table>")
            html.append("</div>")

            # ì¢…í•© ì ìˆ˜ ìƒìœ„ ì¢…ëª©
            html.append("<h2>ì¢…í•© ì ìˆ˜ ìƒìœ„ ì¢…ëª©</h2>")
            html.append("<table>")
            html.append("<tr><th>ìˆœìœ„</th><th>ì¢…ëª©ì½”ë“œ</th><th>ì¢…ëª©ëª…</th><th>ì¢…í•©ì ìˆ˜</th><th>ë°±í…ŒìŠ¤íŠ¸ìˆ˜ìµë¥ </th><th>ì •í™•ë„</th><th>ìƒ¤í”„ë¹„ìœ¨</th><th>ì˜ˆì¸¡ì‹ í˜¸</th></tr>")

            for i, (_, row) in enumerate(top_combined.iterrows(), 1):
                code = row['code']
                company = row['company']
                combined_score = row['combined_score']
                backtest_return = row['backtest_return'] * 100
                accuracy = row['accuracy'] * 100
                sharpe = row['sharpe_ratio']
                signal = row['prediction_signal']

                signal_class = "buy" if signal == "ë§¤ìˆ˜" else "sell" if signal == "ë§¤ë„" else ""

                html.append(f"<tr>")
                html.append(f"<td>{i}</td>")
                html.append(f"<td>{code}</td>")
                html.append(f"<td>{company}</td>")
                html.append(f"<td>{combined_score:.3f}</td>")
                html.append(f"<td>{backtest_return:.2f}%</td>")
                html.append(f"<td>{accuracy:.2f}%</td>")
                html.append(f"<td>{sharpe:.2f}</td>")
                html.append(f"<td class='{signal_class}'>{signal}</td>")
                html.append(f"</tr>")

            html.append("</table>")

            # ë°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥  ìƒìœ„ ì¢…ëª©
            html.append("<h2>ë°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥  ìƒìœ„ ì¢…ëª©</h2>")
            html.append("<table>")
            html.append("<tr><th>ìˆœìœ„</th><th>ì¢…ëª©ì½”ë“œ</th><th>ì¢…ëª©ëª…</th><th>ìˆ˜ìµë¥ </th><th>ì •í™•ë„</th><th>ìƒ¤í”„ë¹„ìœ¨</th><th>ìŠ¹ë¥ </th><th>ì˜ˆì¸¡ì‹ í˜¸</th></tr>")

            for i, (_, row) in enumerate(top_backtest.iterrows(), 1):
                code = row['code']
                company = row['company']
                backtest_return = row['backtest_return'] * 100
                accuracy = row['accuracy'] * 100
                sharpe = row['sharpe_ratio']
                win_rate = row['win_rate'] * 100
                signal = row['prediction_signal']

                signal_class = "buy" if signal == "ë§¤ìˆ˜" else "sell" if signal == "ë§¤ë„" else ""

                html.append(f"<tr>")
                html.append(f"<td>{i}</td>")
                html.append(f"<td>{code}</td>")
                html.append(f"<td>{company}</td>")
                html.append(f"<td>{backtest_return:.2f}%</td>")
                html.append(f"<td>{accuracy:.2f}%</td>")
                html.append(f"<td>{sharpe:.2f}</td>")
                html.append(f"<td>{win_rate:.2f}%</td>")
                html.append(f"<td class='{signal_class}'>{signal}</td>")
                html.append(f"</tr>")

            html.append("</table>")

            # ë§¤ìˆ˜ ì‹ í˜¸ ì¢…ëª© (ì‹ ë¢°ë„ìˆœ)
            html.append("<h2>ë§¤ìˆ˜ ì‹ í˜¸ ì¢…ëª© (ì‹ ë¢°ë„ìˆœ)</h2>")
            html.append("<table>")
            html.append("<tr><th>ì¢…ëª©ì½”ë“œ</th><th>ì¢…ëª©ëª…</th><th>ì‹ ë¢°ë„</th><th>ë°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥ </th><th>ì •í™•ë„</th><th>ìŠ¹ë¥ </th><th>ìµœëŒ€ì†ì‹¤</th></tr>")

            for result in buy_signals_sorted[:min(20, len(buy_signals_sorted))]:
                code = result['stock_code']
                company = result.get('company_name', code)
                confidence = result.get('prediction_confidence', 0) * 100
                backtest_return = result['backtest']['total_return'] * 100
                accuracy = result['accuracy'] * 100
                win_rate = result['backtest']['win_rate'] * 100
                max_drawdown = result['backtest']['max_drawdown'] * 100

                # ì‹ ë¢°ë„ì— ë”°ë¥¸ ê°•ì¡°
                confidence_style = ""
                if confidence >= 80:
                    confidence_style = "style='font-weight: bold; color: #27ae60;'"
                elif confidence >= 70:
                    confidence_style = "style='font-weight: bold; color: #2980b9;'"

                html.append(f"<tr>")
                html.append(f"<td>{code}</td>")
                html.append(f"<td>{company}</td>")
                html.append(f"<td {confidence_style}>{confidence:.2f}%</td>")
                html.append(f"<td>{backtest_return:.2f}%</td>")
                html.append(f"<td>{accuracy:.2f}%</td>")
                html.append(f"<td>{win_rate:.2f}%</td>")
                html.append(f"<td>{max_drawdown:.2f}%</td>")
                html.append(f"</tr>")

            html.append("</table>")

            # íˆ¬ì ì „ëµ ì œì•ˆ
            html.append("<h2>íˆ¬ì ì „ëµ ì œì•ˆ</h2>")
            html.append("<div class='summary-box'>")

            # ì‹œì¥ ìƒí™© ë¶„ì„
            market_bullish = len([r for r in buy_signals if r.get('prediction_confidence', 0) > 0.7]) > len(buy_signals) / 3

            if market_bullish:
                html.append("<p>í˜„ì¬ ë¶„ì„ ê²°ê³¼ëŠ” ì „ë°˜ì ìœ¼ë¡œ <strong>ìƒìŠ¹ ì¶”ì„¸</strong>ë¥¼ ì‹œì‚¬í•©ë‹ˆë‹¤.</p>")
                if len(buy_signals) > 10:
                    html.append("<p>ë‹¤ìˆ˜ì˜ ë§¤ìˆ˜ ì‹ í˜¸ê°€ ìˆì–´, ë‹¤ìŒê³¼ ê°™ì€ ê³ ë ¤ì‚¬í•­ì„ ì œì•ˆí•©ë‹ˆë‹¤:</p>")
                    html.append("<ol>")
                    html.append("<li><strong>í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì‚°:</strong> ë§¤ìˆ˜ ì‹ í˜¸ ìƒìœ„ 5-10ê°œ ì¢…ëª©ì— ìë³¸ì„ ë¶„ì‚° íˆ¬ì</li>")
                    html.append("<li><strong>ë‹¨ê³„ì  ì§„ì…:</strong> ì „ì²´ íˆ¬ìê¸ˆì˜ 60%ë¥¼ ì´ˆê¸°ì— íˆ¬ìí•˜ê³ , ë‚˜ë¨¸ì§€ëŠ” ì¶”ê°€ í•˜ë½ ì‹œ ë¶„í•  ë§¤ìˆ˜</li>")
                    html.append("<li><strong>ì² ì €í•œ ì†ì ˆ:</strong> ê° ì¢…ëª©ë³„ 3% ì†ì ˆë¼ì¸ ì„¤ì •</li>")
                    html.append("</ol>")
                else:
                    html.append("<p>ì œí•œëœ ë§¤ìˆ˜ ì‹ í˜¸ë§Œ ìˆì–´, ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤:</p>")
                    html.append("<ol>")
                    html.append("<li><strong>ì„ ë³„ì  íˆ¬ì:</strong> ë§¤ìˆ˜ ì‹ í˜¸ ì¤‘ ì¢…í•© ì ìˆ˜ ìƒìœ„ 3-5ê°œ ì¢…ëª©ì—ë§Œ ì§‘ì¤‘</li>")
                    html.append("<li><strong>ìë³¸ ë³´ì¡´:</strong> ì „ì²´ íˆ¬ìê¸ˆì˜ 30-40%ë§Œ íˆ¬ìí•˜ê³  ë‚˜ë¨¸ì§€ëŠ” í˜„ê¸ˆ ë³´ìœ </li>")
                    html.append("</ol>")
            else:
                html.append("<p>í˜„ì¬ ë¶„ì„ ê²°ê³¼ëŠ” ì‹œì¥ì˜ <strong>ë¶ˆí™•ì‹¤ì„±</strong>ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.</p>")
                html.append("<ol>")
                html.append("<li><strong>ë°©ì–´ì  í¬ì§€ì…˜:</strong> ë§¤ìˆ˜ ì‹ í˜¸ê°€ ì œí•œì ì´ë¯€ë¡œ ì „ì²´ ìë³¸ì˜ 20-30%ë§Œ íˆ¬ì ê³ ë ¤</li>")
                html.append("<li><strong>ì•ˆì „ ìì‚° ìœ ì§€:</strong> ë‚˜ë¨¸ì§€ ìë³¸ì€ í˜„ê¸ˆ ë˜ëŠ” ì €ìœ„í—˜ ìì‚°ìœ¼ë¡œ ë³´ìœ </li>")
                html.append("</ol>")

            html.append("<p><em>ì°¸ê³ : ì´ ë³´ê³ ì„œëŠ” íˆ¬ì ì°¸ê³ ìš©ì´ë©°, ì‹¤ì œ íˆ¬ì ê²°ì •ì€ ë³¸ì¸ì˜ íŒë‹¨ì— ë”°ë¼ ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.</em></p>")
            html.append("</div>")

            html.append("</body></html>")

            return "\n".join(html)

        else:
            raise ValueError("ì§€ì›ë˜ì§€ ì•ŠëŠ” ë³´ê³ ì„œ í˜•ì‹ì…ë‹ˆë‹¤. 'text' ë˜ëŠ” 'html'ì„ ì‚¬ìš©í•˜ì„¸ìš”.")

# í†µí•© ë°ì´í„° ì†ŒìŠ¤ ê¸°ëŠ¥
def integrate_multiple_data_sources(stock_code):
    """ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ë” ê°•ë ¥í•œ ì˜ˆì¸¡ ì„±ëŠ¥ ì œê³µ"""
    # Yahoo Finance ë°ì´í„°
    def download_yahoo_finance(stock_code):
        ticker = f"{stock_code}.KS"
        session=requests.Session(impersonate="chrome")
        stock = yf.Ticker(ticker,session=session)
        df = stock.history(period="5y")  # 5ë…„ ë°ì´í„°
        df.reset_index(inplace=True)
        return df

    # ë„¤ì´ë²„ ê¸ˆìœµ ë°ì´í„° (ì˜ˆì‹œ)
    def download_naver_finance(stock_code):
        # ì´ í•¨ìˆ˜ëŠ” ì‹¤ì œ êµ¬í˜„ì´ í•„ìš” (ì›¹ ìŠ¤í¬ë˜í•‘ ë“±)
        # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œë§Œ ì œê³µ
        print("ë„¤ì´ë²„ ê¸ˆìœµ ë°ì´í„° ë‹¤ìš´ë¡œë“œëŠ” ì‹¤ì œ êµ¬í˜„ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return None

    # ë°ì´í„° ê²°í•©
    def merge_data_sources(yahoo_data, naver_data):
        if naver_data is None:
            return yahoo_data

        # ì‹¤ì œ ë°ì´í„° ê²°í•© ë¡œì§ êµ¬í˜„ í•„ìš”
        # ì´ ë¶€ë¶„ì€ ë‘ ë°ì´í„° ì†ŒìŠ¤ì˜ í˜•ì‹ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤
        return yahoo_data

    # Yahoo Finance ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    yahoo_data = download_yahoo_finance(stock_code)

    # ë„¤ì´ë²„ ê¸ˆìœµ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ì˜ˆì‹œ)
    naver_data = download_naver_finance(stock_code)

    # ë°ì´í„° ê²°í•©
    combined_data = merge_data_sources(yahoo_data, naver_data)

    return combined_data

def setup_gpu_turbo_mode():
      """GPU í„°ë³´ ëª¨ë“œ ì„¤ì •"""
      print("ğŸ”¥ GPU í„°ë³´ ëª¨ë“œ ì„¤ì • ì¤‘...")
      
      try:
          import torch
          if torch.cuda.is_available():
              # GPU ë©”ëª¨ë¦¬ í’€ ì„¤ì •
              torch.cuda.empty_cache()
              torch.cuda.set_per_process_memory_fraction(0.95)  # GPU ë©”ëª¨ë¦¬ 95% ì‚¬ìš©
              
              # CUDA ì„¤ì • ìµœì í™”
              import os
              os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # ë¹„ë™ê¸° ì‹¤í–‰
              os.environ['CUDA_CACHE_DISABLE'] = '0'    # ìºì‹œ í™œì„±í™”
              
              print("âœ… GPU í„°ë³´ ëª¨ë“œ í™œì„±í™” ì™„ë£Œ")
              
              # GPU ì •ë³´ ì¶œë ¥
              gpu_name = torch.cuda.get_device_name(0)
              gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
              print(f"ğŸš€ GPU: {gpu_name}")
              print(f"ğŸ”¥ ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB")
              
          else:
              print("âŒ GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
              
      except Exception as e:
          print(f"âš ï¸ GPU ì„¤ì • ì˜¤ë¥˜: {e}")

def monitor_gpu_usage():
    """GPU ì‚¬ìš©ëŸ‰ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§"""
    try:
        import torch
        if torch.cuda.is_available():
            memory_used = torch.cuda.memory_allocated(0) / 1024**3
            memory_cached = torch.cuda.memory_reserved(0) / 1024**3
            memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3
                
            usage_percent = (memory_used / memory_total) * 100
                
            print(f"ğŸ“Š GPU ì‹¤ì‹œê°„ ì‚¬ìš©ëŸ‰:")
            print(f"   ğŸ’¾ ì‚¬ìš© ì¤‘: {memory_used:.2f}GB")
            print(f"   ğŸ“¦ ìºì‹œë¨: {memory_cached:.2f}GB") 
            print(f"   ğŸ”¥ ì‚¬ìš©ë¥ : {usage_percent:.1f}%")
                
            if usage_percent > 90:
                print("âš ï¸ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ê²½ê³ !")
            elif usage_percent > 70:
                print("âœ… GPU ë©”ëª¨ë¦¬ ìµœì  ì‚¬ìš© ì¤‘")
            else:
                print("ğŸš€ GPU ë©”ëª¨ë¦¬ ì—¬ìœ  ìˆìŒ")
                    
    except Exception as e:
        print(f"GPU ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    # GPU ìµœì í™” ì„¤ì •
    setup_gpu_turbo_mode()
    
    try:
        import warnings
        warnings.filterwarnings("ignore")
        
        analyzer = StockAnalyzer()
        krx_stocks = analyzer.get_krx_stock_codes()
        
        # ğŸ”¥ ìµœì í™”ëœ ë¶„ì„ (ì •í™•ë„ ìœ ì§€)
        results = analyzer.analyze_in_batches(
            stock_codes=krx_stocks,
            batch_size=100,              # GPU ìµœì í™” ìë™
            period='2y',                  # ë¹ ë¥¸ ë¶„ì„
            prediction_period=5,
            workers=1,                    # GPU ì§‘ì¤‘
            advanced_features=True        # ğŸ”¥ Trueë¡œ ë³µì› (ì •í™•ë„ ìœ„í•´)
        )
        
        # GPU ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
        monitor_gpu_usage()
        try:
            print("ì „ì²´ ì£¼ì‹ ë¶„ì„ ì‹œì‘...")
                
            try:
                import html5lib
                print("html5lib íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            except ImportError:
                print("ê²½ê³ : html5lib íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
                print("pip install html5lib ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")

            # matplotlib ë°±ì—”ë“œ ì„¤ì •
            import matplotlib
            matplotlib.use('Agg')

            import warnings
            warnings.filterwarnings("ignore", message="Dataset is empty")
            warnings.filterwarnings("ignore", message="contains only positive or negative samples")

            # StockAnalyzer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            analyzer = StockAnalyzer()

            # KRX ì¢…ëª© ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
            krx_stocks = analyzer.get_krx_stock_codes()
            print(f"ì´ {len(krx_stocks)}ê°œ ì¢…ëª© ì¡°íšŒë¨")

            # ë¶„ì„í•  ìµœëŒ€ ì¢…ëª© ìˆ˜ ì„¤ì •
            max_stocks = None  # 30  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 30ê°œ, ì „ì²´ ë¶„ì„ì€ Noneìœ¼ë¡œ ë³€ê²½

            # ëª¨ë¸ ì‹ ë¢°ë„ ë° ê±°ë˜ ì„ê³„ê°’ ì„¤ì •
            buy_confidence_threshold = 0.55  # ë§¤ìˆ˜ í™•ì‹ ë„ ì„ê³„ê°’ (55%)
            sell_confidence_threshold = 0.55  # ë§¤ë„ í™•ì‹ ë„ ì„ê³„ê°’ (55%)
            min_accuracy = 0.55  # ìµœì†Œ ëª¨ë¸ ì •í™•ë„ (55%)
            min_win_rate = 0.5  # ìµœì†Œ ìŠ¹ë¥  (50%)

            # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ëª¨ë“  ì¢…ëª© ë¶„ì„ (ê°œì„ : 5ë…„ ë°ì´í„° ì‚¬ìš©)
            # results = analyzer.analyze_all_stocks_parallel(
            #     stock_codes=krx_stocks,
            #     period='2y',  # 1yì—ì„œ 5yë¡œ ë³€ê²½
            #     max_stocks=max_stocks,
            #     prediction_period=5,
            #     workers=4 # ì‘ì—…ì ìˆ˜
            # )

            results = analyzer.analyze_in_batches(
                stock_codes=krx_stocks,
                batch_size=100,  # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ìë™ ìµœì í™”
                period='2y',    
                prediction_period=5,
                workers=1,       # GPU ì§‘ì¤‘ í™œìš©ì„ ìœ„í•´ ë‹¨ì¼ ì›Œì»¤
                advanced_features=False  
            )

            # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
            results_data = []
            for code, result in results.items():
                if result is None:
                    continue

                # ì˜ˆì¸¡ ì‹ ë¢°ë„ ë° ë°©í–¥ ê°€ì ¸ì˜¤ê¸°
                prediction_signal = result.get('prediction_signal', '')
                prediction_confidence = result.get('prediction_confidence', 0)
                accuracy = result.get('accuracy', 0)
                win_rate = result.get('backtest', {}).get('win_rate', 0)

                # ê±°ë˜ ê²°ì • (ë§¤ìˆ˜/ë§¤ë„/ê´€ë§)
                trading_decision = "ê´€ë§"
                action_reason = ""

                # ë§¤ìˆ˜ ì‹ í˜¸ (í™•ì‹ ë„, ì •í™•ë„, ìŠ¹ë¥  ëª¨ë‘ ì„ê³„ê°’ ì´ìƒì¼ ë•Œ)
                if (prediction_signal == "ë§¤ìˆ˜" and
                    (prediction_confidence >= buy_confidence_threshold * 0.95 or  # ì•½ê°„ ë‚®ì¶¤ (ë” ë§ì€ ê¸°íšŒ í¬ì°©)
                    (accuracy >= min_accuracy and win_rate >= min_win_rate))):
                    trading_decision = "ë§¤ìˆ˜"
                    action_reason = f"í™•ì‹ ë„({prediction_confidence:.2%})ê°€ ì¢‹ê±°ë‚˜ ëª¨ë¸ ì„±ëŠ¥(ì •í™•ë„:{accuracy:.2%}, ìŠ¹ë¥ :{win_rate:.2%})ì´ ì–‘í˜¸í•¨"# ë§¤ë„ ì‹ í˜¸ (í™•ì‹ ë„, ì •í™•ë„, ìŠ¹ë¥  ëª¨ë‘ ì„ê³„ê°’ ì´ìƒì¼ ë•Œ)
                elif (prediction_signal == "ë§¤ë„" and
                    prediction_confidence >= sell_confidence_threshold and
                    accuracy >= min_accuracy and
                    win_rate >= min_win_rate):
                    trading_decision = "ë§¤ë„"
                    action_reason = f"í™•ì‹ ë„({prediction_confidence:.2%})ê°€ ë†’ê³  ëª¨ë¸ ì„±ëŠ¥(ì •í™•ë„:{accuracy:.2%}, ìŠ¹ë¥ :{win_rate:.2%})ì´ ì¢‹ìŒ"

                # ê´€ë§ (ê¸°ì¤€ ë¯¸ë‹¬)
                else:
                    reasons = []
                    if prediction_confidence < max(buy_confidence_threshold, sell_confidence_threshold):
                        reasons.append(f"í™•ì‹ ë„ ë¶€ì¡±({prediction_confidence:.2%})")
                    if accuracy < min_accuracy:
                        reasons.append(f"ì •í™•ë„ ë¶€ì¡±({accuracy:.2%})")
                    if win_rate < min_win_rate:
                        reasons.append(f"ìŠ¹ë¥  ë¶€ì¡±({win_rate:.2%})")
                    if reasons:
                        action_reason = ", ".join(reasons)
                    else:
                        action_reason = "ê¸°ì¤€ ë¯¸ë‹¬"

                # ë§¤ìˆ˜ í›„ ëª©í‘œê°€ ë° ì†ì ˆê°€ ê³„ì‚°
                current_price = result.get('latest_price', 0)
                avg_range = result.get('backtest', {}).get('avg_daily_range', 0)

                if avg_range == 0:  # avg_daily_rangeê°€ ì—†ìœ¼ë©´ í˜„ì¬ê°€ì˜ 3% ì‚¬ìš©
                    avg_range = current_price * 0.03

                # ë§¤ìˆ˜ ì‹œë‚˜ë¦¬ì˜¤: ìµì ˆê°€/ì†ì ˆê°€ ì„¤ì •
                target_price = current_price * 1.1  # 10% ìƒìŠ¹ ëª©í‘œ
                stop_loss = current_price * 0.95  # 5% í•˜ë½ ì†ì ˆ

                # ì˜ˆìƒ ë³´ìœ  ê¸°ê°„
                holding_period = "5-10 ê±°ë˜ì¼" if prediction_signal == "ë§¤ìˆ˜" else "ì¦‰ì‹œ ë§¤ë„"

                # í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ
                data = {
                    'ì¢…ëª©ì½”ë“œ': code,
                    'ì¢…ëª©ëª…': result.get('company_name', code),
                    'í˜„ì¬ê°€': current_price,
                    'ì˜ˆì¸¡ë°©í–¥': prediction_signal,
                    'ì˜ˆì¸¡í™•ì‹ ë„': prediction_confidence,
                    'ê±°ë˜ê²°ì •': trading_decision,
                    'ê²°ì •ì´ìœ ': action_reason,
                    'ëª©í‘œê°€': round(target_price) if trading_decision == "ë§¤ìˆ˜" else None,
                    'ì†ì ˆê°€': round(stop_loss) if trading_decision == "ë§¤ìˆ˜" else None,
                    'ì˜ˆìƒë³´ìœ ê¸°ê°„': holding_period if trading_decision == "ë§¤ìˆ˜" else None,
                    'ì •í™•ë„': accuracy,
                    'ìŠ¹ë¥ ': win_rate,
                    'ë°±í…ŒìŠ¤íŠ¸ìˆ˜ìµë¥ ': result['backtest']['total_return'] if 'backtest' in result else 0,
                    'ìƒ¤í”„ë¹„ìœ¨': result['backtest']['sharpe_ratio'] if 'backtest' in result else 0
                }
                results_data.append(data)

            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            all_results_df = pd.DataFrame(results_data)

            # ê±°ë˜ ê²°ì •ë³„ë¡œ ë¶„ë¥˜
            buy_recommendations = all_results_df[all_results_df['ê±°ë˜ê²°ì •'] == "ë§¤ìˆ˜"].sort_values('ì˜ˆì¸¡í™•ì‹ ë„', ascending=False)
            sell_recommendations = all_results_df[all_results_df['ê±°ë˜ê²°ì •'] == "ë§¤ë„"].sort_values('ì˜ˆì¸¡í™•ì‹ ë„', ascending=False)
            hold_recommendations = all_results_df[all_results_df['ê±°ë˜ê²°ì •'] == "ê´€ë§"]

            # ê²°ê³¼ ì €ì¥
            today_date = datetime.now().strftime("%Y%m%d")

            # ê°œì„ : ìµœì í™”ëœ ê²°ê³¼ ì €ì¥
            optimized_file = f"optimized_signals_{today_date}.csv"
            analyzer.save_optimized_results(all_results_df, optimized_file)

            print("\nìƒìœ„ 20ê°œ ìµœì í™” ì¢…ëª© ì¶”ì¶œ ì¤‘...")
            # CSV íŒŒì¼ ë¡œë“œ
            df = pd.read_csv(optimized_file, encoding='utf-8-sig')
            # ë§¤ìˆ˜ ì‹ í˜¸ë§Œ í•„í„°ë§
            buy_signals = df[df['ê±°ë˜ê²°ì •'] == 'ë§¤ìˆ˜']
            # ê° ì§€í‘œì— ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ì¢…í•© ì ìˆ˜ ê³„ì‚°
            buy_signals['ì¢…í•©ì ìˆ˜'] = (
                buy_signals['ì •í™•ë„'] * 0.30 +       # 30% ê°€ì¤‘ì¹˜
                buy_signals['ìŠ¹ë¥ '] * 0.30 +         # 30% ê°€ì¤‘ì¹˜
                buy_signals['ë°±í…ŒìŠ¤íŠ¸ìˆ˜ìµë¥ '] * 0.15 + # 15% ê°€ì¤‘ì¹˜
                buy_signals['ì˜ˆì¸¡í™•ì‹ ë„'] * 0.25      # 25% ê°€ì¤‘ì¹˜ (ìƒí–¥ ì¡°ì •)
            )
            # ì¢…í•© ì ìˆ˜ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 20ê°œ ì¢…ëª© ì¶”ì¶œ
            top_20 = buy_signals.sort_values('ì¢…í•©ì ìˆ˜', ascending=False).head(20)
            # ê²°ê³¼ ì €ì¥
            top_20_file = f"top_20_ìµœì í™”ì¢…ëª©_{today_date}.csv"
            top_20.to_csv(top_20_file, index=False, encoding='utf-8-sig')
            print(f"\nìƒìœ„ 20ê°œ ìµœì í™” ì¢…ëª©ì´ {top_20_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

            # ì½˜ì†”ì— ìƒìœ„ 20ê°œ ì¢…ëª© ì¶œë ¥
            print("\n" + "="*100)
            print(f"ì¢…í•© ì ìˆ˜ ê¸°ì¤€ ìƒìœ„ 20ê°œ ì¢…ëª©")
            print("="*100)

            display_cols = ['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'ëª©í‘œê°€', 'ì†ì ˆê°€', 'ì •í™•ë„', 'ìŠ¹ë¥ ', 'ë°±í…ŒìŠ¤íŠ¸ìˆ˜ìµë¥ ', 'ì¢…í•©ì ìˆ˜']
            # ì¶œë ¥ í˜•ì‹ ì§€ì •
            formatted_top_20 = top_20[display_cols].copy()
            for col in ['ì •í™•ë„', 'ìŠ¹ë¥ ', 'ì˜ˆì¸¡í™•ì‹ ë„', 'ì¢…í•©ì ìˆ˜']:
                if col in formatted_top_20.columns:
                    formatted_top_20[col] = formatted_top_20[col].apply(lambda x: f"{x:.2%}" if pd.notnull(x) else "")

            for col in ['í˜„ì¬ê°€', 'ëª©í‘œê°€', 'ì†ì ˆê°€']:
                if col in formatted_top_20.columns:
                    formatted_top_20[col] = formatted_top_20[col].apply(lambda x: f"{int(x):,}" if pd.notnull(x) else "")

            print(formatted_top_20.to_string(index=False))

            # 1. ë§¤ìˆ˜ ì¶”ì²œ ì¢…ëª© ì €ì¥
            if len(buy_recommendations) > 0:
                buy_file = f"buy_signals_{today_date}.csv"
                buy_recommendations.to_csv(buy_file, index=False, encoding='utf-8-sig')
                print(f"\në§¤ìˆ˜ ì¶”ì²œ ì¢…ëª© {len(buy_recommendations)}ê°œê°€ {buy_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

                # ì½˜ì†”ì— ë§¤ìˆ˜ ì¶”ì²œ ìƒìœ„ ì¢…ëª© ì¶œë ¥
                print("\n" + "="*100)
                print(f"ë§¤ìˆ˜ ì¶”ì²œ ìƒìœ„ ì¢…ëª© (ì´ {len(buy_recommendations)}ê°œ)")
                print("="*100)

                display_cols = ['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'ì˜ˆì¸¡í™•ì‹ ë„', 'ëª©í‘œê°€', 'ì†ì ˆê°€', 'ì˜ˆìƒë³´ìœ ê¸°ê°„', 'ì •í™•ë„', 'ìŠ¹ë¥ ']
                top_buys = buy_recommendations[display_cols].head(min(10, len(buy_recommendations)))

                # ì¶œë ¥ í˜•ì‹ ì§€ì •
                for col in ['ì˜ˆì¸¡í™•ì‹ ë„', 'ì •í™•ë„', 'ìŠ¹ë¥ ']:
                    if col in top_buys.columns:
                        top_buys[col] = top_buys[col].apply(lambda x: f"{x:.2%}")

                for col in ['í˜„ì¬ê°€', 'ëª©í‘œê°€', 'ì†ì ˆê°€']:
                    if col in top_buys.columns:
                        top_buys[col] = top_buys[col].apply(lambda x: f"{int(x):,}" if pd.notnull(x) else "")

                print(top_buys.to_string(index=False))
            else:
                print("\në§¤ìˆ˜ ì¶”ì²œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

            # 2. ë§¤ë„ ì¶”ì²œ ì¢…ëª© ì €ì¥
            if len(sell_recommendations) > 0:
                sell_file = f"sell_signals_{today_date}.csv"
                sell_recommendations.to_csv(sell_file, index=False, encoding='utf-8-sig')
                print(f"\në§¤ë„ ì¶”ì²œ ì¢…ëª© {len(sell_recommendations)}ê°œê°€ {sell_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

                # ì½˜ì†”ì— ë§¤ë„ ì¶”ì²œ ìƒìœ„ ì¢…ëª© ì¶œë ¥
                print("\n" + "="*100)
                print(f"ë§¤ë„ ì¶”ì²œ ìƒìœ„ ì¢…ëª© (ì´ {len(sell_recommendations)}ê°œ)")
                print("="*100)

                display_cols = ['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…', 'í˜„ì¬ê°€', 'ì˜ˆì¸¡í™•ì‹ ë„', 'ì •í™•ë„', 'ìŠ¹ë¥ ']
                top_sells = sell_recommendations[display_cols].head(min(10, len(sell_recommendations)))

                # ì¶œë ¥ í˜•ì‹ ì§€ì •
                for col in ['ì˜ˆì¸¡í™•ì‹ ë„', 'ì •í™•ë„', 'ìŠ¹ë¥ ']:
                    if col in top_sells.columns:
                        top_sells[col] = top_sells[col].apply(lambda x: f"{x:.2%}")

                if 'í˜„ì¬ê°€' in top_sells.columns:
                    top_sells['í˜„ì¬ê°€'] = top_sells['í˜„ì¬ê°€'].apply(lambda x: f"{int(x):,}")

                print(top_sells.to_string(index=False))
            else:
                print("\në§¤ë„ ì¶”ì²œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

            # 3. ì „ì²´ ë¶„ì„ ê²°ê³¼ ì €ì¥
            all_results_file = f"all_stock_analysis_{today_date}.csv"
            all_results_df.to_csv(all_results_file, index=False, encoding='utf-8-sig')
            print(f"\nì „ì²´ ë¶„ì„ ê²°ê³¼ {len(all_results_df)}ê°œê°€ {all_results_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

            print("\në¶„ì„ ë° ê±°ë˜ ì‹ í˜¸ ìƒì„± ì™„ë£Œ!")

        except Exception as e:
            print(f"\nì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
    except Exception as e:
        print(f"ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
