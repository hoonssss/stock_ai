import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import pickle
import warnings
import os
from curl_cffi import requests
import yfinance as yf

from matplotlib.dates import DateFormatter

# 데이터 처리 및 모델링
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, RandomizedSearchCV, TimeSeriesSplit
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, r2_score
from sklearn.metrics import roc_curve
import xgboost as xgb
from xgboost import plot_importance

# 기술적 지표 계산을 위한 라이브러리
import talib
from talib import abstract

import yfinance as yf
import time
from tqdm import tqdm

# 병렬 처리
from concurrent.futures import ProcessPoolExecutor, as_completed

warnings.filterwarnings('ignore')

class StockPredictionModel:
    def __init__(self, prediction_type='classification', prediction_period=5, confidence_threshold=0.6):
        """
        주식 예측 모델 초기화

        Parameters:
        -----------
        prediction_type : str
            'classification' (상승/하락 분류) 또는 'regression' (가격 예측)
        prediction_period : int
            예측 기간 (일)
        confidence_threshold : float
            트레이딩 결정을 위한 확신도 임계값 (0.0 ~ 1.0)
        """
        self.prediction_type = prediction_type
        self.prediction_period = prediction_period
        self.confidence_threshold = confidence_threshold
        self.model = None
        self.scaler = StandardScaler()
        self.feature_names = []
        self.test_accuracy = None
        
        # 🔥 GPU 메모리 프리로딩
        self.setup_gpu_memory()

    def setup_gpu_memory(self):
        """GPU 메모리 사전 최적화"""
        try:
            import torch
            if torch.cuda.is_available():
                # 메모리 풀 설정
                torch.cuda.set_per_process_memory_fraction(0.98)
                torch.cuda.empty_cache()
                
                # 메모리 할당 전략 최적화
                import os
                os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'
                
                # GPU 워밍업
                dummy = torch.randn(2000, 2000).cuda()
                dummy = dummy @ dummy.T  # 행렬 연산으로 GPU 활성화
                del dummy
                torch.cuda.empty_cache()
                
                print("✅ GPU 메모리 최적화 완료")
        except Exception as e:
            print(f"⚠️ GPU 메모리 설정 오류: {e}")

    def check_xgboost_version(self):
        """XGBoost 버전 확인 및 호환 방식 결정"""
        import xgboost as xgb
        version = xgb.__version__
        major_version = int(version.split('.')[0])
        
        print(f"🔍 XGBoost 버전: {version}")
        
        if major_version >= 2:
            return 'v2'  # callbacks 방식
        else:
            return 'v1'  # early_stopping_rounds 방식

    def train_with_xgb_compatibility(self, model):
        """XGBoost 버전에 맞는 학습 방식"""
        eval_set = [(self.X_train, self.y_train), (self.X_test, self.y_test)]
        xgb_version = self.check_xgboost_version()
        
        try:
            if xgb_version == 'v2':
                # XGBoost 2.x 방식
                model.fit(
                    self.X_train, self.y_train,
                    verbose=False
                )
                print("✅ XGBoost 2.x 방식 성공")
            else:
                # XGBoost 1.x 방식
                model.fit(
                    self.X_train, self.y_train,
                    eval_set=eval_set,
                    early_stopping_rounds=30,
                    verbose=False
                )
                print("✅ XGBoost 1.x 방식 성공")
                
        except Exception as e:
            print(f"⚠️ 조기 종료 실패, 기본 학습: {e}")
            model.fit(self.X_train, self.y_train, verbose=False)
        
        return model

    def load_data(self, filepath=None, df=None):
        """
        데이터 로드 (파일 또는 데이터프레임)

        Parameters:
        -----------
        filepath : str, optional
            데이터 파일 경로 (CSV)
        df : DataFrame, optional
            직접 데이터프레임 전달

        Returns:
        --------
        DataFrame
            로드된 주가 데이터
        """
        if filepath is not None:
            self.data = pd.read_csv(filepath)
            # 날짜 형식 변환
            self.data['Date'] = pd.to_datetime(self.data['Date'])
            self.data = self.data.sort_values('Date')
        elif df is not None:
            self.data = df.copy()
            if 'Date' in self.data.columns:
                self.data['Date'] = pd.to_datetime(self.data['Date'])
                self.data = self.data.sort_values('Date')
        else:
            raise ValueError("파일 경로 또는 데이터프레임을 제공해야 합니다.")

        # OHLCV 데이터 존재 확인
        required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
        if not all(col in self.data.columns for col in required_cols):
            raise ValueError(f"데이터에 필요한 열이 없습니다: {required_cols}")

        print(f"데이터 로드 완료: {len(self.data)} 행")
        return self.data

    def optimize_dataframe_memory(self, df):
        """데이터프레임 메모리 사용량 최적화 - Colab Pro용"""
        start_mem = df.memory_usage().sum() / 1024**2

        # float64를 float32로 변환 (메모리 절약)
        for col in df.select_dtypes(include=['float64']).columns:
            df[col] = df[col].astype('float32')

        # int64를 int32로 변환
        for col in df.select_dtypes(include=['int64']).columns:
            if df[col].max() < 2147483647 and df[col].min() > -2147483648:
                df[col] = df[col].astype('int32')

        end_mem = df.memory_usage().sum() / 1024**2
        reduction = (start_mem - end_mem) / start_mem

        print(f"메모리 최적화: {start_mem:.2f} MB → {end_mem:.2f} MB ({reduction:.1%} 감소)")
        return df

    # 유틸리티 함수들
    @staticmethod
    def has_skopt():
        """scikit-optimize 라이브러리 설치 여부 확인"""
        try:
            import skopt
            return True
        except ImportError:
            return False

    @staticmethod
    def has_shap():
        """SHAP 라이브러리 설치 여부 확인"""
        try:
            import shap
            return True
        except ImportError:
            return False
        
    def train_model(self, optimize=True, n_iter=20, advanced_optimize=True):
        """
        모델 학습 메서드 - GPU 최적화 버전 호출
        
        Parameters:
        -----------
        optimize : bool
            하이퍼파라미터 최적화 여부
        n_iter : int
            최적화 반복 횟수
        advanced_optimize : bool
            고급 최적화 여부
        
        Returns:
        --------
        모델 객체
        """
        return self.train_model_gpu_fixed(optimize=optimize, n_iter=n_iter, advanced_optimize=advanced_optimize)

    def train_model_gpu_fixed(self, optimize=True, n_iter=20, advanced_optimize=True):
        """🔥 GPU 성능 극대화 + 정확도 유지"""
        
        if not hasattr(self, 'X_train'):
            raise ValueError("먼저 prepare_data() 메서드를 호출하세요.")

        print("🔥 GPU 최대 성능 모드 시작...")

        # 클래스 비율 확인
        if self.prediction_type == 'classification':
            class_counts = self.y_train.value_counts()
            scale_pos_weight = class_counts[0] / class_counts[1] if len(class_counts) > 1 else 1
        else:
            scale_pos_weight = 1

        # 🔥 GPU 최대 성능 파라미터 (정확도 유지)
        if self.prediction_type == 'classification':
            gpu_params = {
                'device': 'cuda',
                'tree_method': 'hist',
                'objective': 'binary:logistic',
                'eval_metric': 'logloss',
                'learning_rate': 0.05,              # 신중한 학습
                'n_estimators': 1500,               # GPU 활용 증가
                'max_depth': 6,                     # 5→6으로 약간 증가
                'min_child_weight': 5,              # 과적합 방지
                'subsample': 0.8,                   # 0.7→0.8로 약간 증가
                'colsample_bytree': 0.8,            # 0.7→0.8로 약간 증가
                'scale_pos_weight': scale_pos_weight * 1.5,  # 2→1.5로 완화
                'gamma': 0.1,                       # 과적합 방지 추가
                'reg_alpha': 0.1,                   # L1 정규화 추가
                'reg_lambda': 0.2,                  # L2 정규화 강화
                'random_state': 42,
                'verbosity': 1,
                'n_jobs': 1
            }
            model = xgb.XGBClassifier(**gpu_params)
        else:
            gpu_params = {
                'device': 'cuda',
                'tree_method': 'hist',
                'objective': 'reg:squarederror',
                'eval_metric': 'rmse',
                'learning_rate': 0.05,
                'n_estimators': 1500,
                'max_depth': 6,
                'min_child_weight': 5,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'gamma': 0.1,
                'reg_alpha': 0.1,
                'reg_lambda': 0.2,
                'random_state': 42,
                'verbosity': 1,
                'n_jobs': 1
            }
            model = xgb.XGBRegressor(**gpu_params)
        # 🔥 GPU 메모리 최적화
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.set_per_process_memory_fraction(0.98)  # 98% 사용
        except:
            pass

        # 모델 학습
        try:
            model = self.train_with_xgb_compatibility(model)
            print("✅ GPU 최적화 학습 완료")
        except Exception as e:
            print(f"⚠️ 학습 오류: {e}")
            model.fit(self.X_train, self.y_train)

        self.model = model

        # 테스트 정확도 계산 (기존 코드 그대로)
        if self.prediction_type == 'classification':
            y_pred = self.model.predict(self.X_test)
            self.test_accuracy = accuracy_score(self.y_test, y_pred)
        else:
            y_pred = self.model.predict(self.X_test)
            self.test_accuracy = r2_score(self.y_test, y_pred)

        print(f"🎉 GPU 최적화 완료! 정확도: {self.test_accuracy:.4f}")
        return model

    def prepare_data(self, test_size=0.2):
        """
        모델링을 위한 데이터 준비

        Parameters:
        -----------
        test_size : float
            테스트 데이터 비율

        Returns:
        --------
        tuple
            (X_train, X_test, y_train, y_test) 데이터 세트
        """
        if not hasattr(self, 'data_with_features'):
            raise ValueError("먼저 create_features() 메서드를 호출하세요.")

        df = self.data_with_features.copy()

        # 특성 및 타겟 분리
        X = df[self.feature_names]
        y = df['Target']

        # 무한대 값 처리 (inf, -inf를 NaN으로 변환 후 처리)
        X = X.replace([np.inf, -np.inf], np.nan)

        for col in X.columns:
            # 비율 지표는 1로 채움 (중립적 값)
            if 'Ratio' in col:
                X[col] = X[col].fillna(1)
            # 나머지는 0으로 채움
            else:
                X[col] = X[col].fillna(0)

        print(f"무한대 및 NaN 값 처리 완료")

        # 시계열 분할 (최근 데이터를 테스트 세트로)
        split_idx = int(len(df) * (1 - test_size))
        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

        # 날짜 저장 (나중에 시각화에 사용)
        self.test_dates = df['Date'].iloc[split_idx:].reset_index(drop=True)

        # 특성 스케일링
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # DataFrame으로 변환 (특성 이름 유지)
        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)
        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)

        print(f"학습 데이터: {X_train_scaled.shape}, 테스트 데이터: {X_test_scaled.shape}")

        self.X_train, self.X_test, self.y_train, self.y_test = X_train_scaled, X_test_scaled, y_train, y_test
        return X_train_scaled, X_test_scaled, y_train, y_test

    def _check_technical_indicators(self):
        """기술적 지표 확인"""
        # 최근 데이터
        recent_data = self.data_with_features.tail(20)
        latest = recent_data.iloc[-1]

        # 예측 방향
        prediction = 1 if latest.get('PredictionProba', 0.5) > 0.5 else 0
        bullish_prediction = prediction == 1

        # 기술적 지표 확인
        confirmations = {}

        # 1. 이동평균선 확인
        if 'MA_20' in latest and 'MA_50' in latest:
            ma_bullish = latest['Close'] > latest['MA_20'] > latest['MA_50']
            confirmations['이동평균'] = (ma_bullish == bullish_prediction)

        # 2. RSI 확인
        if 'RSI' in latest:
            rsi = latest['RSI']
            if bullish_prediction:
                rsi_confirm = rsi > 50 and rsi < 70  # 상승 추세, 과매수 아님
            else:
                rsi_confirm = rsi < 50 and rsi > 30  # 하락 추세, 과매도 아님
            confirmations['RSI'] = rsi_confirm

        # 3. MACD 확인
        if 'MACD' in latest and 'MACD_Signal' in latest:
            macd_bullish = latest['MACD'] > latest['MACD_Signal']
            confirmations['MACD'] = (macd_bullish == bullish_prediction)

        # 4. 볼린저 밴드 확인
        if 'BB_Position' in latest:
            bb_pos = latest['BB_Position']
            if bullish_prediction:
                bb_confirm = bb_pos > 0.5  # 상단 밴드에 가까움
            else:
                bb_confirm = bb_pos < 0.5  # 하단 밴드에 가까움
            confirmations['볼린저밴드'] = bb_confirm

        # 5. ADX 추세 강도 확인
        if 'ADX' in latest and 'PLUS_DI_14' in latest and 'MINUS_DI_14' in latest:
            adx_strong = latest['ADX'] > 20  # 강한 추세
            trend_bullish = latest['PLUS_DI_14'] > latest['MINUS_DI_14']
            confirmations['ADX'] = adx_strong and (trend_bullish == bullish_prediction)

        return confirmations
    def _get_recent_prediction_errors(self, lookback=20):
        """최근 예측 오차 분석"""
        # 테스트 데이터에서 최근 예측 오차 분석
        if not hasattr(self, 'X_test') or not hasattr(self, 'y_test'):
            return pd.Series([0.02 * self.data['Close'].iloc[-1]])  # 기본값 반환

        # 최근 lookback 개의 샘플만 사용
        X_recent = self.X_test.tail(lookback)
        y_recent = self.y_test.tail(lookback)

        # 예측
        y_pred = self.model.predict(X_recent)

        # 오차 계산
        errors = y_pred - y_recent

        return pd.Series(errors)

    def predict_future(self, days=1, confidence_analysis=True):
        """미래 예측 - 개선된 버전"""
        if self.model is None:
            raise ValueError("먼저 train_model() 메서드를 호출하세요.")

        # 최신 데이터 가져오기
        latest_data = self.data_with_features.iloc[-1]
        latest_date = latest_data['Date']
        latest_price = latest_data['Close']

        print(f"최신 날짜: {latest_date.strftime('%Y-%m-%d')}")
        print(f"최신 가격: {latest_price:.2f}")

        # 예측 결과 저장을 위한 데이터프레임
        predictions_df = pd.DataFrame({
            'Date': [latest_date + timedelta(days=i+1) for i in range(days)],
            'Prediction': [None] * days,
            'Confidence': [None] * days,
            'Upper_Bound': [None] * days,
            'Lower_Bound': [None] * days
        })

        # 1. 개선: 안정적인 특성 추출
        if not all(f in latest_data for f in self.feature_names):
            missing_features = [f for f in self.feature_names if f not in latest_data]
            print(f"경고: {len(missing_features)}개 특성이 최신 데이터에 없습니다. 0으로 대체합니다.")
            features = np.zeros(len(self.feature_names))
            for i, feature in enumerate(self.feature_names):
                if feature in latest_data:
                    features[i] = latest_data[feature]
            features = features.reshape(1, -1)
        else:
            features = latest_data[self.feature_names].values.reshape(1, -1)

        # 2. 개선: 특성 스케일링 안정성 강화
        try:
            features_scaled = self.scaler.transform(features)
        except:
            print("경고: 스케일링 오류, 원본 특성 사용")
            features_scaled = features

        if self.prediction_type == 'classification':
            # 3. 개선: 불확실성 추정 및 신뢰 구간
            try:
                # 상승/하락 확률
                proba = self.model.predict_proba(features_scaled)[0, 1]
                prediction = 1 if proba > 0.5 else 0

                predictions_df.iloc[0, 1] = prediction
                predictions_df.iloc[0, 2] = proba

                # 신뢰 구간 계산 (베타 분포 가정)
                if confidence_analysis:
                    alpha = 2  # 하이퍼파라미터 조정 가능
                    beta = 2
                    conf_level = 0.9

                    # 베이지안 신뢰 구간 (베타 분포)
                    from scipy.stats import beta as beta_dist

                    # 사전 분포에 확률 병합
                    alpha_post = alpha + (proba * 10)
                    beta_post = beta + ((1 - proba) * 10)

                    lower_bound = beta_dist.ppf((1 - conf_level) / 2, alpha_post, beta_post)
                    upper_bound = beta_dist.ppf(1 - (1 - conf_level) / 2, alpha_post, beta_post)

                    predictions_df.iloc[0, 3] = upper_bound
                    predictions_df.iloc[0, 4] = lower_bound

                    print(f"90% 신뢰 구간: [{lower_bound:.4f}, {upper_bound:.4f}]")

                direction = "상승" if prediction == 1 else "하락"
                print(f"향후 {self.prediction_period}일 예측: {direction} (확신도: {proba:.4f})")

                # 4. 개선: 더 다양한 신호 판단
                if proba > 0.8:
                    signal = "강한 매수"
                    strength = "매우 높음"
                elif proba > self.confidence_threshold:
                    signal = "매수"
                    strength = "높음"
                elif proba < 0.2:
                    signal = "강한 매도"
                    strength = "매우 높음"
                elif proba < 0.4:
                    signal = "매도"
                    strength = "중간"
                else:
                    signal = "관망"
                    strength = "낮음"

                print(f"추천 신호: {signal} (신호 강도: {strength})")

                # 추가: 기술적 지표 확인
                if hasattr(self, 'data_with_features'):
                    tech_confirm = self._check_technical_indicators()
                    tech_score = sum(tech_confirm.values())
                    tech_max = len(tech_confirm)

                    print(f"기술적 지표 확인: {tech_score}/{tech_max} 지표가 예측 방향 확인")

                    # 주요 기술적 지표 출력
                    for indicator, confirms in tech_confirm.items():
                        status = "확인" if confirms else "불일치"
                        print(f"  - {indicator}: {status}")
            except Exception as e:
                print(f"예측 오류: {e}")
                predictions_df.iloc[0, 1] = 0
                predictions_df.iloc[0, 2] = 0.5
                print("오류로 인해 기본값(확률 0.5) 사용")
        else:  # regression
            # 가격 예측
            try:
                price_pred = self.model.predict(features_scaled)[0]
                predictions_df.iloc[0, 1] = price_pred

                # 확신도 대신 예상 수익률 계산
                expected_return = price_pred / latest_price - 1
                predictions_df.iloc[0, 2] = expected_return

                # 예측 신뢰 구간 (시계열 모델의 불확실성 고려)
                if confidence_analysis and hasattr(self, 'data_with_features'):
                    # 과거 예측 오차를 기반으로 불확실성 추정
                    recent_errors = self._get_recent_prediction_errors(20)
                    error_std = recent_errors.std()

                    conf_level = 0.9
                    z_score = 1.645  # 90% 신뢰도의 z-점수

                    upper_bound = price_pred + z_score * error_std
                    lower_bound = price_pred - z_score * error_std

                    predictions_df.iloc[0, 3] = upper_bound
                    predictions_df.iloc[0, 4] = lower_bound

                    print(f"90% 신뢰 구간: [{lower_bound:.2f}, {upper_bound:.2f}]")

                print(f"향후 {self.prediction_period}일 예상 가격: {price_pred:.2f}")
                print(f"예상 수익률: {expected_return:.4f} ({expected_return * 100:.2f}%)")

                # 신호 판단 - 더 세밀한 기준
                if expected_return > 0.05:
                    signal = "강한 매수"
                    strength = "매우 높음"
                elif expected_return > 0.01:
                    signal = "매수"
                    strength = "높음"
                elif expected_return < -0.05:
                    signal = "강한 매도"
                    strength = "매우 높음"
                elif expected_return < -0.01:
                    signal = "매도"
                    strength = "중간"
                else:
                    signal = "관망"
                    strength = "낮음"

                print(f"추천 신호: {signal} (신호 강도: {strength})")
            except Exception as e:
                print(f"예측 오류: {e}")
                predictions_df.iloc[0, 1] = latest_price
                predictions_df.iloc[0, 2] = 0
                print("오류로 인해 최신 가격 사용")

        return predictions_df


    # StockPredictionModel 클래스 내에 추가할 개선된 메서드들
    def create_features(self, advanced=True, stock_code=None):
        """특성 엔지니어링 실행 - 개선된 버전"""
        print("특성 엔지니어링 시작...")
        df = self.data.copy()

        # 1. 개선: 재무 정보 특성 추가 및 확장
        if stock_code is not None:
            financial_info = get_financial_info(stock_code)

            # 주요 재무 지표 추가
            for key, value in financial_info.items():
                fin_col_name = f'FIN_{key}'
                df[fin_col_name] = value

                # PER, PBR 등 주요 지표는 가격과의 비율 특성 추가
                if key in ['PER', 'PBR', 'PSR', 'PCR']:
                    df[f'{key}_Ratio'] = df['Close'] / value if value != 0 else 0

                    # 추가: PER, PBR 등의 시장 평균 대비 상대값 (외부 데이터 필요)
                    # df[f'{key}_RelativeToMarket'] = value / market_avg[key] if key in market_avg else 1.0

        # 2. 기본 가격 특성
        df['PrevClose'] = df['Close'].shift(1)
        df['Return'] = df['Close'] / df['PrevClose'] - 1
        df['RangePercent'] = (df['High'] - df['Low']) / df['PrevClose']
        df['GapPercent'] = (df['Open'] - df['PrevClose']) / df['PrevClose']

        # 3. 개선: 심리적 가격대 특성 추가
        df['PriceIntegerRatio'] = (df['Close'] % 1000) / 1000  # 천 단위 가격대 내 위치
        df['PriceRoundNumber'] = (df['Close'] % 1000 < 50).astype(int)  # 천 단위 가격에 가까운지

        # 4. 대상 변수 생성
        if self.prediction_type == 'classification':
            # N일 후 주가가 오를 경우 1, 아니면 0
            future_return = df['Close'].shift(-self.prediction_period) / df['Close'] - 1
            df['Target'] = (future_return > 0).astype(int)

            # 추가: 상승 확률 범주화 (더 세분화된 예측 목표)
            # df['Target_3class'] = pd.qcut(future_return, 3, labels=[0, 1, 2])  # 하락, 보합, 상승
        else:  # regression
            # N일 후 주가
            df['Target'] = df['Close'].shift(-self.prediction_period)

        # 5. 이동평균 특성 - 개선: 비선형 스케일로 다양화
        for period in [5, 10, 20, 50, 100]:
            df[f'MA_{period}'] = df['Close'].rolling(window=period).mean()
            df[f'MA_Ratio_{period}'] = df['Close'] / df[f'MA_{period}']
            df[f'Volume_MA_{period}'] = df['Volume'].rolling(window=period).mean()
            df[f'Volume_Ratio_{period}'] = df['Volume'] / df[f'Volume_MA_{period}']

            # 추가: 주가의 이동평균 교차 시점 포착
            df[f'MA_Cross_{period}'] = ((df['Close'] > df[f'MA_{period}']) &
                                    (df['Close'].shift(1) <= df[f'MA_{period}'].shift(1))).astype(int)

        # 6. 기술적 지표 - 개선: 다양한 파라미터로 확장
        # RSI 기간 다양화
        for rsi_period in [9, 14, 25]:
            df[f'RSI_{rsi_period}'] = talib.RSI(df['Close'], timeperiod=rsi_period)

            # 추가: RSI 과매수/과매도 존 진입/이탈 신호
            df[f'RSI_{rsi_period}_Oversold'] = (df[f'RSI_{rsi_period}'] < 30).astype(int)
            df[f'RSI_{rsi_period}_Overbought'] = (df[f'RSI_{rsi_period}'] > 70).astype(int)
            df[f'RSI_{rsi_period}_CrossUp30'] = ((df[f'RSI_{rsi_period}'] > 30) &
                                            (df[f'RSI_{rsi_period}'].shift(1) <= 30)).astype(int)
            df[f'RSI_{rsi_period}_CrossDown70'] = ((df[f'RSI_{rsi_period}'] < 70) &
                                                (df[f'RSI_{rsi_period}'].shift(1) >= 70)).astype(int)

        # 기본 RSI 유지 (기존 코드와 호환성 위해)
        df['RSI'] = talib.RSI(df['Close'], timeperiod=14)

        # MACD 변형
        for fast_period, slow_period in [(8, 17), (12, 26)]:
            macd, macd_signal, macd_hist = talib.MACD(
                df['Close'], fastperiod=fast_period, slowperiod=slow_period, signalperiod=9)
            df[f'MACD_{fast_period}_{slow_period}'] = macd
            df[f'MACD_Signal_{fast_period}_{slow_period}'] = macd_signal
            df[f'MACD_Hist_{fast_period}_{slow_period}'] = macd_hist

            # 추가: MACD 시그널 교차 (골든/데드 크로스)
            df[f'MACD_GoldenCross_{fast_period}_{slow_period}'] = ((macd > macd_signal) &
                                                            (macd.shift(1) <= macd_signal.shift(1))).astype(int)
            df[f'MACD_DeadCross_{fast_period}_{slow_period}'] = ((macd < macd_signal) &
                                                            (macd.shift(1) >= macd_signal.shift(1))).astype(int)

        # 기본 MACD 유지 (기존 코드와 호환성 위해)
        macd, macd_signal, macd_hist = talib.MACD(df['Close'], fastperiod=12, slowperiod=26, signalperiod=9)
        df['MACD'] = macd
        df['MACD_Signal'] = macd_signal
        df['MACD_Hist'] = macd_hist

        # 7. 볼린저 밴드 개선: 다양한 표준편차와 기간 적용
        for bb_period, stdev in [(20, 2), (20, 3), (50, 2)]:
            upper, middle, lower = talib.BBANDS(
                df['Close'], timeperiod=bb_period, nbdevup=stdev, nbdevdn=stdev, matype=0)
            df[f'BB_Upper_{bb_period}_{stdev}'] = upper
            df[f'BB_Middle_{bb_period}_{stdev}'] = middle
            df[f'BB_Lower_{bb_period}_{stdev}'] = lower
            df[f'BB_Width_{bb_period}_{stdev}'] = (upper - lower) / middle
            df[f'BB_Position_{bb_period}_{stdev}'] = (df['Close'] - lower) / (upper - lower)

            # 추가: 볼린저 밴드 돌파 신호
            df[f'BB_UpperBreakout_{bb_period}_{stdev}'] = ((df['Close'] > upper) &
                                                        (df['Close'].shift(1) <= upper.shift(1))).astype(int)
            df[f'BB_LowerBreakout_{bb_period}_{stdev}'] = ((df['Close'] < lower) &
                                                        (df['Close'].shift(1) >= lower.shift(1))).astype(int)

        # 기본 볼린저 밴드 유지 (기존 코드와 호환성 위해)
        upper, middle, lower = talib.BBANDS(df['Close'], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)
        df['BB_Upper'] = upper
        df['BB_Middle'] = middle
        df['BB_Lower'] = lower
        df['BB_Width'] = (upper - lower) / middle
        df['BB_Position'] = (df['Close'] - lower) / (upper - lower)

        # 8. 추세 지표 개선
        for adx_period in [7, 14, 28]:
            df[f'ADX_{adx_period}'] = talib.ADX(df['High'], df['Low'], df['Close'], timeperiod=adx_period)
            df[f'PLUS_DI_{adx_period}'] = talib.PLUS_DI(df['High'], df['Low'], df['Close'], timeperiod=adx_period)
            df[f'MINUS_DI_{adx_period}'] = talib.MINUS_DI(df['High'], df['Low'], df['Close'], timeperiod=adx_period)

            # 추가: ADX 추세 강도 분류
            df[f'ADX_StrongTrend_{adx_period}'] = (df[f'ADX_{adx_period}'] > 25).astype(int)
            df[f'ADX_VeryStrongTrend_{adx_period}'] = (df[f'ADX_{adx_period}'] > 50).astype(int)

            # 추가: DI 교차 신호 (추세 방향 전환)
            df[f'DI_CrossUp_{adx_period}'] = ((df[f'PLUS_DI_{adx_period}'] > df[f'MINUS_DI_{adx_period}']) &
                                            (df[f'PLUS_DI_{adx_period}'].shift(1) <= df[f'MINUS_DI_{adx_period}'].shift(1))).astype(int)
            df[f'DI_CrossDown_{adx_period}'] = ((df[f'PLUS_DI_{adx_period}'] < df[f'MINUS_DI_{adx_period}']) &
                                            (df[f'PLUS_DI_{adx_period}'].shift(1) >= df[f'MINUS_DI_{adx_period}'].shift(1))).astype(int)

        # 기본 ADX 유지 (기존 코드와 호환성 위해)
        df['ADX'] = talib.ADX(df['High'], df['Low'], df['Close'], timeperiod=14)

        # ATR(Average True Range) 다양화 - 변동성 측정
        for atr_period in [7, 14, 21]:
            df[f'ATR_{atr_period}'] = talib.ATR(df['High'], df['Low'], df['Close'], timeperiod=atr_period)
            df[f'ATR_Percent_{atr_period}'] = df[f'ATR_{atr_period}'] / df['Close']

        # 기본 ATR 유지
        df['ATR'] = talib.ATR(df['High'], df['Low'], df['Close'], timeperiod=14)
        df['ATR_Percent'] = df['ATR'] / df['Close']

        if advanced:
            # 9. 고급 기술적 지표 - 일중 가격 특성
            df['DayHigh_Ratio'] = df['High'] / df['Open']
            df['DayLow_Ratio'] = df['Low'] / df['Open']
            df['CloseOpen_Ratio'] = df['Close'] / df['Open']
            df['ClosePosition'] = (df['Close'] - df['Low']) / (df['High'] - df['Low'])

            # 추가: 캔들 유형 특성
            df['Doji'] = ((abs(df['Close'] - df['Open']) / (df['High'] - df['Low'])) < 0.1).astype(int)
            df['Bullish'] = (df['Close'] > df['Open']).astype(int)
            df['Bearish'] = (df['Close'] < df['Open']).astype(int)
            df['LongUpperShadow'] = ((df['High'] - np.maximum(df['Open'], df['Close'])) >
                                (abs(df['Open'] - df['Close']))).astype(int)
            df['LongLowerShadow'] = ((np.minimum(df['Open'], df['Close']) - df['Low']) >
                                (abs(df['Open'] - df['Close']))).astype(int)

            # 10. 모멘텀 지표 확장
            for period in [5, 10, 20, 60, 120]:
                df[f'ROC_{period}'] = talib.ROC(df['Close'], timeperiod=period)

                # 추가: 모멘텀 가속/감속 포착
                if period <= 60:  # 단기~중기 모멘텀에 대해서만 계산
                    df[f'ROC_Accel_{period}'] = df[f'ROC_{period}'] - df[f'ROC_{period}'].shift(1)
                    df[f'ROC_Sign_{period}'] = np.sign(df[f'ROC_{period}'])
                    df[f'ROC_SignChange_{period}'] = (df[f'ROC_Sign_{period}'] != df[f'ROC_Sign_{period}'].shift(1)).astype(int)

            # 11. 각종 오실레이터 확장
            # 윌리엄스 %R - 다양한 기간
            for period in [7, 14, 28]:
                df[f'WILLR_{period}'] = talib.WILLR(df['High'], df['Low'], df['Close'], timeperiod=period)
                # 추가: 과매수/과매도 존 진입/이탈
                df[f'WILLR_{period}_Oversold'] = (df[f'WILLR_{period}'] < -80).astype(int)
                df[f'WILLR_{period}_Overbought'] = (df[f'WILLR_{period}'] > -20).astype(int)

            # CCI (Commodity Channel Index) - 다양한 기간
            for period in [7, 14, 20]:
                df[f'CCI_{period}'] = talib.CCI(df['High'], df['Low'], df['Close'], timeperiod=period)
                # 추가: CCI 신호
                df[f'CCI_{period}_Positive'] = (df[f'CCI_{period}'] > 0).astype(int)
                df[f'CCI_{period}_Negative'] = (df[f'CCI_{period}'] < 0).astype(int)
                df[f'CCI_{period}_CrossZero'] = ((df[f'CCI_{period}'] > 0) &
                                            (df[f'CCI_{period}'].shift(1) <= 0)).astype(int)

            # 기본 오실레이터 유지
            df['WILLR'] = talib.WILLR(df['High'], df['Low'], df['Close'], timeperiod=14)
            df['CCI'] = talib.CCI(df['High'], df['Low'], df['Close'], timeperiod=14)
            df['ULTOSC'] = talib.ULTOSC(df['High'], df['Low'], df['Close'], timeperiod1=7, timeperiod2=14, timeperiod3=28)
            df['STOCH_K'], df['STOCH_D'] = talib.STOCH(df['High'], df['Low'], df['Close'],
                                                    fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)

            # 12. 추가 추세 지표 확장
            # AROON 지표 - 다양한 기간
            for period in [7, 14, 25]:
                df[f'AROON_UP_{period}'], df[f'AROON_DOWN_{period}'] = talib.AROON(df['High'], df['Low'], timeperiod=period)
                # 추가: AROON 신호
                df[f'AROON_Bullish_{period}'] = (df[f'AROON_UP_{period}'] > df[f'AROON_DOWN_{period}']).astype(int)
                df[f'AROON_CrossUp_{period}'] = ((df[f'AROON_UP_{period}'] > df[f'AROON_DOWN_{period}']) &
                                            (df[f'AROON_UP_{period}'].shift(1) <= df[f'AROON_DOWN_{period}'].shift(1))).astype(int)

            # 기본 AROON 유지
            df['AROON_UP'], df['AROON_DOWN'] = talib.AROON(df['High'], df['Low'], timeperiod=14)

            # 13. 캔들스틱 패턴 강화 - 더 많은 패턴 포함
            patterns = [
                'CDLDOJI', 'CDLHAMMER', 'CDLENGULFING', 'CDLMORNINGSTAR', 'CDLEVENINGSTAR',
                'CDLSHOOTINGSTAR', 'CDLHARAMI', 'CDLDARKCLOUDCOVER', 'CDLPIERCING',
                'CDLSPINNINGTOP', 'CDLMARUBOZU', 'CDLINVERTEDHAMMER', 'CDLHANGINGMAN',
                'CDLBELTHOLD', 'CDLCOUNTERATTACK',
                'CDLDOJISTAR', 'CDLDRAGONFLYDOJI', 'CDLHIGHWAVE'
            ]
            for pattern in patterns:
                if hasattr(talib, pattern):
                    try:
                        pattern_func = getattr(talib, pattern)
                        df[pattern] = pattern_func(df['Open'], df['High'], df['Low'], df['Close'])
                    except Exception as e:
                        print(f"패턴 {pattern} 계산 중 오류: {e}")
                else:
                    print(f"경고: TA-Lib에서 {pattern} 패턴을 찾을 수 없습니다. 건너뜁니다.")

            # 추가: 종합 패턴 점수 (긍정적 패턴 - 부정적 패턴)
            bullish_patterns = ['CDLHAMMER', 'CDLPIERCING', 'CDLMORNINGSTAR', 'CDLENGULFING']
            bearish_patterns = ['CDLSHOOTINGSTAR', 'CDLDARKCLOUDCOVER', 'CDLEVENINGSTAR']

            df['Pattern_Bullish_Count'] = sum([df[p] > 0 for p in bullish_patterns])
            df['Pattern_Bearish_Count'] = sum([df[p] < 0 for p in bearish_patterns])

            # 14. 이동평균 교차 확장
            ma_pairs = [(5, 10), (10, 20), (20, 50), (50, 100)]
            for short_ma, long_ma in ma_pairs:
                df[f'MA_{short_ma}_{long_ma}_Ratio'] = df[f'MA_{short_ma}'] / df[f'MA_{long_ma}']
                df[f'MA_{short_ma}_{long_ma}_Cross'] = (df[f'MA_{short_ma}'] > df[f'MA_{long_ma}']).astype(int)

                # 추가: 골든 크로스 / 데드 크로스 감지
                df[f'MA_{short_ma}_{long_ma}_GoldenCross'] = ((df[f'MA_{short_ma}'] > df[f'MA_{long_ma}']) &
                                                            (df[f'MA_{short_ma}'].shift(1) <= df[f'MA_{long_ma}'].shift(1))).astype(int)
                df[f'MA_{short_ma}_{long_ma}_DeadCross'] = ((df[f'MA_{short_ma}'] < df[f'MA_{long_ma}']) &
                                                        (df[f'MA_{short_ma}'].shift(1) >= df[f'MA_{long_ma}'].shift(1))).astype(int)

            # 15. 연속 상승/하락 패턴 - 정밀화
            for i in range(1, 6):
                df[f'UpDay_{i}'] = (df['Return'].shift(i) > 0).astype(int)
                df[f'DownDay_{i}'] = (df['Return'].shift(i) < 0).astype(int)

                # 추가: 연속 상승/하락의 누적 수익률
                if i > 1:
                    df[f'ConsecutiveReturn_{i}'] = df['Close'].shift(1) / df['Close'].shift(i) - 1

            # 연속 상승/하락 패턴
            for n in [2, 3, 5]:
                # n일 연속 상승
                up_cond = True
                for i in range(1, n+1):
                    up_cond = up_cond & (df[f'UpDay_{i}'] > 0)
                df[f'{n}DayUp'] = up_cond.astype(int)

                # n일 연속 하락
                down_cond = True
                for i in range(1, n+1):
                    down_cond = down_cond & (df[f'DownDay_{i}'] > 0)
                df[f'{n}DayDown'] = down_cond.astype(int)

            # 16. 지연된 지표 (1일, 2일, 3일, 5일, 10일 전) - 확장
            delay_features = ['Return', 'RangePercent', 'RSI', 'MACD_Hist', 'BB_Position',
                            'ADX', 'ATR_Percent', 'ClosePosition']
            for lag in [1, 2, 3, 5, 10]:
                for col in delay_features:
                    df[f'{col}_Lag{lag}'] = df[col].shift(lag)

            # 17. 최근 N일 특성 강화
            for period in [3, 5, 10, 20, 60]:
                # 최근 N일 수익률 및 누적 수익률
                df[f'Return_{period}d'] = df['Close'] / df['Close'].shift(period) - 1
                df[f'CumReturn_{period}d'] = (df['Close'] / df['Close'].shift(1)).rolling(period).apply(lambda x: x.prod() - 1)

                # 최근 N일 변동성 및 비대칭성
                returns = df['Return'].rolling(period)
                df[f'Volatility_{period}d'] = returns.std()
                df[f'Skew_{period}d'] = returns.skew()
                df[f'Kurtosis_{period}d'] = returns.kurt()

                # 최근 N일 최고/최저 돌파
                df[f'HighBreakout_{period}d'] = (df['High'] > df['High'].rolling(period).max().shift(1)).astype(int)
                df[f'LowBreakout_{period}d'] = (df['Low'] < df['Low'].rolling(period).min().shift(1)).astype(int)

                # 평균 거래량 대비 상대 거래량 및 추세
                df[f'RelVolume_{period}d'] = df['Volume'] / df['Volume'].rolling(period).mean()
                df[f'VolumeTrend_{period}d'] = (df['Volume'].rolling(period).mean() /
                                            df['Volume'].rolling(period).mean().shift(5) - 1)

            # 18. 시계열 및 계절성 특성 강화
            # 추가: 확장된 시간 특성
            df['DayOfWeek'] = df['Date'].dt.dayofweek
            df['Month'] = df['Date'].dt.month
            df['WeekOfYear'] = df['Date'].dt.isocalendar().week.astype(int)
            df['Quarter'] = df['Date'].dt.quarter
            df['Year'] = df['Date'].dt.year

            # 추가: 월초/월말, 분기초/분기말 특성
            df['MonthStart'] = df['Date'].dt.is_month_start.astype(int)
            df['MonthEnd'] = df['Date'].dt.is_month_end.astype(int)
            df['QuarterStart'] = ((df['Date'].dt.month - 1) % 3 == 0) & (df['Date'].dt.day == 1)
            df['QuarterEnd'] = df['Date'].dt.is_quarter_end.astype(int)

            # 계절 더미 변수
            spring = (df['Month'] >= 3) & (df['Month'] <= 5)
            summer = (df['Month'] >= 6) & (df['Month'] <= 8)
            fall = (df['Month'] >= 9) & (df['Month'] <= 11)
            winter = (df['Month'] == 12) | (df['Month'] <= 2)

            df['Spring'] = spring.astype(int)
            df['Summer'] = summer.astype(int)
            df['Fall'] = fall.astype(int)
            df['Winter'] = winter.astype(int)

            # 19. 주간 및 월간 수익률 확장
            df['WeeklyReturn'] = df['Close'] / df['Close'].shift(5) - 1
            df['MonthlyReturn'] = df['Close'] / df['Close'].shift(20) - 1
            df['QuarterlyReturn'] = df['Close'] / df['Close'].shift(60) - 1

            # 추가: 주/월/분기 성과 대비 현재 성과 비교
            df['WeeklyOutperformance'] = df['Return'] / (df['WeeklyReturn'] / 5 + 1e-10)
            df['MonthlyOutperformance'] = df['Return'] / (df['MonthlyReturn'] / 20 + 1e-10)

            # 20. 방향 일치 지표 확장
            df['Direction_RSI'] = ((df['RSI'] > 50) == (df['Return'] > 0)).astype(int)
            df['Direction_MACD'] = ((df['MACD'] > df['MACD_Signal']) == (df['Return'] > 0)).astype(int)

            # 추가: 더 많은 지표와의 방향 일치성
            df['Direction_CCI'] = ((df['CCI'] > 0) == (df['Return'] > 0)).astype(int)
            df['Direction_ATR'] = ((df['ATR_Percent'] > df['ATR_Percent'].shift(1)) ==
                                (df['RangePercent'] > df['RangePercent'].shift(1))).astype(int)

            # 21. 시장 강도 메타 특성
            # 시장 강도 지수 (여러 지표의 가중 합산)
            rsi_signal = (df['RSI'] > 50).astype(int) * 2 - 1  # -1 or 1
            macd_signal = (df['MACD'] > df['MACD_Signal']).astype(int) * 2 - 1
            cci_signal = (df['CCI'] > 0).astype(int) * 2 - 1
            adx_signal = (df['PLUS_DI_14'] > df['MINUS_DI_14']).astype(int) * (df['ADX'] > 20).astype(int) * 2 - 1

            df['MarketStrength'] = (rsi_signal * 0.25 +
                                macd_signal * 0.25 +
                                cci_signal * 0.25 +
                                adx_signal * 0.25)

            # 시장 강도의 변화율
            df['MarketStrengthChange'] = df['MarketStrength'] - df['MarketStrength'].shift(1)

            # 22. 클러스터 강도 특성
            # 여러 지표의 일치도를 점수화
            bullish_signals = [
                (df['RSI'] > 50),
                (df['MACD'] > df['MACD_Signal']),
                (df['CCI'] > 0),
                (df['PLUS_DI_14'] > df['MINUS_DI_14']),
                (df['Close'] > df['MA_20']),
                (df['Close'] > df['MA_50']),
                (df['BB_Position'] > 0.5),
                (df['ROC_10'] > 0)
            ]

            df['BullishSignalCount'] = sum([signal.astype(int) for signal in bullish_signals])
            df['BullishConsensus'] = df['BullishSignalCount'] / len(bullish_signals)

            # 강한 추세 신호 (80% 이상 일치)
            df['StrongBullishSignal'] = (df['BullishConsensus'] >= 0.8).astype(int)
            df['StrongBearishSignal'] = (df['BullishConsensus'] <= 0.2).astype(int)

        # 23. 개선: NaN 값 처리 (제거 대신 채우기)
        # 특성별 적절한 채우기 방식 적용
        for col in df.columns:
            if col in ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']:
                continue

            # 기술적 지표는 앞쪽 NaN을 최초값으로 채움
            if any(col.startswith(prefix) for prefix in ['RSI', 'MACD', 'BB_', 'ATR', 'ADX', 'CCI', 'WILLR', 'AROON']):
                df[col] = df[col].fillna(method='bfill').fillna(0)

            # 비율 지표는 1로 채움 (중립적 값)
            elif 'Ratio' in col:
                df[col] = df[col].fillna(1)

            # 신호 지표는 0으로 채움 (신호 없음)
            elif any(term in col for term in ['Cross', 'Signal', 'Breakout', 'Bullish', 'Bearish']):
                df[col] = df[col].fillna(0)

            # 나머지는 0으로 채움
            else:
                df[col] = df[col].fillna(0)

        print(f"특성 생성 및 NaN 처리 완료: {len(df)} 행")

        # 특성 이름 저장 전에 메모리 최적화
        df = self.optimize_dataframe_memory(df)

        # 특성 이름 저장
        features = [col for col in df.columns if col not in ['Date', 'Target', 'Open', 'High', 'Low', 'Close', 'Volume']]
        self.feature_names = features
        print(f"생성된 특성 수: {len(features)}")

        self.data_with_features = df
        return df

    def optimize_dataframe_memory(self, df):
        """데이터프레임 메모리 사용량 최적화"""
        print("데이터프레임 메모리 최적화 중...")
        start_mem = df.memory_usage().sum() / 1024**2

        # float64를 float32로 다운캐스팅
        for col in df.select_dtypes(include=['float64']).columns:
            df[col] = df[col].astype('float32')

        # int64를 int32로 다운캐스팅
        for col in df.select_dtypes(include=['int64']).columns:
            # 최대값이 2^31-1보다 작은지 확인
            if df[col].max() < 2147483647 and df[col].min() > -2147483648:
                df[col] = df[col].astype('int32')

        # object 타입 열에 대한 메모리 최적화
        for col in df.select_dtypes(include=['object']).columns:
            if col != 'Date':  # Date 컬럼은 처리하지 않음
                num_unique_values = len(df[col].unique())
                num_total_values = len(df[col])
                if num_unique_values / num_total_values < 0.5:  # 고유 값이 50% 미만인 경우
                    df[col] = df[col].astype('category')

        end_mem = df.memory_usage().sum() / 1024**2
        reduction = (start_mem - end_mem) / start_mem

        print(f"메모리 사용량: {start_mem:.2f} MB → {end_mem:.2f} MB ({reduction:.1%} 감소)")
        return df

    def save_model(self, filepath):
        """
        모델 저장 - 최적화된 포맷

        Parameters:
        -----------
        filepath : str
            모델 저장 경로
        """
        if self.model is None:
            raise ValueError("먼저 train_model() 메서드를 호출하세요.")

        # 디렉토리 생성
        os.makedirs(os.path.dirname(filepath), exist_ok=True)

        # 파일 확장자 확인
        if not filepath.endswith('.pkl') and not filepath.endswith('.bin'):
            filepath = filepath + '.bin'  # 기본 확장자 추가

        if filepath.endswith('.bin'):
            # XGBoost 네이티브 포맷으로 저장 (더 작고 빠름)
            try:
                # 모델만 저장
                model_path = filepath
                self.model.save_model(model_path)

                # 메타데이터 별도 저장
                meta_path = filepath.replace('.bin', '.meta.pkl')
                meta_data = {
                    'scaler': self.scaler,
                    'feature_names': self.feature_names,
                    'prediction_type': self.prediction_type,
                    'prediction_period': self.prediction_period,
                    'confidence_threshold': self.confidence_threshold,
                    'test_accuracy': self.test_accuracy
                }
                with open(meta_path, 'wb') as f:
                    pickle.dump(meta_data, f, protocol=4)  # 프로토콜 4는 더 효율적

                print(f"모델 저장 완료: {model_path} (XGBoost 네이티브 포맷)")
                print(f"메타데이터 저장 완료: {meta_path}")
                return
            except Exception as e:
                print(f"XGBoost 네이티브 포맷으로 저장 실패, 피클로 대체: {e}")

        # 기존 방식 (피클)
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'feature_names': self.feature_names,
            'prediction_type': self.prediction_type,
            'prediction_period': self.prediction_period,
            'confidence_threshold': self.confidence_threshold,
            'test_accuracy': self.test_accuracy
        }

        # 최적화된 피클 저장
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f, protocol=4)  # 프로토콜 4는 더 효율적

        print(f"모델 저장 완료: {filepath} (피클 포맷)")

    @classmethod
    def load_model(cls, filepath):
        """
        저장된 모델 로드

        Parameters:
        -----------
        filepath : str
            모델 파일 경로

        Returns:
        --------
        StockPredictionModel
            로드된 모델 객체
        """
        # 모델 파일 로드
        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)

        # 모델 객체 생성
        prediction_type = model_data['prediction_type']
        prediction_period = model_data['prediction_period']
        confidence_threshold = model_data['confidence_threshold']

        model_instance = cls(
            prediction_type=prediction_type,
            prediction_period=prediction_period,
            confidence_threshold=confidence_threshold
        )

        # 모델 속성 설정
        model_instance.model = model_data['model']
        model_instance.scaler = model_data['scaler']
        model_instance.feature_names = model_data['feature_names']
        model_instance.test_accuracy = model_data.get('test_accuracy')

        print(f"모델 로드 완료: {filepath}")
        print(f"예측 유형: {prediction_type}")
        print(f"예측 기간: {prediction_period}일")

        return model_instance

    def select_important_features(self, threshold=0.01, method='importance', top_n=None):
        """중요도가 높은 특성만 선택하고 스케일러 업데이트 - 개선된 버전

        Parameters:
        -----------
        threshold : float
            특성 중요도 임계값
        method : str
            특성 선택 방법 ('importance' 또는 'shap')
        top_n : int, optional
            선택할 상위 특성 수 (지정 시 threshold 무시)
        """
        if self.model is None:
            raise ValueError("먼저 train_model() 메서드를 호출하세요.")

        # 1. 개선: 다양한 특성 선택 방법 제공
        if method == 'shap' and has_shap():
            try:
                import shap
                # SHAP 값 계산
                explainer = shap.TreeExplainer(self.model)
                shap_values = explainer.shap_values(self.X_train)

                # 분류 모델의 경우 첫 번째 클래스 또는 평균 SHAP 값 사용
                if isinstance(shap_values, list):
                    if self.prediction_type == 'classification':
                        shap_values = shap_values[1]  # 양성 클래스의 SHAP 값

                # 특성별 중요도 계산 (절대값 평균)
                feature_importance = np.abs(shap_values).mean(axis=0)
                feature_importance = dict(zip(self.feature_names, feature_importance))

                print("SHAP 기반 특성 중요도 계산 완료")
            except Exception as e:
                print(f"SHAP 계산 오류, 기본 중요도 방법으로 대체: {e}")
                feature_importance = dict(zip(self.feature_names, self.model.feature_importances_))
        else:
            # 기본 특성 중요도 사용
            feature_importance = dict(zip(self.feature_names, self.model.feature_importances_))

        # 2. 개선: top_n 파라미터로 상위 N개 특성 선택 옵션 추가
        if top_n is not None and top_n > 0:
            # 중요도순으로 상위 N개 특성 선택
            sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
            top_n = min(top_n, len(sorted_features))  # 특성 수 보다 크지 않도록
            selected_features = [f for f, _ in sorted_features[:top_n]]
            print(f"상위 {top_n}개 중요 특성 선택됨")
        else:
            # 임계값 기반으로 특성 선택
            selected_features = [f for f, imp in feature_importance.items()
                                if imp >= threshold]

            # 3. 개선: 최소 특성 수 보장
            if len(selected_features) < 10:
                # 최소 10개 이상의 특성 선택
                sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
                selected_features = [f for f, _ in sorted_features[:max(10, len(selected_features))]]
                print(f"중요 특성이 적어 상위 {len(selected_features)}개 특성 선택")

        print(f"선택된 중요 특성: {len(selected_features)}/{len(self.feature_names)}")

        # 4. 개선: 선택된 특성의 중요도 출력
        selected_importance = {f: feature_importance[f] for f in selected_features}
        sorted_selected = sorted(selected_importance.items(), key=lambda x: x[1], reverse=True)

        print("\n선택된 특성 중요도 (상위 10개):")
        for feat, imp in sorted_selected[:10]:
            print(f"{feat}: {imp:.6f}")

        # 스케일링되지 않은 원본 데이터 가져오기
        if hasattr(self, 'data_with_features'):
            df = self.data_with_features

            # 특성 및 타겟 분리
            X_raw = df[self.feature_names]
            y = df['Target']

            # 선택된 특성만 필터링
            X_raw_selected = X_raw[selected_features]

            # 시계열 분할 (원본 prepare_data에서와 동일하게)
            test_size = 0.2
            split_idx = int(len(df) * (1 - test_size))
            X_train_raw = X_raw_selected.iloc[:split_idx]
            X_test_raw = X_raw_selected.iloc[split_idx:]
            y_train = y.iloc[:split_idx]
            y_test = y.iloc[split_idx:]

            # 새로운 스케일러 생성 및 학습
            self.scaler = StandardScaler()
            X_train_scaled = self.scaler.fit_transform(X_train_raw)
            X_test_scaled = self.scaler.transform(X_test_raw)

            # DataFrame으로 변환
            X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_raw.columns)
            X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_raw.columns)

            # 기존 데이터 업데이트
            self.X_train = X_train_scaled
            self.X_test = X_test_scaled
            self.y_train = y_train
            self.y_test = y_test

            # 특성 이름 업데이트
            self.feature_names = selected_features

            # 모델 재학습
            print("특성 선택 후 모델 재학습...")
            self.train_model(optimize=False)

            # 5. 개선: 특성 선택 전후 성능 비교
            if hasattr(self, 'test_accuracy') and hasattr(self, 'original_test_accuracy'):
                performance_change = self.test_accuracy - self.original_test_accuracy
                print(f"특성 선택 전후 성능 변화: {performance_change:.4f} ({performance_change * 100:.2f}%)")
        else:
            print("경고: 원본 데이터를 찾을 수 없어 스케일러를 업데이트할 수 없습니다.")
            self.feature_names = selected_features

        return selected_features

    # 🔧 XGBoost 버전 호환성 수정 - train_model 메서드 완전 교체
    def train_model_fixed(self, optimize=True, n_iter=20, advanced_optimize=True):
        """XGBoost 2.1.4 GPU 완전 호환 버전"""
        
        if not hasattr(self, 'X_train'):
            raise ValueError("먼저 prepare_data() 메서드를 호출하세요.")

        print("🔥 XGBoost 2.1.4 GPU 모드 학습 시작...")

        # 클래스 비율 확인
        if self.prediction_type == 'classification':
            class_counts = self.y_train.value_counts()
            print(f"학습 데이터 클래스 분포: {dict(class_counts)}")
            if len(class_counts) > 1:
                scale_pos_weight = class_counts[0] / class_counts[1] if 1 in class_counts and 0 in class_counts else 1
            else:
                scale_pos_weight = 1
        else:
            scale_pos_weight = 1

        # 🔥 XGBoost 2.1.4 GPU 파라미터
        if self.prediction_type == 'classification':
            gpu_params = {
                'device': 'cuda',                    # ✅ 핵심!
                'tree_method': 'hist',               # ✅ 핵심!
                'objective': 'binary:logistic',
                'eval_metric': 'logloss',
                'learning_rate': 0.1,
                'n_estimators': 800,
                'max_depth': 8,
                'min_child_weight': 1,
                'subsample': 0.9,
                'colsample_bytree': 0.9,
                'gamma': 0,
                'reg_alpha': 0,
                'reg_lambda': 0.1,
                'scale_pos_weight': scale_pos_weight,
                'random_state': 42,
                'verbosity': 1,
                'n_jobs': 1,
                'max_bin': 512,
                'grow_policy': 'lossguide',
                'max_leaves': 1023
            }
            model = xgb.XGBClassifier(**gpu_params)
        else:
            gpu_params = {
                'device': 'cuda',
                'tree_method': 'hist',
                'objective': 'reg:squarederror',
                'eval_metric': 'rmse',
                'learning_rate': 0.1,
                'n_estimators': 800,
                'max_depth': 8,
                'min_child_weight': 1,
                'subsample': 0.9,
                'colsample_bytree': 0.9,
                'gamma': 0,
                'reg_alpha': 0,
                'reg_lambda': 0.1,
                'random_state': 42,
                'verbosity': 1,
                'n_jobs': 1,
                'max_bin': 512,
                'grow_policy': 'lossguide',
                'max_leaves': 1023
            }
            model = xgb.XGBRegressor(**gpu_params)

        print("✅ GPU 파라미터 설정 완료")

        # 모델 학습
        print("🚀 GPU 모델 학습 시작...")
        
        try:
            eval_set = [(self.X_train, self.y_train), (self.X_test, self.y_test)]
            
            try:
                model = self.train_with_xgb_compatibility(model)
                print("✅ XGBoost 2.1.4 콜백 방식 성공")
            except:
                model.fit(self.X_train, self.y_train)
                print("✅ 기본 학습 완료")
                
        except Exception as e:
            print(f"⚠️ 학습 오류: {e}")
            model.fit(self.X_train, self.y_train)

        # GPU 메모리 확인
        try:
            import torch
            if torch.cuda.is_available():
                memory_used = torch.cuda.memory_allocated(0) / 1024**2
                print(f"🔥 GPU 메모리 사용량: {memory_used:.1f}MB")
        except:
            pass

        self.model = model

        # 테스트 정확도 계산
        if self.prediction_type == 'classification':
            from sklearn.metrics import accuracy_score
            y_pred = self.model.predict(self.X_test)
            self.test_accuracy = accuracy_score(self.y_test, y_pred)
        else:
            from sklearn.metrics import r2_score
            y_pred = self.model.predict(self.X_test)
            self.test_accuracy = r2_score(self.y_test, y_pred)

        print(f"🎉 GPU 모델 학습 완료! 테스트 정확도: {self.test_accuracy:.4f}")
        
        return model

    def evaluate_model(self):
        """
        모델 성능 평가

        Returns:
        --------
        dict
            평가 지표
        """
        if self.model is None:
            raise ValueError("먼저 train_model() 메서드를 호출하세요.")

        print("모델 평가 중...")

        # 예측
        if self.prediction_type == 'classification':
            y_pred = self.model.predict(self.X_test)

            # AUC 계산 시 예외 처리 추가
            try:
                y_pred_proba = self.model.predict_proba(self.X_test)[:, 1]

                # 클래스가 하나만 있는지 확인
                if len(np.unique(self.y_test)) < 2:
                    print("경고: 테스트 데이터에 클래스가 하나만 있어 AUC를 계산할 수 없습니다.")
                    auc = 0.5  # 기본값으로 0.5 설정
                else:
                    auc = roc_auc_score(self.y_test, y_pred_proba)
            except Exception as e:
                print(f"AUC 계산 오류: {e}")
                auc = 0.5  # 기본값으로 0.5 설정

            # 다른 평가 지표 계산 시에도 예외 처리 추가
            try:
                accuracy = accuracy_score(self.y_test, y_pred)
                precision = precision_score(self.y_test, y_pred, zero_division=0)
                recall = recall_score(self.y_test, y_pred, zero_division=0)
                f1 = f1_score(self.y_test, y_pred, zero_division=0)
            except Exception as e:
                print(f"평가 지표 계산 오류: {e}")
                accuracy = precision = recall = f1 = 0

            # 평가 결과 출력
            print(f"정확도: {accuracy:.4f}")
            print(f"정밀도: {precision:.4f}")
            print(f"재현율: {recall:.4f}")
            print(f"F1 점수: {f1:.4f}")
            print(f"AUC: {auc:.4f}")

            # 분류 리포트
            try:
                print("\n분류 리포트:")
                print(classification_report(self.y_test, y_pred))
            except Exception as e:
                print(f"분류 리포트 생성 오류: {e}")

            # 혼동 행렬 - 그래프 생성하지 않음
            try:
                cm = confusion_matrix(self.y_test, y_pred)
                # 콘솔에만 출력
                print("혼동 행렬:")
                print(cm)
            except Exception as e:
                print(f"혼동 행렬 계산 오류: {e}")

            # 테스트 정확도 저장
            self.test_accuracy = accuracy

            return {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'auc': auc
            }
        else:  # regression
            y_pred = self.model.predict(self.X_test)

            # 평가 지표
            try:
                mse = mean_squared_error(self.y_test, y_pred)
                rmse = np.sqrt(mse)
                r2 = r2_score(self.y_test, y_pred)
            except Exception as e:
                print(f"평가 지표 계산 오류: {e}")
                mse = rmse = 0
                r2 = 0

            # 평가 결과 출력
            print(f"MSE: {mse:.4f}")
            print(f"RMSE: {rmse:.4f}")
            print(f"R2 점수: {r2:.4f}")

            # 테스트 정확도 (R2) 저장
            self.test_accuracy = r2

            return {
                'mse': mse,
                'rmse': rmse,
                'r2': r2
            }

    def plot_feature_importance(self, top_n=20):
        """
        특성 중요도 시각화

        Parameters:
        -----------
        top_n : int
            표시할 상위 특성 수
        """
        if self.model is None:
            raise ValueError("먼저 train_model() 메서드를 호출하세요.")

        # 특성 중요도 추출
        importance = self.model.feature_importances_
        indices = np.argsort(importance)[::-1]

        # 상위 N개 특성 선택
        if top_n > len(self.feature_names):
            top_n = len(self.feature_names)

        top_indices = indices[:top_n]
        top_features = [self.feature_names[i] for i in top_indices]
        top_importance = importance[top_indices]

        # 시각화
        plt.figure(figsize=(12, 8))
        plt.barh(range(top_n), top_importance, align='center')
        plt.yticks(range(top_n), top_features)
        plt.xlabel('중요도')
        plt.title(f'상위 {top_n}개 특성 중요도')
        plt.gca().invert_yaxis()  # 중요도 내림차순 정렬
        plt.tight_layout()
        # plt.show()

        # 중요도 정보 반환
        return dict(zip(top_features, top_importance))

    def enhanced_prediction(self, days=1, ensemble=True, bootstrap_samples=10):
        """향상된 신뢰도와 정확도를 제공하는 예측 메서드 - 개선된 버전"""
        # 기본 예측 수행
        base_prediction = self.predict_future(days)

        if self.prediction_type != 'classification':
            return base_prediction  # 회귀 모델은 기본 예측만 수행

        # 최신 데이터
        latest_data = self.data_with_features.iloc[-1]
        features = latest_data[self.feature_names].values.reshape(1, -1)
        features_scaled = self.scaler.transform(features)

        # 1. 앙상블 예측 (부트스트랩 샘플링)
        if ensemble and bootstrap_samples > 1:
            ensemble_predictions = []

            for _ in range(bootstrap_samples):
                # 데이터 부트스트랩 샘플링
                n_samples = len(self.X_train)
                indices = np.random.choice(n_samples, n_samples, replace=True)
                X_boot = self.X_train.iloc[indices] if isinstance(self.X_train, pd.DataFrame) else self.X_train[indices]
                y_boot = self.y_train.iloc[indices] if isinstance(self.y_train, pd.Series) else self.y_train[indices]

                # 부트스트랩 모델 학습
                boot_model = xgb.XGBClassifier(**self.model.get_params())
                boot_model.fit(X_boot, y_boot)

                # 예측
                boot_proba = boot_model.predict_proba(features_scaled)[0, 1]
                ensemble_predictions.append(boot_proba)

            # 앙상블 결과 계산
            ensemble_mean = np.mean(ensemble_predictions)
            ensemble_std = np.std(ensemble_predictions)

            print(f"앙상블 예측 (평균): {ensemble_mean:.4f}")
            print(f"앙상블 불확실성 (표준편차): {ensemble_std:.4f}")

            # 앙상블 신뢰 구간
            conf_level = 0.9
            z_score = 1.645  # 90% 신뢰 구간
            lower = max(0, ensemble_mean - z_score * ensemble_std)
            upper = min(1, ensemble_mean + z_score * ensemble_std)

            print(f"90% 신뢰 구간: [{lower:.4f}, {upper:.4f}]")

            # 기본 예측 업데이트
            base_confidence = base_prediction['Confidence'].iloc[0]

            # 앙상블 결과와 기본 예측 결합 (가중평균)
            adjusted_confidence = 0.7 * ensemble_mean + 0.3 * base_confidence
        else:
            adjusted_confidence = base_prediction['Confidence'].iloc[0]

        # 2. 다중 기간 신호의 일관성 확인
        multi_period_consistent = True
        try:
            # 여러 기간의 과거 예측 일관성 확인
            for lookback in [0, 1, 2, 3]:
                if lookback > 0 and len(self.data_with_features) > lookback:
                    past_data = self.data_with_features.iloc[-(lookback+1)]
                    past_features = past_data[self.feature_names].values.reshape(1, -1)
                    past_features_scaled = self.scaler.transform(past_features)
                    past_proba = self.model.predict_proba(past_features_scaled)[0, 1]

                    # 현재 예측과 과거 예측의 방향 일치 여부
                    current_bullish = adjusted_confidence > 0.5
                    past_bullish = past_proba > 0.5

                    if current_bullish != past_bullish:
                        multi_period_consistent = False
                        break
        except:
            # 오류 발생 시 무시
            pass

        # 3. 시장 상태 확인
        recent_data = self.data_with_features.tail(20)
        market_trend = recent_data['Close'].pct_change().mean() > 0
        market_vol = recent_data['Return'].std()

        # 일관성 및 시장 상태에 따른 확신도 조정
        adjusted_confidence_original = adjusted_confidence

        # 시장 추세와 예측 방향이 일치하면 확신도 상승
        prediction = 1 if adjusted_confidence > 0.5 else 0
        if (market_trend and prediction == 1) or (not market_trend and prediction == 0):
            adjustment_factor = 1.15  # 15% 상승
        else:
            adjustment_factor = 0.9  # 10% 감소

        # 변동성 적용
        vol_factor = 1.0
        if market_vol > 0.03:  # 3% 이상 변동성
            vol_factor = 0.9  # 10% 감소
        elif market_vol < 0.01:  # 1% 미만 변동성
            vol_factor = 1.1  # 10% 상승

        # 일관성 적용
        consistency_factor = 1.1 if multi_period_consistent else 0.95

        # 조정된 확신도 계산
        adjusted_confidence = adjusted_confidence * adjustment_factor * vol_factor * consistency_factor

        # 범위 내로 조정
        if prediction == 1:
            adjusted_confidence = min(0.99, max(0.51, adjusted_confidence))
        else:
            adjusted_confidence = min(0.49, max(0.01, adjusted_confidence))

        # 4. 기술적 지표 확인
        tech_confirmation = 0
        try:
            confirmations = self._check_technical_indicators()
            tech_confirmation = sum(confirmations.values())

            # 기술적 지표 일치도에 따른 확신도 조정
            if tech_confirmation >= len(confirmations) * 0.7:  # 70% 이상 일치
                adjusted_confidence = adjusted_confidence * 1.1  # 10% 상승
                # 범위 내로 조정
                if prediction == 1:
                    adjusted_confidence = min(0.99, adjusted_confidence)
                else:
                    adjusted_confidence = max(0.01, adjusted_confidence)
        except:
            # 오류 발생 시 무시
            pass

        # 5. 최종 예측 결과 업데이트
        enhanced_pred = base_prediction.copy()
        enhanced_pred['Confidence'].iloc[0] = adjusted_confidence

        # 조정 원인 설명
        print(f"\n확신도 조정: {adjusted_confidence_original:.4f} → {adjusted_confidence:.4f}")
        print(f"- 시장 추세 영향: {'일치' if (market_trend and prediction == 1) or (not market_trend and prediction == 0) else '불일치'}")
        print(f"- 변동성 영향: {market_vol:.4f} ({'높음' if market_vol > 0.03 else '보통' if market_vol > 0.01 else '낮음'})")
        print(f"- 기간 일관성: {'있음' if multi_period_consistent else '없음'}")
        print(f"- 기술적 지표 확인: {tech_confirmation}/{len(confirmations) if 'confirmations' in locals() and confirmations else 0}")

        # 6. 매우 강한 신호일 경우 추가 표시
        strong_signal = adjusted_confidence > 0.8 or adjusted_confidence < 0.2
        if strong_signal:
            strength = "매우 강한 매수" if adjusted_confidence > 0.8 else "매우 강한 매도"
            print(f"\n{strength} 신호 감지: {adjusted_confidence:.2f} 확신도")

        # 7. 위험 평가
        if hasattr(self, 'backtest_results'):
            risk_level = "높음" if self.backtest_results.get('max_drawdown', 0) < -0.1 else "중간"
            print(f"위험 수준: {risk_level} (최대 손실: {self.backtest_results.get('max_drawdown', 0):.2%})")

        return enhanced_pred

    def backtest(self, initial_capital=10000, transaction_cost=0.001, stop_loss=0.03, take_profit=0.05):
        """백테스트 수행 - 개선된 버전"""
        if self.model is None:
            raise ValueError("먼저 train_model() 메서드를 호출하세요.")

        print("백테스트 수행 중...")

        # 테스트 데이터 가져오기
        test_data = self.data_with_features.iloc[-len(self.X_test):].reset_index(drop=True)

        # 1. 개선: 이동 윈도우 방식으로 더 현실적인 예측
        if len(test_data) > 50:  # 충분한 테스트 데이터가 있을 경우
            use_walk_forward = True
            print("이동 윈도우 백테스트 방식 사용")
        else:
            use_walk_forward = False

        # 예측
        if self.prediction_type == 'classification':
            if use_walk_forward:
                # 이동 윈도우 예측
                window_size = 30  # 초기 학습 기간
                test_proba = np.zeros(len(test_data))

                for i in range(window_size, len(test_data)):
                    # 현재 데이터까지 학습
                    train_window = self.data_with_features.iloc[:-(len(test_data)-i)]
                    window_model = xgb.XGBClassifier(**self.model.get_params())

                    # 특성 및 타겟 준비
                    X_win = train_window[self.feature_names]
                    y_win = train_window['Target']

                    # NaN 처리
                    X_win = X_win.fillna(0)

                    # 스케일링
                    scaler = StandardScaler()
                    X_win_scaled = scaler.fit_transform(X_win)

                    # 모델 학습
                    window_model.fit(X_win_scaled, y_win)

                    # 현재 데이터포인트 예측
                    current_features = test_data.iloc[i][self.feature_names].values.reshape(1, -1)
                    current_scaled = scaler.transform(current_features)
                    test_proba[i] = window_model.predict_proba(current_scaled)[0, 1]

                # 예측값 저장
                test_data['PredictionProba'] = test_proba
                test_data['Prediction'] = (test_data['PredictionProba'] > 0.5).astype(int)
                test_data['Signal'] = (test_data['PredictionProba'] > self.confidence_threshold).astype(int)
            else:
                # 기본 예측 방식
                test_data['PredictionProba'] = self.model.predict_proba(self.X_test)[:, 1]
                test_data['Prediction'] = (test_data['PredictionProba'] > 0.5).astype(int)
                test_data['Signal'] = (test_data['PredictionProba'] > self.confidence_threshold).astype(int)
        else:  # regression
            if use_walk_forward:
                # 이동 윈도우 예측 (회귀 모델용)
                window_size = 30
                test_pred = np.zeros(len(test_data))

                for i in range(window_size, len(test_data)):
                    # 이하 동일한 방식으로 구현
                    pass
            else:
                # 기본 예측 방식
                test_data['Prediction'] = self.model.predict(self.X_test)
                # 다음 예측 가격이 현재 가격보다 높으면 매수 신호
                test_data['Signal'] = (test_data['Prediction'] > test_data['Close']).astype(int)

        # 2. 개선: 확신도에 따른 포지셔닝 사이즈 조정
        test_data['Position'] = test_data['Signal'].shift(1).fillna(0).astype(int)

        # 확신도 기반 포지션 사이즈 (0.6~1.0)
        if self.prediction_type == 'classification':
            # 0.5~1.0 범위의 확신도에 따라 0.6~1.0 범위로 스케일링
            test_data['PositionSize'] = test_data['PredictionProba'].apply(
                lambda x: 0.6 + 0.4 * (2 * abs(x - 0.5)) if x >= 0.5 else 0
            ).shift(1).fillna(0)
        else:
            # 회귀 모델의 경우 예측된 수익률의 크기에 따라 포지션 사이즈 조정
            expected_return = (test_data['Prediction'] / test_data['Close'] - 1)
            test_data['PositionSize'] = expected_return.apply(
                lambda x: min(1.0, max(0.6, 0.6 + 0.4 * min(1, x / 0.05))) if x > 0 else 0
            ).shift(1).fillna(0)

        # 수익률 계산
        test_data['Returns'] = test_data['Close'] / test_data['Close'].shift(1) - 1
        test_data['Strategy_Returns'] = test_data['Position'] * test_data['PositionSize'] * test_data['Returns']

        # 3. 개선: 손절/익절 로직 추가
        if stop_loss > 0 or take_profit > 0:
            # 손절/익절 적용
            positions = []  # 현재 포지션 추적
            entry_prices = []  # 진입 가격 추적

            for i in range(len(test_data)):
                if i == 0:
                    positions.append(0)
                    entry_prices.append(0)
                    continue

                prev_position = positions[-1]
                prev_entry = entry_prices[-1]

                # 새 포지션 시그널
                new_position = test_data['Position'].iloc[i]
                position_size = test_data['PositionSize'].iloc[i]

                if prev_position == 0 and new_position > 0:
                    # 새로운 매수 진입
                    positions.append(new_position)
                    entry_prices.append(test_data['Close'].iloc[i])
                elif prev_position > 0:
                    current_price = test_data['Close'].iloc[i]
                    returns = current_price / prev_entry - 1

                    # 손절/익절 조건 확인
                    if returns <= -stop_loss or returns >= take_profit:
                        # 포지션 청산
                        positions.append(0)
                        entry_prices.append(0)

                        # 실제 수익률 업데이트
                        test_data.loc[i, 'Strategy_Returns'] = (
                            prev_position * position_size * returns - transaction_cost
                        )
                    else:
                        # 포지션 유지
                        positions.append(new_position)
                        entry_prices.append(prev_entry)
                else:
                    # 이전과 동일한 포지션 유지
                    positions.append(new_position)
                    entry_prices.append(
                        prev_entry if new_position == prev_position else
                        (test_data['Close'].iloc[i] if new_position > 0 else 0)
                    )

            test_data['Actual_Position'] = positions
            test_data['Entry_Price'] = entry_prices

            # 최종 전략 수익률 업데이트
            test_data['Strategy_Returns_SL_TP'] = test_data['Actual_Position'] * test_data['PositionSize'] * test_data['Returns']

            # 손절/익절 이벤트 추적
            test_data['Stop_Loss'] = ((test_data['Actual_Position'].shift(1) > 0) &
                                (test_data['Actual_Position'] == 0) &
                                (test_data['Close'] < test_data['Entry_Price'].shift(1) * (1 - stop_loss)))

            test_data['Take_Profit'] = ((test_data['Actual_Position'].shift(1) > 0) &
                                    (test_data['Actual_Position'] == 0) &
                                    (test_data['Close'] > test_data['Entry_Price'].shift(1) * (1 + take_profit)))

            # 손절/익절 후 전략 수익률 사용
            test_data['Strategy_Returns'] = test_data['Strategy_Returns_SL_TP']

        # 4. 개선: 거래 비용 계산 정교화
        # 거래 발생 시점 파악
        test_data['Trade'] = test_data['Position'].diff().abs()

        # 매수/매도 시 다른 거래 비용 적용 (매도 시 더 높은 비용)
        buy_cost = transaction_cost
        sell_cost = transaction_cost * 1.2  # 매도 시 약간 더 높은 비용

        test_data['Buy'] = ((test_data['Position'].diff() > 0)).astype(int)
        test_data['Sell'] = ((test_data['Position'].diff() < 0)).astype(int)

        test_data['Cost'] = (test_data['Buy'] * buy_cost + test_data['Sell'] * sell_cost) * test_data['PositionSize']
        test_data['Strategy_Returns_Net'] = test_data['Strategy_Returns'] - test_data['Cost']

        # 5. 개선: 누적 수익 및 드로다운 계산
        test_data['Cumulative_Returns'] = (1 + test_data['Returns']).cumprod()
        test_data['Strategy_Cumulative_Returns'] = (1 + test_data['Strategy_Returns_Net']).cumprod()

        # 드로다운 계산
        test_data['BuyHold_Peak'] = test_data['Cumulative_Returns'].cummax()
        test_data['Strategy_Peak'] = test_data['Strategy_Cumulative_Returns'].cummax()

        test_data['BuyHold_Drawdown'] = (test_data['Cumulative_Returns'] / test_data['BuyHold_Peak'] - 1)
        test_data['Strategy_Drawdown'] = (test_data['Strategy_Cumulative_Returns'] / test_data['Strategy_Peak'] - 1)

        # 6. 개선: 백테스트 성과 지표 확장
        # 기본 성과 지표
        total_return = test_data['Strategy_Cumulative_Returns'].iloc[-1] - 1
        buy_hold_return = test_data['Cumulative_Returns'].iloc[-1] - 1

        # 연간 수익률
        days = (test_data['Date'].iloc[-1] - test_data['Date'].iloc[0]).days
        annual_return = (1 + total_return) ** (365 / max(days, 1)) - 1
        buy_hold_annual = (1 + buy_hold_return) ** (365 / max(days, 1)) - 1

        # 샤프 비율
        daily_returns = test_data['Strategy_Returns_Net']
        daily_risk_free = 0.03 / 252  # 연 3% 무위험 수익률 가정
        excess_returns = daily_returns - daily_risk_free
        sharpe_ratio = np.sqrt(252) * excess_returns.mean() / max(daily_returns.std(), 1e-6)

        # 칼마 비율 (Calmar Ratio) - 연간 수익률 / 최대 낙폭
        max_drawdown = test_data['Strategy_Drawdown'].min()
        calmar_ratio = annual_return / abs(max_drawdown) if max_drawdown < 0 else float('inf')

        # 승률 및 손익비
        profitable_trades = test_data[test_data['Position'] == 1]['Returns'] > 0
        win_rate = profitable_trades.mean() if len(profitable_trades) > 0 else 0

        # 평균 수익/손실 비율
        avg_win = test_data.loc[test_data['Position'] == 1, 'Returns'][
            test_data.loc[test_data['Position'] == 1, 'Returns'] > 0
        ].mean() if len(profitable_trades[profitable_trades]) > 0 else 0

        avg_loss = test_data.loc[test_data['Position'] == 1, 'Returns'][
            test_data.loc[test_data['Position'] == 1, 'Returns'] < 0
        ].mean() if len(profitable_trades[~profitable_trades]) > 0 else 0

        profit_loss_ratio = abs(avg_win / avg_loss) if avg_loss < 0 else float('inf')

        # 최대 연속 손실/이익
        consecutive_wins = 0
        consecutive_losses = 0
        max_consecutive_wins = 0
        max_consecutive_losses = 0

        for i in range(len(test_data)):
            if test_data['Position'].iloc[i] == 1:
                if test_data['Returns'].iloc[i] > 0:
                    consecutive_wins += 1
                    consecutive_losses = 0
                elif test_data['Returns'].iloc[i] < 0:
                    consecutive_losses += 1
                    consecutive_wins = 0

                max_consecutive_wins = max(max_consecutive_wins, consecutive_wins)
                max_consecutive_losses = max(max_consecutive_losses, consecutive_losses)

        # 일평균 가격 변동폭 계산
        try:
            avg_daily_range = ((test_data['High'] - test_data['Low']) / test_data['Close']).mean()
        except Exception as e:
            print(f"일평균 변동폭 계산 오류: {e}")
            avg_daily_range = 0.03  # 기본값으로 3% 설정

        # 7. 개선: 결과 시각화 및 출력
        print(f"\n===== 백테스트 결과 요약 =====")
        print(f"총 수익률: {total_return:.4f} ({total_return * 100:.2f}%) vs. 매수 후 보유: {buy_hold_return:.4f} ({buy_hold_return * 100:.2f}%)")
        print(f"연간 수익률: {annual_return:.4f} ({annual_return * 100:.2f}%) vs. 매수 후 보유: {buy_hold_annual:.4f} ({buy_hold_annual * 100:.2f}%)")
        print(f"샤프 비율: {sharpe_ratio:.4f}")
        print(f"칼마 비율: {calmar_ratio:.4f}")
        print(f"최대 손실: {max_drawdown:.4f} ({max_drawdown * 100:.2f}%)")
        print(f"승률: {win_rate:.4f} ({win_rate * 100:.2f}%)")
        print(f"손익비: {profit_loss_ratio:.2f}")
        print(f"최대 연속 이익: {max_consecutive_wins}, 최대 연속 손실: {max_consecutive_losses}")
        print(f"총 거래 횟수: {test_data['Trade'].sum() / 2:.0f}")

        if 'Stop_Loss' in test_data and 'Take_Profit' in test_data:
            sl_count = test_data['Stop_Loss'].sum()
            tp_count = test_data['Take_Profit'].sum()
            print(f"손절 횟수: {sl_count}, 익절 횟수: {tp_count}")

        # 백테스트 결과 저장
        self.backtest_results = {
            'total_return': total_return,
            'buy_hold_return': buy_hold_return,
            'annual_return': annual_return,
            'sharpe_ratio': sharpe_ratio,
            'calmar_ratio': calmar_ratio,
            'max_drawdown': max_drawdown,
            'win_rate': win_rate,
            'profit_loss_ratio': profit_loss_ratio,
            'max_consecutive_wins': max_consecutive_wins,
            'max_consecutive_losses': max_consecutive_losses,
            'trade_count': test_data['Trade'].sum() / 2,
            'avg_daily_range': avg_daily_range,
            'test_data': test_data  # 분석을 위해 테스트 데이터 저장
        }

        return self.backtest_results

def get_financial_info(stock_code):
        """
        네이버 금융에서 재무정보 스크래핑

        Parameters:
        -----------
        stock_code : str
            종목 코드

        Returns:
        --------
        dict
            재무 정보 포함한 딕셔너리
        """
        import requests
        from bs4 import BeautifulSoup
        import pandas as pd

        try:
            # 네이버 금융 종목 페이지 URL
            url = f"https://finance.naver.com/item/main.naver?code={stock_code}"

            # 페이지 요청
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
            response = requests.get(url, headers=headers)
            response.encoding = 'euc-kr'

            # BeautifulSoup로 HTML 파싱
            soup = BeautifulSoup(response.text, 'html.parser')

            # 재무정보 추출
            financial_info = {}

            # 투자지표 테이블
            finance_table = soup.select('#tab_con1 > div:nth-child(3) > table > tbody > tr')

            # PER, PBR, ROE 등 기본 투자지표 추출
            for row in finance_table:
                th_tags = row.find_all('th')
                td_tags = row.find_all('td', class_='num')

                if len(th_tags) > 0 and len(td_tags) > 0:
                    indicator_name = th_tags[0].text.strip()
                    # 가장 최근 분기 데이터 사용
                    indicator_value = td_tags[0].text.strip().replace('%', '').replace(',', '')

                    try:
                        indicator_value = float(indicator_value)
                        financial_info[indicator_name] = indicator_value
                    except:
                        pass

            # 더 많은 정보가 필요하면 여기에 추가 스크래핑 코드 작성
            # 예: 매출액, 영업이익, 순이익 등

            return financial_info

        except Exception as e:
            print(f"재무정보 스크래핑 오류: {e}")
            return {}

def create_ensemble_model(stock_code, period='2y', prediction_period=5):
        """
        재무정보와 기술적 지표를 결합한 앙상블 모델 생성

        Parameters:
        -----------
        stock_code : str
            종목 코드
        period : str
            분석 기간
        prediction_period : int
            예측 기간

        Returns:
        --------
        dict
            앙상블 예측 결과
        """
        # 주가 데이터 다운로드
        import yfinance as yf
        ticker = f"{stock_code}.KS"
        session = requests.Session(impersonate="chrome")
        stock = yf.Ticker(ticker,session=session)
        df = stock.history(period=period)
        df.reset_index(inplace=True)

        # 1. 기술적 지표 모델
        tech_model = StockPredictionModel(prediction_period=prediction_period)
        tech_model.load_data(df=df)
        tech_model.create_features(advanced=True)
        tech_model.prepare_data(test_size=0.2)
        tech_model.train_model(optimize=True, n_iter=10)
        tech_model.select_important_features(threshold=0.01)
        tech_prediction = tech_model.predict_future()

        # 2. 재무 정보 활용 모델
        financial_model = StockPredictionModel(prediction_period=prediction_period)
        financial_model.load_data(df=df)
        financial_model.create_features(advanced=True, stock_code=stock_code)
        financial_model.prepare_data(test_size=0.2)
        financial_model.train_model(optimize=True, n_iter=10)
        financial_model.select_important_features(threshold=0.01)
        financial_prediction = financial_model.predict_future()

        # 3. 앙상블 (가중 평균)
        tech_pred = tech_prediction['Prediction'].iloc[0]
        tech_conf = tech_prediction['Confidence'].iloc[0]
        fin_pred = financial_prediction['Prediction'].iloc[0]
        fin_conf = financial_prediction['Confidence'].iloc[0]

        # 기술적 지표와 재무 정보의 가중치 설정 (60:40)
        ensemble_pred = tech_pred * 0.6 + fin_pred * 0.4
        ensemble_conf = tech_conf * 0.6 + fin_conf * 0.4

        final_prediction = 1 if ensemble_pred > 0.5 else 0
        final_confidence = ensemble_conf if final_prediction == 1 else 1 - ensemble_conf

        return {
            'prediction': final_prediction,
            'confidence': final_confidence,
            'tech_prediction': tech_pred,
            'tech_confidence': tech_conf,
            'fin_prediction': fin_pred,
            'fin_confidence': fin_conf
        }

def create_enhanced_ensemble_model(stock_code, period='2y', prediction_period=5):
    """다중 모델 및 시점 앙상블로 정확도 향상"""
    # 주가 데이터 다운로드
    import yfinance as yf
    ticker = f"{stock_code}.KS"
    session = requests.Session(impersonate="chrome")
    stock = yf.Ticker(ticker,session=session)
    df = stock.history(period=period)
    df.reset_index(inplace=True)

    # 다양한 예측 기간의 모델 결과 수집
    period_results = []
    for pred_period in [1, 3, 5, 10]:
        # 모델 생성 및 학습
        model = StockPredictionModel(prediction_period=pred_period)
        model.load_data(df=df)
        model.create_features(advanced=True, stock_code=stock_code if pred_period == prediction_period else None)
        model.prepare_data(test_size=0.2)
        # 빠른 학습 (주기간만 최적화)
        optimize = (pred_period == prediction_period)
        model.train_model(optimize=optimize, n_iter=10 if optimize else 5)

        if optimize:
            model.select_important_features(threshold=0.01)

        # 향상된 예측 수행
        if hasattr(model, 'enhanced_prediction'):
            prediction = model.enhanced_prediction()
        else:
            prediction = model.predict_future()

        # 결과 저장
        pred = prediction['Prediction'].iloc[0]
        conf = prediction['Confidence'].iloc[0]

        # 예측 기간에 따른 가중치 설정 (주 기간에 더 높은 가중치)
        weight = 2.0 if pred_period == prediction_period else 1.0

        period_results.append((pred_period, pred, conf, weight))

    # 가중 투표로 앙상블
    weighted_sum = sum(p * c * w for _, p, c, w in period_results)
    total_weight = sum(c * w for _, _, c, w in period_results)

    # 예측 및 신뢰도 계산
    ensemble_pred = weighted_sum / total_weight if total_weight > 0 else 0.5
    final_prediction = 1 if ensemble_pred > 0.5 else 0

    # 신뢰도 계산
    # 각 모델의 확신도와 예측이 전체 결과와 일치할수록 높은 신뢰도
    agreement_factor = sum(1 for _, p, _, _ in period_results if (p > 0.5) == (final_prediction == 1))
    agreement_ratio = agreement_factor / len(period_results)

    # 주 모델의 확신도 찾기
    main_confidence = next((c for p, _, c, _ in period_results if p == prediction_period), 0.6)

    # 최종 확신도 계산 (주 모델 확신도 * 일치도)
    final_confidence = main_confidence * (0.7 + 0.3 * agreement_ratio)

    return {
        'prediction': final_prediction,
        'confidence': final_confidence,
        'models': period_results
    }

# 개선된 앙상블 예측 모델
def ensemble_predictions(stock_code, periods=[1, 3, 5, 10]):
    """여러 예측 기간의 모델을 앙상블하여 예측"""
    results = []

    # 데이터 다운로드
    import yfinance as yf
    ticker = f"{stock_code}.KS"
    session = requests.Session(impersonate="chrome")
    stock = yf.Ticker(ticker,session=session)
    df = stock.history(period="5y")  # 5년 데이터로 확장
    df.reset_index(inplace=True)

    for period in periods:
        # 모델 생성
        model = StockPredictionModel(prediction_period=period)

        # 데이터 준비 및 모델 학습
        model.load_data(df=df)
        model.create_features(advanced=True)
        model.prepare_data(test_size=0.2)
        model.train_model(optimize=True, n_iter=10)  # 최적화 활성화

        # 특성 선택 적용
        model.select_important_features(threshold=0.01)

        # 미래 예측
        prediction = model.predict_future()
        results.append((period, prediction['Prediction'].iloc[0], prediction['Confidence'].iloc[0]))

    # 다수결 또는 가중 투표로 최종 결정
    # 예시: 확신도로 가중 평균
    weighted_sum = sum(conf * pred for _, pred, conf in results)
    total_conf = sum(conf for _, _, conf in results)

    final_prediction = 1 if weighted_sum/total_conf > 0.5 else 0
    confidence = weighted_sum/total_conf if final_prediction == 1 else 1 - weighted_sum/total_conf

    return {'prediction': final_prediction, 'confidence': confidence, 'models': results}

class StockAnalyzer:
    """
    다중 주식 분석 및 스크리닝을 위한 클래스
    StockPredictionModel을 사용하여 다수의 주식을 분석하고 결과를 비교합니다.
    """

    def __init__(self):
        """
        주식 분석기 초기화
        """
        self.stock_data = {}
        self.analysis_results = {}

    def _analyze_stock_helper(self, args):
        """병렬 처리를 위한 헬퍼 메서드"""
        code, company = args
        try:
            return code, self.analyze_stock(code, company, period='2y', prediction_period=5)  # 개선: 5년 데이터 사용
        except Exception as e:
            print(f"{code} 분석 실패: {str(e)}")
            return code, None
    def manage_gpu_memory(self):
        """GPU 메모리 정리 함수"""
        import gc
        gc.collect()

        try:
            # CUDA 메모리 확인 및 정리
            import subprocess
            result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.free', '--format=csv'],
                                    stdout=subprocess.PIPE, text=True)
            print(f"GPU 메모리 상태:\n{result.stdout}")

            # XGBoost 내부 CUDA 메모리 정리
            try:
                import xgboost as xgb
                xgb.config_context(verbosity=0)
                print("XGBoost CUDA 캐시 정리 시도")
            except:
                pass

            # PyTorch CUDA 메모리 정리 (설치된 경우)
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    print("PyTorch CUDA 캐시 정리 완료")
            except (ImportError, AttributeError):
                pass

            print("GPU 메모리 정리 완료")
        except Exception as e:
            print(f"GPU 메모리 정리 시도 중 오류: {e}")

    def get_krx_stock_codes(self):
        """
        한국 거래소(KRX) 종목 코드 가져오기
        """
        try:
            # 여러 방법으로 시도
            parsers = ['html5lib', 'lxml', 'bs4']

            for parser in parsers:
                try:
                    # macOS에서 SSL 인증서 검증 문제 해결
                    import ssl
                    ssl._create_default_https_context = ssl._create_unverified_context

                    # KRX 종목 코드 가져오기
                    krx = pd.read_html('http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&searchType=13',
                                    header=0, encoding='euc-kr', flavor=parser)[0]
                    krx = krx[['종목코드', '회사명']]
                    krx['종목코드'] = krx['종목코드'].apply(lambda x: f'{x:06d}')
                    krx = krx.rename(columns={'종목코드': 'code', '회사명': 'company'})

                    print(f"KRX 종목 수: {len(krx)} (parser: {parser})")
                    return krx
                except Exception as e:
                    print(f"{parser} 파서 사용 실패: {e}")

            # 모든 파서가 실패하면 예시 데이터 반환
            raise Exception("모든 파서가 실패했습니다.")
        except Exception as e:
            print(f"KRX 종목 다운로드 실패: {e}")
            # 예시 코드 반환 (실패 시)
            return pd.DataFrame({
                'code': ['005930', '000660', '035720', '051910', '035420'],
                'company': ['삼성전자', 'SK하이닉스', '카카오', 'LG화학', 'NAVER']
            })

    # StockAnalyzer 클래스 내부에 추가 (다른 메서드들과 같은 레벨에)
    def analyze_in_batches(self, stock_codes, batch_size=None, period='2y', prediction_period=5, workers=1, advanced_features=True):
        """🔥 GPU 메모리 최적화 배치 처리 (정확도 유지)"""
        import gc
        
        # 🔥 GPU 메모리 기반 배치 크기 최적화
        if batch_size is None:
            try:
                import torch
                if torch.cuda.is_available():
                    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                    if total_memory >= 14:  # T4 GPU
                        batch_size = 100      # 80 → 50 (안정성 확보)
                    elif total_memory >= 10:
                        batch_size = 35
                    else:
                        batch_size = 25
                    print(f"🚀 GPU 최적화 배치: {batch_size}")
                else:
                    batch_size = 15
            except:
                batch_size = 20

        all_results = {}

        if isinstance(stock_codes, pd.DataFrame):
            codes_list = list(zip(stock_codes['code'], stock_codes['company']))
        else:
            codes_list = [(code, None) for code in stock_codes]

        total_batches = (len(codes_list) + batch_size - 1) // batch_size
        print(f"🔥 GPU 배치 처리: {len(codes_list)}개 → {total_batches}배치")

        for i in range(0, len(codes_list), batch_size):
            batch = codes_list[i:i+batch_size]
            print(f"\n🚀 배치 {i//batch_size + 1}/{total_batches} 처리... ({len(batch)}개)")

            batch_results = {}
            for j, (code, company) in enumerate(batch):
                try:
                    print(f"  ⚡ {j+1}/{len(batch)}: {company or code}")
                    result = self.analyze_stock(
                        code, company, period,
                        prediction_period=prediction_period,
                        advanced_features=advanced_features  # True 유지 (정확도 위해)
                    )
                    if result is not None:
                        batch_results[code] = result
                        
                    # 🔥 스마트 메모리 관리
                    if (j + 1) % 5 == 0:  # 5개마다 정리 (10 → 5)
                        gc.collect()
                        try:
                            import torch
                            if torch.cuda.is_available():
                                torch.cuda.empty_cache()
                        except:
                            pass
                            
                except Exception as e:
                    print(f"    ❌ {code} 실패: {e}")

            all_results.update(batch_results)

            # 배치 완료 후 철저한 메모리 정리
            gc.collect()
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
            except:
                pass

            success_rate = len(batch_results) / len(batch) * 100
            print(f"✅ 배치 완료 - 성공률: {success_rate:.1f}% 누적: {len(all_results)}개")

        self.analysis_results.update(all_results)
        print(f"🎉 최적화 분석 완료! {len(all_results)}개 성공")
        return all_results

    def download_stock_data(self, stock_code, period='2y', proxy=None):  # 개선: 기본값 5y로 변경
        """
        Yahoo Finance에서 주식 데이터 다운로드

        Parameters:
        -----------
        stock_code : str
            종목 코드
        period : str
            다운로드 기간 ('1d', '5d', '1mo', '3mo', '6mo', '1y', '2y', '5y', '10y', 'max')
        proxy : str, optional
            프록시 서버 URL

        Returns:
        --------
        DataFrame
            주가 데이터
        """
        try:
            # 한국 주식은 종목코드.KS 형식으로 요청
            ticker = f"{stock_code}.KS"

            # Yahoo Finance에서 데이터 다운로드
            session = requests.Session(impersonate="chrome")
            stock = yf.Ticker(ticker,session=session)
            df = stock.history(period=period)

            # 인덱스를 Date 열로 변환
            df.reset_index(inplace=True)
            df.rename(columns={'Date': 'Date', 'Open': 'Open', 'High': 'High',
                             'Low': 'Low', 'Close': 'Close', 'Volume': 'Volume'}, inplace=True)

            # 필요한 열만 선택
            df = df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]

            return df
        except Exception as e:
            print(f"{stock_code} 데이터 다운로드 실패: {e}")
            return None

    def analyze_all_stocks_parallel(self, stock_codes=None, period='2y', max_stocks=None, prediction_period=5, workers=None):
        """
        다수의 주식을 병렬로 분석

        Parameters:
        -----------
        stock_codes : DataFrame or list, optional
            분석할 종목 코드 목록
        period : str
            분석 기간
        max_stocks : int, optional
            최대 분석 종목 수
        prediction_period : int
            예측 기간 (일)
        workers : int
            병렬 처리에 사용할 작업자 수

        Returns:
        --------
        dict
            분석 결과 딕셔너리
        """
        # ThreadPoolExecutor를 사용 (matplotlib 문제 방지)
        from concurrent.futures import ThreadPoolExecutor, as_completed

        # matplotlib 백엔드를 'Agg'로 설정하여 UI 창이 열리지 않도록 함
        import matplotlib
        matplotlib.use('Agg')

        # XGBoost 경고 메시지 억제
        import warnings
        warnings.filterwarnings("ignore", message="Dataset is empty, or contains only positive or negative samples")

        import os
        if workers is None:
            try:
                available_cpus = os.cpu_count()
                # 시스템 메모리에 따라 적절한 작업자 수 결정
                import psutil
                available_memory_gb = psutil.virtual_memory().available / (1024**3)

                # 메모리 기반 작업자 수 조정 (각 작업자가 약 2GB 사용한다고 가정)
                memory_based_workers = max(1, int(available_memory_gb / 2))

                # CPU와 메모리 기반 중 더 작은 값 선택
                workers = min(available_cpus, memory_based_workers)

                # 너무 많은 작업자는 오히려 성능 저하 가능
                workers = min(workers, 8)
            except:
                workers = 4  # 기본값

        print(f"총 {len(codes_list)}개 종목 병렬 분석 시작 (작업자: {workers}명, 시스템 CPU: {os.cpu_count()}개)...")

        if stock_codes is None:
            # KRX 종목 코드 가져오기
            stock_codes = self.get_krx_stock_codes()

        # 데이터프레임인 경우 처리
        if isinstance(stock_codes, pd.DataFrame):
            codes_list = list(zip(stock_codes['code'], stock_codes['company']))
        else:
            codes_list = [(code, None) for code in stock_codes]

        # 최대 종목 수 제한
        if max_stocks is not None:
            codes_list = codes_list[:max_stocks]

        print(f"총 {len(codes_list)}개 종목 병렬 분석 시작 (작업자: {workers}명)...")

        # 분석 결과 저장
        results = {}

        # 각 종목 분석을 위한 함수
        def _analyze_stock_wrapper(args):
            code, company = args
            try:
                # 종목별 분석 수행 - advanced_features=False로 고정하여 오류 방지
                result = self.analyze_stock(code, company, period, prediction_period,
                                        advanced_features=False)  # 항상 False로 설정
                return code, result
            except AttributeError as e:
                if "no attribute 'CDL" in str(e):
                    print(f"{code} 분석 실패: TA-Lib 패턴 함수 누락 - {e}")
                    # 이미 advanced_features=False로 설정했으므로 재시도 로직 제거
                    return code, None
                else:
                    print(f"{code} 분석 실패: {e}")
                    return code, None
            except Exception as e:
                print(f"{code} 분석 실패: {e}")
                return code, None

        # ThreadPoolExecutor로 병렬 처리
        with ThreadPoolExecutor(max_workers=workers) as executor:
            # 작업 제출
            futures = []
            for code_company in codes_list:
                future = executor.submit(_analyze_stock_wrapper, code_company)
                futures.append(future)

            # 진행 상황 표시
            for future in tqdm(as_completed(futures), total=len(futures), desc="주식 병렬 분석 중"):
                try:
                    code, result = future.result()
                    if result is not None:
                        results[code] = result
                except Exception as e:
                    print(f"분석 중 오류 발생: {e}")
                    continue

        print(f"\n분석 완료: {len(results)}개 종목 (성공: {len(results)}, 실패: {len(codes_list) - len(results)})")

        # 결과 저장
        self.analysis_results = results

        return results

    def filter_stocks_by_quality(self, stock_codes, min_volume=500000, min_days=200):
        """
        고품질 주식만 필터링 - 더 엄격한 기준 적용

        Parameters:
        -----------
        stock_codes : DataFrame
            분석할 종목 코드 목록
        min_volume : int
            최소 평균 거래량
        min_days : int
            최소 거래일 수

        Returns:
        --------
        DataFrame
            필터링된 종목 목록
        """
        filtered_stocks = []

        print(f"거래량 기준으로 종목 필터링 중... (최소 거래량: {min_volume:,}주)")

        for code, company in tqdm(zip(stock_codes['code'], stock_codes['company']),
                                total=len(stock_codes), desc="주식 필터링"):
            try:
                # 데이터 다운로드
                df = self.download_stock_data(code, period='2y')

                if df is None or len(df) < min_days * 0.8:  # 데이터가 충분하지 않으면 제외
                    continue

                # 1. 거래량 필터
                avg_volume = df['Volume'].mean()
                recent_volume = df['Volume'].tail(20).mean()

                # 2. 변동성 필터 (극단적 변동성 제외)
                returns = df['Close'].pct_change().dropna()
                volatility = returns.std()

                # 3. 가격 필터 (너무 낮은 가격 제외)
                avg_price = df['Close'].mean()

                # 4. 유동성 필터 (거래일별 가격 변동과 거래량의 관계)
                price_volume_corr = df['Close'].pct_change().abs().corr(df['Volume'])

                # 5. 추세 강도 필터 (ADX 추세 지표 사용)
                if len(df) >= 30:  # ADX 계산에 필요한 최소 데이터
                    try:
                        df['ADX'] = talib.ADX(df['High'], df['Low'], df['Close'], timeperiod=14)
                        avg_adx = df['ADX'].mean()
                    except:
                        avg_adx = 0
                else:
                    avg_adx = 0

                # 6. 이상치 빈도 필터 (극단적 가격 변동 일수)
                outlier_threshold = 3 * volatility
                outlier_pct = (returns.abs() > outlier_threshold).mean()

                # 7. 종목 품질 점수 계산
                quality_score = 0

                # 거래량 점수 (최대 3점)
                if avg_volume >= min_volume * 2:
                    quality_score += 3
                elif avg_volume >= min_volume * 1.5:
                    quality_score += 2
                elif avg_volume >= min_volume:
                    quality_score += 1

                # 최근 거래량 점수 (최대 2점)
                if recent_volume >= min_volume:
                    quality_score += 1
                    if recent_volume >= avg_volume * 0.9:  # 최근 거래량이 평균의 90% 이상
                        quality_score += 1

                # 변동성 점수 (최대 2점)
                if volatility < 0.04:  # 4% 이하 변동성
                    quality_score += 2
                elif volatility < 0.06:  # 6% 이하 변동성
                    quality_score += 1

                # 가격 점수 (최대 2점)
                if avg_price >= 10000:  # 만원 이상
                    quality_score += 2
                elif avg_price >= 5000:  # 5천원 이상
                    quality_score += 1

                # 추세 점수 (최대 2점)
                if avg_adx >= 25:  # 강한 추세
                    quality_score += 2
                elif avg_adx >= 15:  # 중간 추세
                    quality_score += 1

                # 이상치 점수 (최대 1점)
                if outlier_pct <= 0.01:  # 1% 이하 이상치
                    quality_score += 1

                # 데이터 충분성 점수 (최대 1점)
                if len(df) >= min_days:
                    quality_score += 1

                # 품질 점수가 6점 이상인 종목만 선택 (총 13점 만점)
                if quality_score >= 6:
                    filtered_stocks.append({
                        'code': code,
                        'company': company,
                        'quality_score': quality_score,
                        'avg_volume': avg_volume,
                        'volatility': volatility,
                        'avg_price': avg_price,
                        'avg_adx': avg_adx
                    })

            except Exception as e:
                # 오류 발생 시 해당 종목 건너뛰기
                continue

        # 결과 데이터프레임 생성
        filtered_df = pd.DataFrame(filtered_stocks)

        if not filtered_df.empty:
            # 품질 점수 기준 내림차순 정렬
            filtered_df = filtered_df.sort_values('quality_score', ascending=False)

            # 품질 등급 추가
            conditions = [
                (filtered_df['quality_score'] >= 10),
                (filtered_df['quality_score'] >= 8),
                (filtered_df['quality_score'] >= 6)
            ]
            grades = ['A', 'B', 'C']
            filtered_df['quality_grade'] = np.select(conditions, grades, default='D')

        print(f"필터링 결과: {len(filtered_df)}개 종목 선택됨 (전체 {len(stock_codes)}개 중)")

        if not filtered_df.empty:
            print("\n상위 10개 고품질 종목:")
            top_10 = filtered_df.head(10)[['code', 'company', 'quality_score', 'quality_grade', 'avg_volume']]
            top_10['avg_volume'] = top_10['avg_volume'].map(lambda x: f"{int(x):,}")
            print(top_10.to_string(index=False))

        return filtered_df[['code', 'company', 'quality_score', 'quality_grade']]

    def analyze_stock(self, stock_code, company_name=None, period='2y', prediction_period=5, use_financials=False, advanced_features=True):
        """🔥 개별 종목 최적화 분석 (정확도 유지)"""
        try:
            # 데이터 다운로드
            df = self.download_stock_data(stock_code, period=period)
            if df is None or len(df) < 100:
                return None

            # 🔥 거래량 기준 완화 (더 많은 종목 포함)
            if df['Volume'].mean() < 200000:  # 500000 → 200000 (기회 확대)
                return None

            # 모델 초기화
            model = StockPredictionModel(
                prediction_type='classification',
                prediction_period=prediction_period,
                confidence_threshold=0.7
            )

            model.load_data(df=df)
            
            # 🔥 특성 생성 (advanced=True 유지 - 정확도 위해)
            model.create_features(advanced=advanced_features, stock_code=None)  # 재무정보는 제외 (속도)
            model.prepare_data(test_size=0.2)

            # 🔥 단계별 학습 (정확도 확보)
            # 1단계: 기본 학습
            model.train_model(optimize=False)
            
            # 2단계: 특성 선택 (중요도 기반)
            try:
                model.select_important_features(threshold=0.005, top_n=None)  # 임계값 낮춤 (더 많은 특성 유지)
            except:
                pass  # 특성 선택 실패해도 계속 진행
            
            # 3단계: 최종 학습
            model.train_model(optimize=False)  # 빠른 학습이지만 앙상블로 정확도 확보

            # 평가
            try:
                metrics = model.evaluate_model()
            except:
                metrics = {'accuracy': 0.5, 'precision': 0, 'recall': 0, 'f1': 0, 'auc': 0.5}

            # 🔥 간소화된 백테스트 (핵심 지표만)
            try:
                backtest_results = model.backtest(
                    transaction_cost=0.001, 
                    stop_loss=0.03, 
                    take_profit=0.05
                )
            except:
                backtest_results = {
                    'total_return': 0, 'buy_hold_return': 0, 'annual_return': 0,
                    'sharpe_ratio': 0, 'max_drawdown': 0, 'win_rate': 0.5, 'trade_count': 0
                }

            # 예측
            future_prediction = model.predict_future(days=1)
            prediction_signal = "매수" if future_prediction['Prediction'].iloc[0] == 1 else "매도"
            prediction_confidence = future_prediction['Confidence'].iloc[0]

            # 결과 반환
            return {
                'stock_code': stock_code,
                'company_name': company_name,
                'accuracy': model.test_accuracy or 0.5,
                'metrics': metrics,
                'backtest': backtest_results,
                'latest_price': df['Close'].iloc[-1],
                'prediction_signal': prediction_signal,
                'prediction_confidence': prediction_confidence,
                'volatility': df['Close'].pct_change().std(),
                'avg_volume': df['Volume'].mean()
            }

        except Exception as e:
            print(f"분석 실패 {stock_code}: {e}")
            return None

    def analyze_all_stocks(self, stock_codes=None, period='2y', max_stocks=None, prediction_period=5):  # 개선: 5y로 변경
        """
        다수의 주식 분석 및 스크리닝

        Parameters:
        -----------
        stock_codes : DataFrame or list, optional
            분석할 종목 코드 목록
        period : str
            분석 기간
        max_stocks : int, optional
            최대 분석 종목 수
        prediction_period : int
            예측 기간 (일)

        Returns:
        --------
        dict
            분석 결과 딕셔너리
        """
        if stock_codes is None:
            # KRX 종목 코드 가져오기
            stock_codes = self.get_krx_stock_codes()

        # 데이터프레임인 경우 처리
        if isinstance(stock_codes, pd.DataFrame):
            codes_list = list(zip(stock_codes['code'], stock_codes['company']))
        else:
            codes_list = [(code, None) for code in stock_codes]

        # 최대 종목 수 제한
        if max_stocks is not None:
            codes_list = codes_list[:max_stocks]

        print(f"총 {len(codes_list)}개 종목 분석 시작...")

        # 분석 결과 저장
        results = {}

        # 프로그레스바로 진행 상황 표시
        for i, (code, company) in enumerate(tqdm(codes_list, desc="주식 분석 중")):
            result = self.analyze_stock(code, company, period, prediction_period)
            if result is not None:
                results[code] = result

        print(f"\n분석 완료: {len(results)}개 종목 (성공: {len(results)}, 실패: {len(codes_list) - len(results)})")

        # 결과 저장
        self.analysis_results = results

        return results

    def get_top_stocks(self, criteria='combined_score', top_n=10, ascending=False):
        """
        특정 기준으로 상위 종목 선택 - 개선된 복합 점수

        Parameters:
        -----------
        criteria : str
            정렬 기준 ('combined_score', 'backtest_return', 'accuracy', 'sharpe_ratio', 'win_rate' 등)
        top_n : int
            반환할 상위 종목 수
        ascending : bool
            오름차순 정렬 여부

        Returns:
        --------
        DataFrame
            상위 종목 데이터프레임
        """
        if not self.analysis_results:
            raise ValueError("먼저 analyze_all_stocks() 메서드를 호출하세요.")

        # 결과를 데이터프레임으로 변환
        results_data = []

        for code, result in self.analysis_results.items():
            if result is None:
                continue

            data = {
                'code': code,
                'company': result.get('company_name', code),
                'accuracy': result['accuracy'],
                'backtest_return': result['backtest']['total_return'],
                'buy_hold_return': result['backtest']['buy_hold_return'],
                'annual_return': result['backtest']['annual_return'],
                'sharpe_ratio': result['backtest']['sharpe_ratio'],
                'calmar_ratio': result['backtest'].get('calmar_ratio', 0),
                'max_drawdown': result['backtest']['max_drawdown'],
                'win_rate': result['backtest']['win_rate'],
                'profit_loss_ratio': result['backtest'].get('profit_loss_ratio', 1),
                'prediction_signal': result['prediction_signal'],
                'prediction_confidence': result.get('prediction_confidence', 0),
                'latest_price': result.get('latest_price', 0),
                'volatility': result.get('volatility', 0),
                'avg_volume': result.get('avg_volume', 0)
            }

            # 복합 점수 계산 (여러 지표의 가중 평균)
            if criteria == 'combined_score':
                # 복합 점수 요소들 정규화 (0~1 범위로)
                backtest_score = min(max(data['backtest_return'] / 0.5, 0), 1)  # 50% 수익률까지 스케일
                accuracy_score = data['accuracy']
                sharpe_score = min(max(data['sharpe_ratio'] / 3, 0), 1)  # 샤프 3까지 스케일
                win_rate_score = data['win_rate']
                max_drawdown_score = 1 - min(abs(data['max_drawdown']) / 0.3, 1)  # 30% 손실까지 스케일

                # 가중 평균으로 복합 점수 계산
                data['combined_score'] = (
                    backtest_score * 0.3 +       # 백테스트 수익률 (30%)
                    accuracy_score * 0.2 +        # 모델 정확도 (20%)
                    sharpe_score * 0.2 +          # 샤프 비율 (20%)
                    win_rate_score * 0.15 +       # 승률 (15%)
                    max_drawdown_score * 0.15     # 최대 손실 (15%)
                )

            results_data.append(data)

        # 데이터프레임 생성
        df_results = pd.DataFrame(results_data)

        # 복합 점수 없을 경우 계산
        if 'combined_score' not in df_results.columns and criteria == 'combined_score':
            # 정규화 함수
            def normalize(series, min_val, max_val):
                return (series - min_val) / (max_val - min_val) if max_val > min_val else series * 0

            # 정규화된 지표 계산
            backtest_norm = normalize(df_results['backtest_return'],
                                    df_results['backtest_return'].min(),
                                    df_results['backtest_return'].max())

            accuracy_norm = normalize(df_results['accuracy'],
                                    df_results['accuracy'].min(),
                                    df_results['accuracy'].max())

            sharpe_norm = normalize(df_results['sharpe_ratio'],
                                df_results['sharpe_ratio'].min(),
                                df_results['sharpe_ratio'].max())

            win_rate_norm = normalize(df_results['win_rate'],
                                    df_results['win_rate'].min(),
                                    df_results['win_rate'].max())

            # 드로다운은 작을수록 좋음
            drawdown_norm = 1 - normalize(df_results['max_drawdown'].abs(),
                                        df_results['max_drawdown'].abs().min(),
                                        df_results['max_drawdown'].abs().max())

            # 복합 점수 계산
            df_results['combined_score'] = (
                backtest_norm * 0.3 +
                accuracy_norm * 0.2 +
                sharpe_norm * 0.2 +
                win_rate_norm * 0.15 +
                drawdown_norm * 0.15
            )

        # 기준에 따라 정렬
        if criteria not in df_results.columns:
            print(f"경고: '{criteria}' 열을 찾을 수 없습니다. 'combined_score'를 사용합니다.")
            sort_col = 'combined_score'
        else:
            sort_col = criteria

        # 정렬 및 상위 종목 선택
        df_sorted = df_results.sort_values(sort_col, ascending=ascending)
        top_stocks = df_sorted.head(top_n)

        # 결과 출력
        print(f"\n===== {criteria} 기준 상위 {top_n}개 종목 =====")
        display_cols = ['code', 'company', sort_col, 'backtest_return', 'accuracy', 'sharpe_ratio', 'win_rate', 'prediction_signal']

        # 출력용 포맷 데이터
        display_df = top_stocks[display_cols].copy()

        # 퍼센트 포맷팅
        for col in ['backtest_return', 'accuracy', 'win_rate']:
            if col in display_df.columns:
                display_df[col] = display_df[col].map(lambda x: f"{x:.2%}")

        # 소수점 포맷팅
        for col in ['sharpe_ratio', 'combined_score']:
            if col in display_df.columns:
                display_df[col] = display_df[col].map(lambda x: f"{x:.3f}")

        print(display_df.to_string(index=False))

        return top_stocks

    def plot_top_stocks(self, criteria='backtest_return', top_n=10, ascending=False):
        """
        상위 종목 성과 시각화

        Parameters:
        -----------
        criteria : str
            정렬 기준
        top_n : int
            표시할 상위 종목 수
        ascending : bool
            오름차순 정렬 여부
        """
        # 상위 종목 가져오기
        top_stocks = self.get_top_stocks(criteria, top_n, ascending)

        # 백테스트 수익률 시각화
        plt.figure(figsize=(12, 6))
        bars = plt.bar(top_stocks['company'], top_stocks['backtest_return'] * 100)

        # 매수 후 보유 수익률 추가
        plt.bar(top_stocks['company'], top_stocks['buy_hold_return'] * 100, alpha=0.5, color='gray')

        # 그래프 꾸미기
        plt.title(f'상위 {top_n}개 종목 백테스트 수익률')
        plt.xlabel('종목명')
        plt.ylabel('수익률 (%)')
        plt.xticks(rotation=45, ha='right')
        plt.grid(axis='y', alpha=0.3)

        # 수익률 표시
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 1,
                    f'{height:.1f}%', ha='center', va='bottom')

        plt.tight_layout()
        # plt.show()

        # 정확도 vs 샤프 비율 산점도
        plt.figure(figsize=(10, 6))
        scatter = plt.scatter(top_stocks['accuracy'], top_stocks['sharpe_ratio'],
                            s=top_stocks['backtest_return'] * 1000, alpha=0.6,
                            c=top_stocks['win_rate'], cmap='viridis')

        # 종목명 표시
        for i, txt in enumerate(top_stocks['company']):
            plt.annotate(txt, (top_stocks['accuracy'].iloc[i], top_stocks['sharpe_ratio'].iloc[i]),
                        xytext=(5, 5), textcoords='offset points')

        plt.title('정확도 vs 샤프 비율')
        plt.xlabel('정확도')
        plt.ylabel('샤프 비율')
        plt.grid(True, alpha=0.3)
        plt.colorbar(scatter, label='승률')

        plt.tight_layout()
        # plt.show()

    # 개선: 최적화된 결과만 저장하는 메서드
    def save_optimized_results(self, all_results_df, filename):
        """
        최적화된 결과만 CSV에 저장 - 개선된 버전

        Parameters:
        -----------
        all_results_df : DataFrame
            모든 분석 결과 데이터프레임
        filename : str
            저장할 파일 이름

        Returns:
        --------
        DataFrame
            필터링된 고품질 결과
        """
        # 1. 필수 열 확인 및 처리
        essential_cols = [
            '종목코드', '종목명', '현재가',
            '예측방향', '예측확신도', '거래결정',
            '목표가', '손절가',  # 목표가/손절가는 중요한 매매 지표
            '정확도', '승률', '백테스트수익률'
        ]

        # 누락된 열 처리
        missing_cols = [col for col in essential_cols if col not in all_results_df.columns]
        if missing_cols:
            print(f"경고: 다음 열이 누락되었습니다: {missing_cols}")
            # 누락된 열 추가 (기본값으로)
            for col in missing_cols:
                if col == '종목코드' or col == '종목명':
                    continue  # 이 열들은 반드시 있어야 함
                all_results_df[col] = None

        # 사용 가능한 열만 선택
        available_cols = [col for col in essential_cols if col in all_results_df.columns]
        optimized_df = all_results_df[available_cols].copy()

        # 2. 거래 가능한 종목만 필터링 (관망 제외)
        if '거래결정' in optimized_df.columns:
            action_df = optimized_df[optimized_df['거래결정'] != '관망']
        else:
            # 거래결정 열이 없으면 예측방향으로 대체
            optimized_df['거래결정'] = optimized_df['예측방향'].apply(
                lambda x: x if x in ['매수', '매도'] else '관망'
            )
            action_df = optimized_df[optimized_df['거래결정'] != '관망']

        # 행이 없으면 처리
        if len(action_df) == 0:
            print("경고: 거래 가능한 종목이 없습니다. 모든 결과를 사용합니다.")
            action_df = optimized_df

        # 3. 개선: 다양한 품질 필터 적용
        # 3.1. 확신도 필터
        confidence_filter = (
            (action_df['예측확신도'] >= 0.55) if '예측확신도' in action_df.columns
            else pd.Series([True] * len(action_df))
        )

        # 3.2. 정확도 필터
        accuracy_filter = (
            (action_df['정확도'] >= 0.55) if '정확도' in action_df.columns
            else pd.Series([True] * len(action_df))
        )

        # 3.3. 승률 필터
        winrate_filter = (
            (action_df['승률'] >= 0.5) if '승률' in action_df.columns
            else pd.Series([True] * len(action_df))
        )

        # 3.4. 백테스트 수익률 필터
        return_filter = (
            (action_df['백테스트수익률'] > 0) if '백테스트수익률' in action_df.columns
            else pd.Series([True] * len(action_df))
        )

        # 조합된 필터 적용
        combined_filter = confidence_filter & accuracy_filter & winrate_filter & return_filter
        high_quality = action_df[combined_filter]

        # 필터링 결과가 너무 제한적인 경우 더 관대한 필터 적용
        if len(high_quality) < 5 and len(action_df) > 5:
            print("경고: 엄격한 필터링 후 종목이 너무 적습니다. 더 관대한 기준 적용...")

            # 더 관대한 필터
            relaxed_filter = (
                (action_df['예측확신도'] >= 0.5 if '예측확신도' in action_df.columns else True) &
                (action_df['정확도'] >= 0.52 if '정확도' in action_df.columns else True)
            )

            high_quality = action_df[relaxed_filter]

        # 여전히 결과가 너무 적으면 모든 거래 가능 종목 사용
        if len(high_quality) < 3 and len(action_df) > 0:
            print("경고: 필터링 후 종목이 너무 적습니다. 모든 거래 가능 종목 사용...")
            high_quality = action_df

        # 4. 종합 점수 계산 및 정렬
        if len(high_quality) > 0:
            # 정규화 함수
            def normalize(series, default=0.5):
                if len(series) == 0:
                    return pd.Series([default])

                min_val = series.min()
                max_val = series.max()

                if max_val == min_val:
                    return pd.Series([0.5] * len(series))

                return (series - min_val) / (max_val - min_val)

            # 가능한 열에 대해서만 점수 계산
            score_components = []

            if '예측확신도' in high_quality.columns:
                conf_norm = normalize(high_quality['예측확신도'])
                score_components.append(conf_norm * 0.4)  # 40% 가중치

            if '정확도' in high_quality.columns:
                acc_norm = normalize(high_quality['정확도'])
                score_components.append(acc_norm * 0.3)  # 30% 가중치

            if '승률' in high_quality.columns:
                win_norm = normalize(high_quality['승률'])
                score_components.append(win_norm * 0.15)  # 15% 가중치

            if '백테스트수익률' in high_quality.columns:
                ret_norm = normalize(high_quality['백테스트수익률'])
                score_components.append(ret_norm * 0.15)  # 15% 가중치

            # 종합 점수 계산
            if score_components:
                high_quality['종합점수'] = sum(score_components)
            else:
                # 점수 계산이 불가능하면 기본값 사용
                high_quality['종합점수'] = 0.5

            # 정렬
            high_quality = high_quality.sort_values('종합점수', ascending=False)

        # 5. 저장
        try:
            high_quality.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"최적화된 결과 {len(high_quality)}개가 {filename}에 저장되었습니다.")
        except Exception as e:
            print(f"파일 저장 오류: {e}")
            # 백업 위치에 저장 시도
            try:
                backup_filename = filename.replace('.csv', '_backup.csv')
                high_quality.to_csv(backup_filename, index=False, encoding='utf-8-sig')
                print(f"백업 파일로 저장: {backup_filename}")
            except:
                print("파일 저장에 실패했습니다.")

        return high_quality

    #   향상된 메인 함수 (프로그램 실행 지점)
    def run_stock_analysis_pipeline(filter_by_volume=True, batch_size=100, period='2y', save_to_drive=False, drive_path=None):
        """
        전체 주식 분석 파이프라인 실행

        Parameters:
        -----------
        filter_by_volume : bool
            거래량 기준으로 종목 필터링 여부
        batch_size : int
            배치 처리 크기
        period : str
            분석 기간
        save_to_drive : bool
            Google Drive에 결과 저장 여부
        drive_path : str, optional
            Google Drive 저장 경로
        """
        try:
            print("전체 주식 분석 시작...")

            # 필요한 패키지 확인
            try:
                import html5lib
                print("html5lib 패키지가 설치되어 있습니다.")
            except ImportError:
                print("경고: html5lib 패키지가 설치되어 있지 않습니다.")
                print("pip install html5lib 명령어로 설치해주세요.")

            # matplotlib 백엔드 설정
            import matplotlib
            matplotlib.use('Agg')

            import warnings
            warnings.filterwarnings("ignore", message="Dataset is empty")
            warnings.filterwarnings("ignore", message="contains only positive or negative samples")

            # Google Drive 마운트 (옵션)
            if save_to_drive:
                try:
                    from google.colab import drive
                    drive.mount('/content/drive')

                    # 저장 경로 설정
                    if drive_path is None:
                        drive_path = "/content/drive/MyDrive/주식분석결과/"

                    import os
                    os.makedirs(drive_path, exist_ok=True)
                    print(f"Google Drive 마운트 완료. 결과 저장 경로: {drive_path}")
                except Exception as e:
                    print(f"Google Drive 마운트 오류: {e}")
                    save_to_drive = False
                    print("로컬 저장으로 전환합니다.")

            # StockAnalyzer 인스턴스 생성
            analyzer = StockAnalyzer()

            # KRX 종목 코드 가져오기
            krx_stocks = analyzer.get_krx_stock_codes()
            print(f"총 {len(krx_stocks)}개 종목 조회됨")

            # 필터링 적용
            if filter_by_volume:
                print("거래량 기준으로 종목 필터링 중...")
                filtered_stocks = analyzer.filter_stocks_by_quality(
                    krx_stocks,
                    min_volume=500000,  # 50만주 이상
                    min_days=200  # 200일 이상 거래 데이터
                )
                print(f"필터링 결과: {len(filtered_stocks)}개 종목 선택됨")
                analysis_targets = filtered_stocks
            else:
                analysis_targets = krx_stocks

            # 모델 신뢰도 및 거래 임계값 설정
            buy_confidence_threshold = 0.55  # 매수 확신도 임계값 (55%)
            sell_confidence_threshold = 0.55  # 매도 확신도 임계값 (55%)
            min_accuracy = 0.55  # 최소 모델 정확도 (55%)
            min_win_rate = 0.5  # 최소 승률 (50%)

            # 배치 처리로 분석 수행
            print(f"배치 크기 {batch_size}로 분석 시작...")
            results = analyzer.analyze_in_batches(
                stock_codes=analysis_targets,
                batch_size=batch_size,
                period=period,
                prediction_period=5,
                workers=4
            )

            # 결과 데이터프레임 생성
            results_data = []
            for code, result in results.items():
                if result is None:
                    continue

                # 예측 신뢰도 및 방향 가져오기
                prediction_signal = result.get('prediction_signal', '')
                prediction_confidence = result.get('prediction_confidence', 0)
                accuracy = result.get('accuracy', 0)
                win_rate = result.get('backtest', {}).get('win_rate', 0)

                # 거래 결정 (매수/매도/관망)
                trading_decision = "관망"
                action_reason = ""

                # 매수 신호 (확신도, 정확도, 승률 기준 충족 시)
                if (prediction_signal == "매수" and
                    (prediction_confidence >= buy_confidence_threshold * 0.95 or  # 약간 낮춤 (더 많은 기회 포착)
                    (accuracy >= min_accuracy and win_rate >= min_win_rate))):
                    trading_decision = "매수"
                    action_reason = f"확신도({prediction_confidence:.2%})가 좋거나 모델 성능(정확도:{accuracy:.2%}, 승률:{win_rate:.2%})이 양호함"
                # 매도 신호 (확신도, 정확도, 승률 모두 임계값 이상일 때)
                elif (prediction_signal == "매도" and
                    prediction_confidence >= sell_confidence_threshold and
                    accuracy >= min_accuracy and
                    win_rate >= min_win_rate):
                    trading_decision = "매도"
                    action_reason = f"확신도({prediction_confidence:.2%})가 높고 모델 성능(정확도:{accuracy:.2%}, 승률:{win_rate:.2%})이 좋음"
                # 관망 (기준 미달)
                else:
                    reasons = []
                    if prediction_confidence < max(buy_confidence_threshold, sell_confidence_threshold):
                        reasons.append(f"확신도 부족({prediction_confidence:.2%})")
                    if accuracy < min_accuracy:
                        reasons.append(f"정확도 부족({accuracy:.2%})")
                    if win_rate < min_win_rate:
                        reasons.append(f"승률 부족({win_rate:.2%})")
                    if reasons:
                        action_reason = ", ".join(reasons)
                    else:
                        action_reason = "기준 미달"

                # 매수 후 목표가 및 손절가 계산 - 더 정교한 계산
                current_price = result.get('latest_price', 0)
                avg_range = result.get('backtest', {}).get('avg_daily_range', 0)
                volatility = result.get('volatility', 0.03)  # 기본값 3%

                if avg_range == 0:  # avg_daily_range가 없으면 변동성 사용
                    avg_range = current_price * volatility

                # 매수 시나리오: 예상 승률과 변동성에 따른 위험/보상 조정
                # 승률이 높을수록 손절폭은 작게, 목표가는 크게 설정
                if win_rate > 0.65:  # 높은 승률
                    risk_reward_ratio = 3.0  # 3:1 위험/보상 비율
                    stop_loss_pct = 0.03  # 3% 손절
                elif win_rate > 0.55:  # 중간 승률
                    risk_reward_ratio = 2.0  # 2:1 위험/보상 비율
                    stop_loss_pct = 0.04  # 4% 손절
                else:  # 낮은 승률
                    risk_reward_ratio = 1.5  # 1.5:1 위험/보상 비율
                    stop_loss_pct = 0.05  # 5% 손절

                # 변동성 조정
                stop_loss_pct = max(stop_loss_pct, volatility * 0.8)  # 변동성의 최소 80%

                # 목표가 및 손절가 계산
                take_profit_pct = stop_loss_pct * risk_reward_ratio
                target_price = current_price * (1 + take_profit_pct)
                stop_loss = current_price * (1 - stop_loss_pct)

                # 예상 보유 기간 - 백테스트 평균 거래 기간 활용
                avg_trade_days = result.get('backtest', {}).get('avg_trade_days', 7)

                if avg_trade_days and avg_trade_days > 0:
                    if avg_trade_days < 3:
                        holding_period = "1-3 거래일"
                    elif avg_trade_days < 7:
                        holding_period = "3-7 거래일"
                    elif avg_trade_days < 14:
                        holding_period = "1-2주"
                    else:
                        holding_period = "2주 이상"
                else:
                    holding_period = "5-10 거래일" if prediction_signal == "매수" else "즉시 매도"

                # 종합 품질 점수 계산 (여러 지표의 가중 평균)
                quality_score = (
                    (prediction_confidence if prediction_signal == "매수" else 0) * 0.3 +  # 30% 확신도
                    accuracy * 0.25 +  # 25% 정확도
                    win_rate * 0.25 +  # 25% 승률
                    (result['backtest']['total_return'] * 2 if result['backtest']['total_return'] > 0 else 0) * 0.15 +  # 15% 백테스트 수익률
                    (result['backtest']['sharpe_ratio'] / 2 if result['backtest']['sharpe_ratio'] > 0 else 0) * 0.05  # 5% 샤프 비율
                )

                # 품질 등급 부여
                if quality_score >= 0.8:
                    quality_grade = "A"
                elif quality_score >= 0.7:
                    quality_grade = "B"
                elif quality_score >= 0.6:
                    quality_grade = "C"
                elif quality_score >= 0.5:
                    quality_grade = "D"
                else:
                    quality_grade = "F"

                # 필요한 데이터 추출
                data = {
                    '종목코드': code,
                    '종목명': result.get('company_name', code),
                    '현재가': current_price,
                    '예측방향': prediction_signal,
                    '예측확신도': prediction_confidence,
                    '거래결정': trading_decision,
                    '결정이유': action_reason,
                    '목표가': round(target_price) if trading_decision == "매수" else None,
                    '손절가': round(stop_loss) if trading_decision == "매수" else None,
                    '예상보유기간': holding_period if trading_decision == "매수" else None,
                    '정확도': accuracy,
                    '승률': win_rate,
                    '백테스트수익률': result['backtest']['total_return'] if 'backtest' in result else 0,
                    '샤프비율': result['backtest']['sharpe_ratio'] if 'backtest' in result else 0,
                    '품질점수': quality_score,
                    '품질등급': quality_grade
                }
                results_data.append(data)

            # 데이터프레임 생성
            all_results_df = pd.DataFrame(results_data)

            # 거래 결정별로 분류
            buy_recommendations = all_results_df[all_results_df['거래결정'] == "매수"].sort_values('예측확신도', ascending=False)
            sell_recommendations = all_results_df[all_results_df['거래결정'] == "매도"].sort_values('예측확신도', ascending=False)
            hold_recommendations = all_results_df[all_results_df['거래결정'] == "관망"]

            # 결과 저장 파일명 준비
            from datetime import datetime
            today_date = datetime.now().strftime("%Y%m%d")

            # 저장 경로 설정
            save_path = drive_path if save_to_drive else ""

            # 최적화된 결과 저장
            optimized_file = f"{save_path}optimized_signals_{today_date}.csv"
            analyzer.save_optimized_results(all_results_df, optimized_file)

            # 상위 20개 최적화 종목 추출
            print("\n상위 20개 최적화 종목 추출 중...")

            # CSV 파일 로드 (직접 결과 사용)
            top_signals = analyzer.save_optimized_results(all_results_df, f"{save_path}temp_signals.csv")

            # 종합 점수 계산 및 정렬
            if '품질점수' in top_signals.columns:
                buy_signals = top_signals.sort_values('품질점수', ascending=False)
            else:
                # 매수 신호만 필터링
                buy_signals = top_signals[top_signals['거래결정'] == '매수']

                # 각 지표에 가중치를 부여하여 종합 점수 계산
                components = []
                weights = []

                if '예측확신도' in buy_signals.columns:
                    components.append(buy_signals['예측확신도'])
                    weights.append(0.3)  # 30% 가중치

                if '정확도' in buy_signals.columns:
                    components.append(buy_signals['정확도'])
                    weights.append(0.3)  # 30% 가중치

                if '승률' in buy_signals.columns:
                    components.append(buy_signals['승률'])
                    weights.append(0.2)  # 20% 가중치

                if '백테스트수익률' in buy_signals.columns:
                    # 수익률 스케일링 (최대 50%까지만 고려)
                    scaled_return = buy_signals['백테스트수익률'].apply(lambda x: min(x, 0.5) / 0.5)
                    components.append(scaled_return)
                    weights.append(0.2)  # 20% 가중치

                # 종합 점수 계산
                if components:
                    total_weight = sum(weights)
                    buy_signals['종합점수'] = sum(c * w / total_weight for c, w in zip(components, weights))
                else:
                    buy_signals['종합점수'] = 0.5

                # 종합 점수로 정렬
                buy_signals = buy_signals.sort_values('종합점수', ascending=False)

            # 상위 20개 종목 추출
            top_20 = buy_signals.head(20)

            # 결과 저장
            top_20_file = f"{save_path}top_20_최적화종목_{today_date}.csv"
            top_20.to_csv(top_20_file, index=False, encoding='utf-8-sig')
            print(f"\n상위 20개 최적화 종목이 {top_20_file}에 저장되었습니다.")

            # 콘솔에 상위 20개 종목 출력
            print("\n" + "="*100)
            print(f"종합 점수 기준 상위 20개 종목")
            print("="*100)

            # 표시할 열 선택
            if '종합점수' in top_20.columns:
                display_cols = ['종목코드', '종목명', '현재가', '목표가', '손절가', '종합점수', '정확도', '승률', '백테스트수익률']
            else:
                display_cols = ['종목코드', '종목명', '현재가', '목표가', '손절가', '정확도', '승률', '백테스트수익률']

            # 사용 가능한 열만 선택
            display_cols = [col for col in display_cols if col in top_20.columns]

            # 출력 형식 지정
            formatted_top_20 = top_20[display_cols].copy()

            # 퍼센트 포맷팅
            for col in ['정확도', '승률', '예측확신도', '종합점수']:
                if col in formatted_top_20.columns:
                    formatted_top_20[col] = formatted_top_20[col].apply(lambda x: f"{x:.2%}" if pd.notnull(x) else "")

            # 가격 포맷팅
            for col in ['현재가', '목표가', '손절가']:
                if col in formatted_top_20.columns:
                    formatted_top_20[col] = formatted_top_20[col].apply(lambda x: f"{int(x):,}" if pd.notnull(x) else "")

            print(formatted_top_20.to_string(index=False))

            # 1. 매수 추천 종목 저장
            if len(buy_recommendations) > 0:
                buy_file = f"{save_path}buy_signals_{today_date}.csv"
                buy_recommendations.to_csv(buy_file, index=False, encoding='utf-8-sig')
                print(f"\n매수 추천 종목 {len(buy_recommendations)}개가 {buy_file}에 저장되었습니다.")

                # 콘솔에 매수 추천 상위 종목 출력
                print("\n" + "="*100)
                print(f"매수 추천 상위 종목 (총 {len(buy_recommendations)}개)")
                print("="*100)

                display_cols = ['종목코드', '종목명', '현재가', '예측확신도', '목표가', '손절가', '예상보유기간', '정확도', '승률', '품질등급']
                display_cols = [col for col in display_cols if col in buy_recommendations.columns]

                top_buys = buy_recommendations[display_cols].head(min(10, len(buy_recommendations)))

                # 출력 형식 지정
                for col in ['예측확신도', '정확도', '승률']:
                    if col in top_buys.columns:
                        top_buys[col] = top_buys[col].apply(lambda x: f"{x:.2%}")

                for col in ['현재가', '목표가', '손절가']:
                    if col in top_buys.columns:
                        top_buys[col] = top_buys[col].apply(lambda x: f"{int(x):,}" if pd.notnull(x) else "")

                print(top_buys.to_string(index=False))
            else:
                print("\n매수 추천 종목이 없습니다.")

            # 2. 매도 추천 종목 저장
            if len(sell_recommendations) > 0:
                sell_file = f"{save_path}sell_signals_{today_date}.csv"
                sell_recommendations.to_csv(sell_file, index=False, encoding='utf-8-sig')
                print(f"\n매도 추천 종목 {len(sell_recommendations)}개가 {sell_file}에 저장되었습니다.")

                # 콘솔에 매도 추천 상위 종목 출력
                print("\n" + "="*100)
                print(f"매도 추천 상위 종목 (총 {len(sell_recommendations)}개)")
                print("="*100)

                display_cols = ['종목코드', '종목명', '현재가', '예측확신도', '정확도', '승률', '품질등급']
                display_cols = [col for col in display_cols if col in sell_recommendations.columns]

                top_sells = sell_recommendations[display_cols].head(min(10, len(sell_recommendations)))

                # 출력 형식 지정
                for col in ['예측확신도', '정확도', '승률']:
                    if col in top_sells.columns:
                        top_sells[col] = top_sells[col].apply(lambda x: f"{x:.2%}")

                if '현재가' in top_sells.columns:
                    top_sells['현재가'] = top_sells['현재가'].apply(lambda x: f"{int(x):,}")

                print(top_sells.to_string(index=False))
            else:
                print("\n매도 추천 종목이 없습니다.")

            # 3. 전체 분석 결과 저장
            all_results_file = f"{save_path}all_stock_analysis_{today_date}.csv"
            all_results_df.to_csv(all_results_file, index=False, encoding='utf-8-sig')
            print(f"\n전체 분석 결과 {len(all_results_df)}개가 {all_results_file}에 저장되었습니다.")

            # 4. HTML 보고서 생성 및 저장
            try:
                html_report = analyzer.generate_report(top_n=30, format='html')
                report_file = f"{save_path}stock_report_{today_date}.html"

                with open(report_file, 'w', encoding='utf-8') as f:
                    f.write(html_report)

                print(f"\nHTML 보고서가 {report_file}에 저장되었습니다.")
            except Exception as e:
                print(f"HTML 보고서 생성 오류: {e}")

            print("\n분석 및 거래 신호 생성 완료!")

            # 5. Google Drive 저장 확인
            if save_to_drive:
                print("\nGoogle Drive에 모든 파일이 저장되었습니다.")
                print(f"저장 위치: {drive_path}")

        except Exception as e:
            print(f"\n오류 발생: {e}")
            import traceback
            traceback.print_exc()

    def generate_report(self, top_n=20, format='text'):
        """
        분석 결과 보고서 생성 - 개선된 버전

        Parameters:
        -----------
        top_n : int
            보고서에 포함할 상위 종목 수
        format : str
            보고서 형식 ('text' 또는 'html')

        Returns:
        --------
        str
            보고서 텍스트/HTML
        """
        if not self.analysis_results:
            raise ValueError("먼저 analyze_all_stocks() 메서드를 호출하세요.")

        # 상위 종목 가져오기
        top_backtest = self.get_top_stocks('backtest_return', top_n)
        top_accuracy = self.get_top_stocks('accuracy', top_n)
        top_sharpe = self.get_top_stocks('sharpe_ratio', top_n)
        top_combined = self.get_top_stocks('combined_score', top_n)

        # 매수 신호가 있는 종목 가져오기
        buy_signals = [result for code, result in self.analysis_results.items()
                    if result is not None and result['prediction_signal'] == "매수"]

        # 신뢰도별로 정렬
        buy_signals_sorted = sorted(buy_signals, key=lambda x: x.get('prediction_confidence', 0), reverse=True)

        # 텍스트 형식 보고서
        if format == 'text':
            # 보고서 생성
            report = []

            # 현재 날짜 추가
            from datetime import datetime
            report.append("=" * 80)
            report.append(f"주식 분석 보고서 - {datetime.now().strftime('%Y-%m-%d %H:%M')}")
            report.append(f"분석 종목 수: {len(self.analysis_results)}")
            report.append("=" * 80)

            # 요약 통계
            report.append("\n[요약 통계]")
            valid_results = [r for r in self.analysis_results.values() if r is not None]
            all_returns = [result['backtest']['total_return'] for result in valid_results]
            all_accuracies = [result['accuracy'] for result in valid_results]
            all_sharpes = [result['backtest']['sharpe_ratio'] for result in valid_results]
            all_win_rates = [result['backtest']['win_rate'] for result in valid_results]

            report.append(f"평균 백테스트 수익률: {np.mean(all_returns):.4f} ({np.mean(all_returns) * 100:.2f}%)")
            report.append(f"평균 모델 정확도: {np.mean(all_accuracies):.4f} ({np.mean(all_accuracies) * 100:.2f}%)")
            report.append(f"평균 샤프 비율: {np.mean(all_sharpes):.4f}")
            report.append(f"평균 승률: {np.mean(all_win_rates):.4f} ({np.mean(all_win_rates) * 100:.2f}%)")
            report.append(f"매수 신호 종목 수: {len(buy_signals)} ({len(buy_signals) / len(valid_results) * 100:.2f}%)")

            # 종합 점수 상위 종목
            report.append("\n\n[종합 점수 상위 종목]")
            report.append("순위\t종목코드\t종목명\t\t종합점수\t백테스트수익률\t정확도\t샤프비율\t예측신호")
            report.append("-" * 80)

            for i, (_, row) in enumerate(top_combined.iterrows(), 1):
                code = row['code']
                company = row['company']
                combined_score = row['combined_score']
                backtest_return = row['backtest_return'] * 100
                accuracy = row['accuracy'] * 100
                sharpe = row['sharpe_ratio']
                signal = row['prediction_signal']

                report.append(f"{i}\t{code}\t{company:<10}\t{combined_score:.3f}\t{backtest_return:.2f}%\t{accuracy:.2f}%\t{sharpe:.2f}\t{signal}")

            # 백테스트 수익률 상위 종목
            report.append("\n\n[백테스트 수익률 상위 종목]")
            report.append("순위\t종목코드\t종목명\t\t수익률\t정확도\t샤프비율\t예측신호")
            report.append("-" * 80)

            for i, (_, row) in enumerate(top_backtest.iterrows(), 1):
                code = row['code']
                company = row['company']
                backtest_return = row['backtest_return'] * 100
                accuracy = row['accuracy'] * 100
                sharpe = row['sharpe_ratio']
                signal = row['prediction_signal']

                report.append(f"{i}\t{code}\t{company:<10}\t{backtest_return:.2f}%\t{accuracy:.2f}%\t{sharpe:.2f}\t{signal}")

            # 매수 신호 종목 (신뢰도순)
            report.append("\n\n[매수 신호 종목 (신뢰도순)]")
            report.append("종목코드\t종목명\t\t신뢰도\t백테스트 수익률\t정확도\t승률\t최대손실")
            report.append("-" * 80)

            for i, result in enumerate(buy_signals_sorted[:min(20, len(buy_signals_sorted))], 1):
                code = result['stock_code']
                company = result.get('company_name', code)
                confidence = result.get('prediction_confidence', 0) * 100
                backtest_return = result['backtest']['total_return'] * 100
                accuracy = result['accuracy'] * 100
                win_rate = result['backtest']['win_rate'] * 100
                max_drawdown = result['backtest']['max_drawdown'] * 100

                report.append(f"{code}\t{company:<10}\t{confidence:.2f}%\t{backtest_return:.2f}%\t{accuracy:.2f}%\t{win_rate:.2f}%\t{max_drawdown:.2f}%")

            # 추가: 상관관계 분석
            report.append("\n\n[성능 지표 상관관계 분석]")
            # 데이터프레임 생성
            metrics_df = pd.DataFrame([
                {
                    'backtest_return': result['backtest']['total_return'],
                    'accuracy': result['accuracy'],
                    'sharpe_ratio': result['backtest']['sharpe_ratio'],
                    'win_rate': result['backtest']['win_rate'],
                    'max_drawdown': result['backtest']['max_drawdown']
                }
                for result in valid_results
            ])

            # 상관관계 계산
            corr_matrix = metrics_df.corr()

            # 주요 상관관계 출력
            report.append("백테스트 수익률과 다른 지표의 상관관계:")
            for col in ['accuracy', 'sharpe_ratio', 'win_rate', 'max_drawdown']:
                corr = corr_matrix.loc['backtest_return', col]
                report.append(f"- {col}: {corr:.4f}")

            # 투자 전략 제안
            report.append("\n\n[투자 전략 제안]")

            # 시장 상황 분석
            market_bullish = len([r for r in buy_signals if r.get('prediction_confidence', 0) > 0.7]) > len(buy_signals) / 3

            if market_bullish:
                report.append("현재 분석 결과는 전반적으로 상승 추세를 시사합니다.")
                if len(buy_signals) > 10:
                    report.append("다수의 매수 신호가 있어, 다음과 같은 고려사항을 제안합니다:")
                    report.append("1. 포트폴리오 분산: 매수 신호 상위 5-10개 종목에 자본을 분산 투자")
                    report.append("2. 단계적 진입: 전체 투자금의 60%를 초기에 투자하고, 나머지는 추가 하락 시 분할 매수")
                    report.append("3. 철저한 손절: 각 종목별 3% 손절라인 설정")
                else:
                    report.append("제한된 매수 신호만 있어, 신중한 접근이 필요합니다:")
                    report.append("1. 선별적 투자: 매수 신호 중 종합 점수 상위 3-5개 종목에만 집중")
                    report.append("2. 자본 보존: 전체 투자금의 30-40%만 투자하고 나머지는 현금 보유")
            else:
                report.append("현재 분석 결과는 시장의 불확실성을 시사합니다.")
                report.append("1. 방어적 포지션: 매수 신호가 제한적이므로 전체 자본의 20-30%만 투자 고려")
                report.append("2. 안전 자산 유지: 나머지 자본은 현금 또는 저위험 자산으로 보유")

            report.append("\n참고: 이 보고서는 투자 참고용이며, 실제 투자 결정은 본인의 판단에 따라 이루어져야 합니다.")

            return "\n".join(report)

        elif format == 'html':
            # HTML 형식 보고서 (좀 더 시각적으로 보기 좋게)
            html = []
            html.append("<html><head>")
            html.append("<style>")
            html.append("body { font-family: Arial, sans-serif; margin: 20px; }")
            html.append("h1, h2 { color: #2c3e50; }")
            html.append("table { border-collapse: collapse; width: 100%; margin-bottom: 20px; }")
            html.append("th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }")
            html.append("th { background-color: #f2f2f2; color: #333; }")
            html.append("tr:nth-child(even) { background-color: #f9f9f9; }")
            html.append(".buy { color: #27ae60; font-weight: bold; }")
            html.append(".sell { color: #e74c3c; font-weight: bold; }")
            html.append(".summary-box { background-color: #f8f9fa; border: 1px solid #ddd; padding: 15px; border-radius: 5px; margin-bottom: 20px; }")
            html.append("</style>")
            html.append("</head><body>")

            # 헤더 및 요약
            from datetime import datetime
            html.append(f"<h1>주식 분석 보고서</h1>")
            html.append(f"<p>생성일시: {datetime.now().strftime('%Y-%m-%d %H:%M')}</p>")

            # 요약 통계
            valid_results = [r for r in self.analysis_results.values() if r is not None]
            all_returns = [result['backtest']['total_return'] for result in valid_results]
            all_accuracies = [result['accuracy'] for result in valid_results]
            all_sharpes = [result['backtest']['sharpe_ratio'] for result in valid_results]
            all_win_rates = [result['backtest']['win_rate'] for result in valid_results]

            html.append("<div class='summary-box'>")
            html.append("<h2>요약 통계</h2>")
            html.append("<table>")
            html.append("<tr><th>지표</th><th>평균값</th></tr>")
            html.append(f"<tr><td>분석 종목 수</td><td>{len(valid_results)}</td></tr>")
            html.append(f"<tr><td>매수 신호 종목 수</td><td>{len(buy_signals)} ({len(buy_signals) / len(valid_results) * 100:.2f}%)</td></tr>")
            html.append(f"<tr><td>평균 백테스트 수익률</td><td>{np.mean(all_returns):.4f} ({np.mean(all_returns) * 100:.2f}%)</td></tr>")
            html.append(f"<tr><td>평균 모델 정확도</td><td>{np.mean(all_accuracies):.4f} ({np.mean(all_accuracies) * 100:.2f}%)</td></tr>")
            html.append(f"<tr><td>평균 샤프 비율</td><td>{np.mean(all_sharpes):.4f}</td></tr>")
            html.append(f"<tr><td>평균 승률</td><td>{np.mean(all_win_rates):.4f} ({np.mean(all_win_rates) * 100:.2f}%)</td></tr>")
            html.append("</table>")
            html.append("</div>")

            # 종합 점수 상위 종목
            html.append("<h2>종합 점수 상위 종목</h2>")
            html.append("<table>")
            html.append("<tr><th>순위</th><th>종목코드</th><th>종목명</th><th>종합점수</th><th>백테스트수익률</th><th>정확도</th><th>샤프비율</th><th>예측신호</th></tr>")

            for i, (_, row) in enumerate(top_combined.iterrows(), 1):
                code = row['code']
                company = row['company']
                combined_score = row['combined_score']
                backtest_return = row['backtest_return'] * 100
                accuracy = row['accuracy'] * 100
                sharpe = row['sharpe_ratio']
                signal = row['prediction_signal']

                signal_class = "buy" if signal == "매수" else "sell" if signal == "매도" else ""

                html.append(f"<tr>")
                html.append(f"<td>{i}</td>")
                html.append(f"<td>{code}</td>")
                html.append(f"<td>{company}</td>")
                html.append(f"<td>{combined_score:.3f}</td>")
                html.append(f"<td>{backtest_return:.2f}%</td>")
                html.append(f"<td>{accuracy:.2f}%</td>")
                html.append(f"<td>{sharpe:.2f}</td>")
                html.append(f"<td class='{signal_class}'>{signal}</td>")
                html.append(f"</tr>")

            html.append("</table>")

            # 백테스트 수익률 상위 종목
            html.append("<h2>백테스트 수익률 상위 종목</h2>")
            html.append("<table>")
            html.append("<tr><th>순위</th><th>종목코드</th><th>종목명</th><th>수익률</th><th>정확도</th><th>샤프비율</th><th>승률</th><th>예측신호</th></tr>")

            for i, (_, row) in enumerate(top_backtest.iterrows(), 1):
                code = row['code']
                company = row['company']
                backtest_return = row['backtest_return'] * 100
                accuracy = row['accuracy'] * 100
                sharpe = row['sharpe_ratio']
                win_rate = row['win_rate'] * 100
                signal = row['prediction_signal']

                signal_class = "buy" if signal == "매수" else "sell" if signal == "매도" else ""

                html.append(f"<tr>")
                html.append(f"<td>{i}</td>")
                html.append(f"<td>{code}</td>")
                html.append(f"<td>{company}</td>")
                html.append(f"<td>{backtest_return:.2f}%</td>")
                html.append(f"<td>{accuracy:.2f}%</td>")
                html.append(f"<td>{sharpe:.2f}</td>")
                html.append(f"<td>{win_rate:.2f}%</td>")
                html.append(f"<td class='{signal_class}'>{signal}</td>")
                html.append(f"</tr>")

            html.append("</table>")

            # 매수 신호 종목 (신뢰도순)
            html.append("<h2>매수 신호 종목 (신뢰도순)</h2>")
            html.append("<table>")
            html.append("<tr><th>종목코드</th><th>종목명</th><th>신뢰도</th><th>백테스트 수익률</th><th>정확도</th><th>승률</th><th>최대손실</th></tr>")

            for result in buy_signals_sorted[:min(20, len(buy_signals_sorted))]:
                code = result['stock_code']
                company = result.get('company_name', code)
                confidence = result.get('prediction_confidence', 0) * 100
                backtest_return = result['backtest']['total_return'] * 100
                accuracy = result['accuracy'] * 100
                win_rate = result['backtest']['win_rate'] * 100
                max_drawdown = result['backtest']['max_drawdown'] * 100

                # 신뢰도에 따른 강조
                confidence_style = ""
                if confidence >= 80:
                    confidence_style = "style='font-weight: bold; color: #27ae60;'"
                elif confidence >= 70:
                    confidence_style = "style='font-weight: bold; color: #2980b9;'"

                html.append(f"<tr>")
                html.append(f"<td>{code}</td>")
                html.append(f"<td>{company}</td>")
                html.append(f"<td {confidence_style}>{confidence:.2f}%</td>")
                html.append(f"<td>{backtest_return:.2f}%</td>")
                html.append(f"<td>{accuracy:.2f}%</td>")
                html.append(f"<td>{win_rate:.2f}%</td>")
                html.append(f"<td>{max_drawdown:.2f}%</td>")
                html.append(f"</tr>")

            html.append("</table>")

            # 투자 전략 제안
            html.append("<h2>투자 전략 제안</h2>")
            html.append("<div class='summary-box'>")

            # 시장 상황 분석
            market_bullish = len([r for r in buy_signals if r.get('prediction_confidence', 0) > 0.7]) > len(buy_signals) / 3

            if market_bullish:
                html.append("<p>현재 분석 결과는 전반적으로 <strong>상승 추세</strong>를 시사합니다.</p>")
                if len(buy_signals) > 10:
                    html.append("<p>다수의 매수 신호가 있어, 다음과 같은 고려사항을 제안합니다:</p>")
                    html.append("<ol>")
                    html.append("<li><strong>포트폴리오 분산:</strong> 매수 신호 상위 5-10개 종목에 자본을 분산 투자</li>")
                    html.append("<li><strong>단계적 진입:</strong> 전체 투자금의 60%를 초기에 투자하고, 나머지는 추가 하락 시 분할 매수</li>")
                    html.append("<li><strong>철저한 손절:</strong> 각 종목별 3% 손절라인 설정</li>")
                    html.append("</ol>")
                else:
                    html.append("<p>제한된 매수 신호만 있어, 신중한 접근이 필요합니다:</p>")
                    html.append("<ol>")
                    html.append("<li><strong>선별적 투자:</strong> 매수 신호 중 종합 점수 상위 3-5개 종목에만 집중</li>")
                    html.append("<li><strong>자본 보존:</strong> 전체 투자금의 30-40%만 투자하고 나머지는 현금 보유</li>")
                    html.append("</ol>")
            else:
                html.append("<p>현재 분석 결과는 시장의 <strong>불확실성</strong>을 시사합니다.</p>")
                html.append("<ol>")
                html.append("<li><strong>방어적 포지션:</strong> 매수 신호가 제한적이므로 전체 자본의 20-30%만 투자 고려</li>")
                html.append("<li><strong>안전 자산 유지:</strong> 나머지 자본은 현금 또는 저위험 자산으로 보유</li>")
                html.append("</ol>")

            html.append("<p><em>참고: 이 보고서는 투자 참고용이며, 실제 투자 결정은 본인의 판단에 따라 이루어져야 합니다.</em></p>")
            html.append("</div>")

            html.append("</body></html>")

            return "\n".join(html)

        else:
            raise ValueError("지원되지 않는 보고서 형식입니다. 'text' 또는 'html'을 사용하세요.")

# 통합 데이터 소스 기능
def integrate_multiple_data_sources(stock_code):
    """여러 데이터 소스를 통합하여 더 강력한 예측 성능 제공"""
    # Yahoo Finance 데이터
    def download_yahoo_finance(stock_code):
        ticker = f"{stock_code}.KS"
        session=requests.Session(impersonate="chrome")
        stock = yf.Ticker(ticker,session=session)
        df = stock.history(period="5y")  # 5년 데이터
        df.reset_index(inplace=True)
        return df

    # 네이버 금융 데이터 (예시)
    def download_naver_finance(stock_code):
        # 이 함수는 실제 구현이 필요 (웹 스크래핑 등)
        # 여기서는 예시로만 제공
        print("네이버 금융 데이터 다운로드는 실제 구현이 필요합니다.")
        return None

    # 데이터 결합
    def merge_data_sources(yahoo_data, naver_data):
        if naver_data is None:
            return yahoo_data

        # 실제 데이터 결합 로직 구현 필요
        # 이 부분은 두 데이터 소스의 형식에 따라 달라집니다
        return yahoo_data

    # Yahoo Finance 데이터 다운로드
    yahoo_data = download_yahoo_finance(stock_code)

    # 네이버 금융 데이터 다운로드 (예시)
    naver_data = download_naver_finance(stock_code)

    # 데이터 결합
    combined_data = merge_data_sources(yahoo_data, naver_data)

    return combined_data

def setup_gpu_turbo_mode():
      """GPU 터보 모드 설정"""
      print("🔥 GPU 터보 모드 설정 중...")
      
      try:
          import torch
          if torch.cuda.is_available():
              # GPU 메모리 풀 설정
              torch.cuda.empty_cache()
              torch.cuda.set_per_process_memory_fraction(0.95)  # GPU 메모리 95% 사용
              
              # CUDA 설정 최적화
              import os
              os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # 비동기 실행
              os.environ['CUDA_CACHE_DISABLE'] = '0'    # 캐시 활성화
              
              print("✅ GPU 터보 모드 활성화 완료")
              
              # GPU 정보 출력
              gpu_name = torch.cuda.get_device_name(0)
              gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
              print(f"🚀 GPU: {gpu_name}")
              print(f"🔥 메모리: {gpu_memory:.1f}GB")
              
          else:
              print("❌ GPU를 찾을 수 없습니다.")
              
      except Exception as e:
          print(f"⚠️ GPU 설정 오류: {e}")

def monitor_gpu_usage():
    """GPU 사용량 실시간 모니터링"""
    try:
        import torch
        if torch.cuda.is_available():
            memory_used = torch.cuda.memory_allocated(0) / 1024**3
            memory_cached = torch.cuda.memory_reserved(0) / 1024**3
            memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3
                
            usage_percent = (memory_used / memory_total) * 100
                
            print(f"📊 GPU 실시간 사용량:")
            print(f"   💾 사용 중: {memory_used:.2f}GB")
            print(f"   📦 캐시됨: {memory_cached:.2f}GB") 
            print(f"   🔥 사용률: {usage_percent:.1f}%")
                
            if usage_percent > 90:
                print("⚠️ GPU 메모리 부족 경고!")
            elif usage_percent > 70:
                print("✅ GPU 메모리 최적 사용 중")
            else:
                print("🚀 GPU 메모리 여유 있음")
                    
    except Exception as e:
        print(f"GPU 모니터링 오류: {e}")

if __name__ == "__main__":
    # GPU 최적화 설정
    setup_gpu_turbo_mode()
    
    try:
        import warnings
        warnings.filterwarnings("ignore")
        
        analyzer = StockAnalyzer()
        krx_stocks = analyzer.get_krx_stock_codes()
        
        # 🔥 최적화된 분석 (정확도 유지)
        results = analyzer.analyze_in_batches(
            stock_codes=krx_stocks,
            batch_size=100,              # GPU 최적화 자동
            period='2y',                  # 빠른 분석
            prediction_period=5,
            workers=1,                    # GPU 집중
            advanced_features=True        # 🔥 True로 복원 (정확도 위해)
        )
        
        # GPU 사용량 모니터링
        monitor_gpu_usage()
        try:
            print("전체 주식 분석 시작...")
                
            try:
                import html5lib
                print("html5lib 패키지가 설치되어 있습니다.")
            except ImportError:
                print("경고: html5lib 패키지가 설치되어 있지 않습니다.")
                print("pip install html5lib 명령어로 설치해주세요.")

            # matplotlib 백엔드 설정
            import matplotlib
            matplotlib.use('Agg')

            import warnings
            warnings.filterwarnings("ignore", message="Dataset is empty")
            warnings.filterwarnings("ignore", message="contains only positive or negative samples")

            # StockAnalyzer 인스턴스 생성
            analyzer = StockAnalyzer()

            # KRX 종목 코드 가져오기
            krx_stocks = analyzer.get_krx_stock_codes()
            print(f"총 {len(krx_stocks)}개 종목 조회됨")

            # 분석할 최대 종목 수 설정
            max_stocks = None  # 30  # 테스트용으로 30개, 전체 분석은 None으로 변경

            # 모델 신뢰도 및 거래 임계값 설정
            buy_confidence_threshold = 0.55  # 매수 확신도 임계값 (55%)
            sell_confidence_threshold = 0.55  # 매도 확신도 임계값 (55%)
            min_accuracy = 0.55  # 최소 모델 정확도 (55%)
            min_win_rate = 0.5  # 최소 승률 (50%)

            # 병렬 처리로 모든 종목 분석 (개선: 5년 데이터 사용)
            # results = analyzer.analyze_all_stocks_parallel(
            #     stock_codes=krx_stocks,
            #     period='2y',  # 1y에서 5y로 변경
            #     max_stocks=max_stocks,
            #     prediction_period=5,
            #     workers=4 # 작업자 수
            # )

            results = analyzer.analyze_in_batches(
                stock_codes=krx_stocks,
                batch_size=100,  # GPU 메모리에 따라 자동 최적화
                period='2y',    
                prediction_period=5,
                workers=1,       # GPU 집중 활용을 위해 단일 워커
                advanced_features=False  
            )

            # 결과 데이터프레임 생성
            results_data = []
            for code, result in results.items():
                if result is None:
                    continue

                # 예측 신뢰도 및 방향 가져오기
                prediction_signal = result.get('prediction_signal', '')
                prediction_confidence = result.get('prediction_confidence', 0)
                accuracy = result.get('accuracy', 0)
                win_rate = result.get('backtest', {}).get('win_rate', 0)

                # 거래 결정 (매수/매도/관망)
                trading_decision = "관망"
                action_reason = ""

                # 매수 신호 (확신도, 정확도, 승률 모두 임계값 이상일 때)
                if (prediction_signal == "매수" and
                    (prediction_confidence >= buy_confidence_threshold * 0.95 or  # 약간 낮춤 (더 많은 기회 포착)
                    (accuracy >= min_accuracy and win_rate >= min_win_rate))):
                    trading_decision = "매수"
                    action_reason = f"확신도({prediction_confidence:.2%})가 좋거나 모델 성능(정확도:{accuracy:.2%}, 승률:{win_rate:.2%})이 양호함"# 매도 신호 (확신도, 정확도, 승률 모두 임계값 이상일 때)
                elif (prediction_signal == "매도" and
                    prediction_confidence >= sell_confidence_threshold and
                    accuracy >= min_accuracy and
                    win_rate >= min_win_rate):
                    trading_decision = "매도"
                    action_reason = f"확신도({prediction_confidence:.2%})가 높고 모델 성능(정확도:{accuracy:.2%}, 승률:{win_rate:.2%})이 좋음"

                # 관망 (기준 미달)
                else:
                    reasons = []
                    if prediction_confidence < max(buy_confidence_threshold, sell_confidence_threshold):
                        reasons.append(f"확신도 부족({prediction_confidence:.2%})")
                    if accuracy < min_accuracy:
                        reasons.append(f"정확도 부족({accuracy:.2%})")
                    if win_rate < min_win_rate:
                        reasons.append(f"승률 부족({win_rate:.2%})")
                    if reasons:
                        action_reason = ", ".join(reasons)
                    else:
                        action_reason = "기준 미달"

                # 매수 후 목표가 및 손절가 계산
                current_price = result.get('latest_price', 0)
                avg_range = result.get('backtest', {}).get('avg_daily_range', 0)

                if avg_range == 0:  # avg_daily_range가 없으면 현재가의 3% 사용
                    avg_range = current_price * 0.03

                # 매수 시나리오: 익절가/손절가 설정
                target_price = current_price * 1.1  # 10% 상승 목표
                stop_loss = current_price * 0.95  # 5% 하락 손절

                # 예상 보유 기간
                holding_period = "5-10 거래일" if prediction_signal == "매수" else "즉시 매도"

                # 필요한 데이터 추출
                data = {
                    '종목코드': code,
                    '종목명': result.get('company_name', code),
                    '현재가': current_price,
                    '예측방향': prediction_signal,
                    '예측확신도': prediction_confidence,
                    '거래결정': trading_decision,
                    '결정이유': action_reason,
                    '목표가': round(target_price) if trading_decision == "매수" else None,
                    '손절가': round(stop_loss) if trading_decision == "매수" else None,
                    '예상보유기간': holding_period if trading_decision == "매수" else None,
                    '정확도': accuracy,
                    '승률': win_rate,
                    '백테스트수익률': result['backtest']['total_return'] if 'backtest' in result else 0,
                    '샤프비율': result['backtest']['sharpe_ratio'] if 'backtest' in result else 0
                }
                results_data.append(data)

            # 데이터프레임 생성
            all_results_df = pd.DataFrame(results_data)

            # 거래 결정별로 분류
            buy_recommendations = all_results_df[all_results_df['거래결정'] == "매수"].sort_values('예측확신도', ascending=False)
            sell_recommendations = all_results_df[all_results_df['거래결정'] == "매도"].sort_values('예측확신도', ascending=False)
            hold_recommendations = all_results_df[all_results_df['거래결정'] == "관망"]

            # 결과 저장
            today_date = datetime.now().strftime("%Y%m%d")

            # 개선: 최적화된 결과 저장
            optimized_file = f"optimized_signals_{today_date}.csv"
            analyzer.save_optimized_results(all_results_df, optimized_file)

            print("\n상위 20개 최적화 종목 추출 중...")
            # CSV 파일 로드
            df = pd.read_csv(optimized_file, encoding='utf-8-sig')
            # 매수 신호만 필터링
            buy_signals = df[df['거래결정'] == '매수']
            # 각 지표에 가중치를 부여하여 종합 점수 계산
            buy_signals['종합점수'] = (
                buy_signals['정확도'] * 0.30 +       # 30% 가중치
                buy_signals['승률'] * 0.30 +         # 30% 가중치
                buy_signals['백테스트수익률'] * 0.15 + # 15% 가중치
                buy_signals['예측확신도'] * 0.25      # 25% 가중치 (상향 조정)
            )
            # 종합 점수로 정렬하여 상위 20개 종목 추출
            top_20 = buy_signals.sort_values('종합점수', ascending=False).head(20)
            # 결과 저장
            top_20_file = f"top_20_최적화종목_{today_date}.csv"
            top_20.to_csv(top_20_file, index=False, encoding='utf-8-sig')
            print(f"\n상위 20개 최적화 종목이 {top_20_file}에 저장되었습니다.")

            # 콘솔에 상위 20개 종목 출력
            print("\n" + "="*100)
            print(f"종합 점수 기준 상위 20개 종목")
            print("="*100)

            display_cols = ['종목코드', '종목명', '현재가', '목표가', '손절가', '정확도', '승률', '백테스트수익률', '종합점수']
            # 출력 형식 지정
            formatted_top_20 = top_20[display_cols].copy()
            for col in ['정확도', '승률', '예측확신도', '종합점수']:
                if col in formatted_top_20.columns:
                    formatted_top_20[col] = formatted_top_20[col].apply(lambda x: f"{x:.2%}" if pd.notnull(x) else "")

            for col in ['현재가', '목표가', '손절가']:
                if col in formatted_top_20.columns:
                    formatted_top_20[col] = formatted_top_20[col].apply(lambda x: f"{int(x):,}" if pd.notnull(x) else "")

            print(formatted_top_20.to_string(index=False))

            # 1. 매수 추천 종목 저장
            if len(buy_recommendations) > 0:
                buy_file = f"buy_signals_{today_date}.csv"
                buy_recommendations.to_csv(buy_file, index=False, encoding='utf-8-sig')
                print(f"\n매수 추천 종목 {len(buy_recommendations)}개가 {buy_file}에 저장되었습니다.")

                # 콘솔에 매수 추천 상위 종목 출력
                print("\n" + "="*100)
                print(f"매수 추천 상위 종목 (총 {len(buy_recommendations)}개)")
                print("="*100)

                display_cols = ['종목코드', '종목명', '현재가', '예측확신도', '목표가', '손절가', '예상보유기간', '정확도', '승률']
                top_buys = buy_recommendations[display_cols].head(min(10, len(buy_recommendations)))

                # 출력 형식 지정
                for col in ['예측확신도', '정확도', '승률']:
                    if col in top_buys.columns:
                        top_buys[col] = top_buys[col].apply(lambda x: f"{x:.2%}")

                for col in ['현재가', '목표가', '손절가']:
                    if col in top_buys.columns:
                        top_buys[col] = top_buys[col].apply(lambda x: f"{int(x):,}" if pd.notnull(x) else "")

                print(top_buys.to_string(index=False))
            else:
                print("\n매수 추천 종목이 없습니다.")

            # 2. 매도 추천 종목 저장
            if len(sell_recommendations) > 0:
                sell_file = f"sell_signals_{today_date}.csv"
                sell_recommendations.to_csv(sell_file, index=False, encoding='utf-8-sig')
                print(f"\n매도 추천 종목 {len(sell_recommendations)}개가 {sell_file}에 저장되었습니다.")

                # 콘솔에 매도 추천 상위 종목 출력
                print("\n" + "="*100)
                print(f"매도 추천 상위 종목 (총 {len(sell_recommendations)}개)")
                print("="*100)

                display_cols = ['종목코드', '종목명', '현재가', '예측확신도', '정확도', '승률']
                top_sells = sell_recommendations[display_cols].head(min(10, len(sell_recommendations)))

                # 출력 형식 지정
                for col in ['예측확신도', '정확도', '승률']:
                    if col in top_sells.columns:
                        top_sells[col] = top_sells[col].apply(lambda x: f"{x:.2%}")

                if '현재가' in top_sells.columns:
                    top_sells['현재가'] = top_sells['현재가'].apply(lambda x: f"{int(x):,}")

                print(top_sells.to_string(index=False))
            else:
                print("\n매도 추천 종목이 없습니다.")

            # 3. 전체 분석 결과 저장
            all_results_file = f"all_stock_analysis_{today_date}.csv"
            all_results_df.to_csv(all_results_file, index=False, encoding='utf-8-sig')
            print(f"\n전체 분석 결과 {len(all_results_df)}개가 {all_results_file}에 저장되었습니다.")

            print("\n분석 및 거래 신호 생성 완료!")

        except Exception as e:
            print(f"\n오류 발생: {e}")
            import traceback
            traceback.print_exc()
    except Exception as e:
        print(f"오류: {e}")
        import traceback
        traceback.print_exc()
